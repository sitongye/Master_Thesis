{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using TensorFlow backend.\n"
                    ]
                }
            ],
            "source": [
                "# import libraries\n",
                "import pandas as pd\n",
                "import os\n",
                "import spacy\n",
                "from spacy.pipeline import EntityRuler\n",
                "from spacy.displacy import render,serve\n",
                "from IPython.core.display import display, HTML\n",
                "from spacy.tokens import Span\n",
                "from spacy.displacy import render,serve\n",
                "import networkx as nx\n",
                "import itertools\n",
                "import json\n",
                "import pylab\n",
                "from spacy.util import filter_spans\n",
                "import re\n",
                "import tensorflow as tf\n",
                "from transformers import *\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch.nn.utils.rnn import pad_sequence\n",
                "from keras.utils import to_categorical\n",
                "from sklearn.model_selection import train_test_split\n",
                "import spacy\n",
                "from spacy import displacy\n",
                "from keras.models import Model\n",
                "from keras.layers import Input, LSTM, Lambda, Dense, Concatenate\n",
                "from keras.preprocessing.sequence import pad_sequences\n",
                "import pandas as pd\n",
                "import ast\n",
                "from tqdm import tqdm\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     C:\\Users\\sye\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "# for base model\n",
                "# load libraries\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from scipy.sparse import hstack\n",
                "from sklearn.linear_model import Lasso, LogisticRegression\n",
                "from sklearn import svm\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import nltk\n",
                "nltk.download('wordnet')\n",
                "import numpy as np\n",
                "from nltk.stem import WordNetLemmatizer \n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def bow_col2feat(train_data,test_data,column,paradict,bow=True):\n",
                "    features_train, features_test,vectorizer = bag_of_word(train_data[column].apply(lambda x: \" \".join(x)),\n",
                "                                                            test_data[column].apply(lambda x: \" \".join(x)),\n",
                "                                                            paradict,bow=bow)\n",
                "    return features_train, features_test,vectorizer\n",
                "\n",
                "def bow_train_feature_stack(train_data,test_data,paradict,column_list,bow=True):\n",
                "    features_stack_train = None\n",
                "    features_stack_test = None\n",
                "    for column in column_list:\n",
                "        features_train,features_test,_ = bow_col2feat(train_data,test_data,column,paradict,bow=bow)\n",
                "        features_stack_train = hstack((features_stack_train, features_train))\n",
                "        features_stack_test = hstack((features_stack_test,features_test))\n",
                "    return features_stack_train, features_stack_test\n",
                "\n",
                "def bag_of_word(train,test,paradict,bow=True):\n",
                "    vectorizer = CountVectorizer(ngram_range=paradict[\"NGRAM_RANGE\"],\n",
                "                                 max_features=paradict[\"MAX_FEATURES\"],\n",
                "                                 binary=paradict[\"BINARY\"],\n",
                "                                 max_df=paradict[\"MAX_DF\"])\n",
                "    if bow==False:\n",
                "        vectorizer = TfidfVectorizer(ngram_range=paradict[\"NGRAM_RANGE\"],\n",
                "                                 max_features=paradict[\"MAX_FEATURES\"],\n",
                "                                 binary=paradict[\"BINARY\"],\n",
                "                                 max_df=paradict[\"MAX_DF\"])\n",
                "    train_data_features = vectorizer.fit_transform(train)\n",
                "    test_data_features = vectorizer.transform(test)\n",
                "    return train_data_features, test_data_features, vectorizer\n",
                "\n",
                "bow_paradict = {\n",
                "\"NGRAM_RANGE\":(1,3),\n",
                "\"MAX_FEATURES\": 30,\n",
                "\"BINARY\": False,\n",
                "\"MAX_DF\":0.95}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from BertMerger import BadTERMMerger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "LABELED_DATA = r\"C:\\Users\\sye\\OneDrive - MHP\\Masterthese\\data\\processed_data\\TW\\labeled\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1d33ba26f98>),\n",
                            " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1d33bb45a08>),\n",
                            " ('BadTERMMerger', <BertMerger.BadTERMMerger at 0x1d33b888550>),\n",
                            " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1d33bb45a68>),\n",
                            " ('merge_entities', <function spacy.pipeline.functions.merge_entities(doc)>)]"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nlp = spacy.load(r\"C:\\Users\\sye\\OneDrive - MHP\\Masterthese\\py\\ner\\parameter\")\n",
                "nlp.add_pipe(nlp.create_pipe('merge_entities'))\n",
                "term_merger = BadTERMMerger(nlp)\n",
                "nlp.add_pipe(term_merger, before=\"ner\")\n",
                "nlp.pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.max_rows', 1000)\n",
                "pd.set_option('display.max_colwidth', 1000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def return_quant_token(row):\n",
                "    q_t = None\n",
                "    i = None\n",
                "    text_doc = nlp(row[\"Text\"])\n",
                "    for t in text_doc:\n",
                "        if row[\"Quant\"].strip().lower() in t.text.lower():\n",
                "            q_t = t\n",
                "            i = t.i\n",
                "    return q_t, i\n",
                "\n",
                "def return_target_token(row):\n",
                "    t_t = None\n",
                "    i = None\n",
                "    text_doc = nlp(row[\"Text\"])\n",
                "    for t in text_doc:\n",
                "        if str(row[\"target\"]).strip().lower() in t.text.lower():\n",
                "            t_t = t\n",
                "            i = t.i\n",
                "    return t_t, i\n",
                "\n",
                "def sent_snippet(row):\n",
                "    span = None\n",
                "    if (row[\"Quant_Token\"][1] is not None) and (row[\"target_Token\"][1] is not None):\n",
                "        start = min(row[\"Quant_Token\"][1],row[\"target_Token\"][1])\n",
                "        end = max(row[\"Quant_Token\"][1],row[\"target_Token\"][1])\n",
                "        span = row[\"Tokens\"][start:end+1]\n",
                "    return span\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def read_labeled_data(data_path):\n",
                "    gesamt = pd.DataFrame()\n",
                "    for path, _, files in os.walk(data_path):\n",
                "        for FILE_NAME in tqdm(files):\n",
                "            try:\n",
                "                test_input = pd.read_excel(os.path.join(path, FILE_NAME),usecols = [\"Text\",\"Quant\",\"Target\",\"Label\"],dtype={\"Text\":str,\"Quant\": str,\"Target\":str})\n",
                "                test_input.dropna(subset=[\"Label\"], inplace=True,axis=0)\n",
                "                test_input = test_input.reset_index(drop=True)\n",
                "                test_input.rename(columns={\"Target\":\"target\",\"Label\":\"label\"}, inplace=True)\n",
                "                test_input[\"label\"] = test_input[\"label\"].apply(lambda x: int(x))\n",
                "                test_input[\"Tokens\"] = test_input.Text.apply(lambda x: [t for t in nlp(x)])\n",
                "                test_input[\"Quant_Token\"] = test_input.apply(return_quant_token, axis=1)\n",
                "                test_input[\"target_Token\"] = test_input.apply(return_target_token, axis=1)\n",
                "                test_input[\"Sent_Span\"] = test_input.apply(sent_snippet, axis=1)\n",
                "                valided_index = []\n",
                "                for row in range(len(test_input)):\n",
                "                    tokens = test_input.loc[row, \"Tokens\"]\n",
                "                    quant_index= test_input.loc[row, \"Quant_Token\"][1]\n",
                "                    target_index = test_input.loc[row, \"target_Token\"][1]\n",
                "                    if quant_index is not None:\n",
                "                        if tokens[quant_index].head==tokens[target_index].head:\n",
                "                            valided_index.append(row)\n",
                "                cleaned = test_input.loc[valided_index,:]\n",
                "                cleaned =test_input.reset_index(drop=True)\n",
                "                print(FILE_NAME)\n",
                "                gesamt = gesamt.append(cleaned,ignore_index=True)\n",
                "            except:\n",
                "                print(\"ERROR!:\",FILE_NAME)\n",
                "                continue\n",
                "    return gesamt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  0%|                                                                                           | 0/59 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "01 The applicable motor vehicle category for vehicle inspection and testing.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  2%|█▍                                                                                 | 1/59 [00:00<00:27,  2.10it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "02 The requirement of specification for motor vehicle.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  3%|██▊                                                                                | 2/59 [00:10<03:08,  3.30s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "03-0 The installation of lighting and light-signaling devices.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  5%|████▏                                                                              | 3/59 [00:10<02:15,  2.43s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "03-1 The installation of lighting and light-signaling devices.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  7%|█████▋                                                                             | 4/59 [00:15<02:55,  3.19s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "04 Static Braking.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        "  8%|███████                                                                            | 5/59 [00:15<02:04,  2.30s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "06 The inspection requirement of fuel system for CNG vehicle.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 10%|████████▍                                                                          | 6/59 [00:16<01:34,  1.79s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "07 The lateral protection device and the Rear Underrun Protection Device (RUPD)(or bumper).xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 12%|█████████▊                                                                         | 7/59 [00:17<01:18,  1.50s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "08 The requirement of vehicle tilt stability.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 14%|███████████▎                                                                       | 8/59 [00:17<00:56,  1.11s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "09-2 Installation of audible warning devices.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 15%|████████████▋                                                                      | 9/59 [00:17<00:40,  1.23it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "10 Installation requirements of pay load meter.xlsx\n",
                        "11 The installation requirement of turning and reversing audible warning device.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 19%|███████████████▎                                                                  | 11/59 [00:17<00:28,  1.71it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "12 The thermal-insulation protection device of exhaust system for motorcycle.xlsx\n",
                        "13 The requirement of stability and durability regarding motorcycle stands.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 22%|██████████████████                                                                | 13/59 [00:17<00:19,  2.35it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "15 Payload meter.xlsx\n",
                        "19 Flammability of the interior materials for motor vehicle.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 25%|████████████████████▊                                                             | 15/59 [00:18<00:14,  3.05it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "19-1 Flammability of the interior materials for motor vehicle.xlsx\n",
                        "21-1 Audible warning devices.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 29%|███████████████████████▋                                                          | 17/59 [00:19<00:17,  2.44it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "22 Speedometer.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 31%|█████████████████████████                                                         | 18/59 [00:19<00:15,  2.71it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "23-2 Installation of devices for indirect vision.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 32%|██████████████████████████▍                                                       | 19/59 [00:20<00:26,  1.53it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "24 Driver operated controls.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 34%|███████████████████████████▊                                                      | 20/59 [00:21<00:19,  1.96it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "25-3 Safety Glass.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 36%|█████████████████████████████▏                                                    | 21/59 [00:24<00:47,  1.24s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "26-1 Safety Belt.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 37%|██████████████████████████████▌                                                   | 22/59 [00:25<00:47,  1.29s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "27 Devices for indirect vision.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 39%|███████████████████████████████▉                                                  | 23/59 [00:26<00:42,  1.18s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "29 Filament lamps.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 41%|█████████████████████████████████▎                                                | 24/59 [00:26<00:34,  1.00it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "31 Direction indicator.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 42%|██████████████████████████████████▋                                               | 25/59 [00:28<00:36,  1.09s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "33 Reversing lamps.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 44%|████████████████████████████████████▏                                             | 26/59 [00:28<00:27,  1.21it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "34 Front position lamps.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 46%|█████████████████████████████████████▌                                            | 27/59 [00:28<00:22,  1.39it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "35 Rear position lamps.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 47%|██████████████████████████████████████▉                                           | 28/59 [00:29<00:18,  1.68it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "39 End-outline marker lamp.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 49%|████████████████████████████████████████▎                                         | 29/59 [00:29<00:14,  2.03it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "41-0 Reflex reflectors.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 51%|█████████████████████████████████████████▋                                        | 30/59 [00:29<00:13,  2.17it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "42-3 Dynamic Braking.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 53%|███████████████████████████████████████████                                       | 31/59 [00:31<00:23,  1.19it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "44-1 Steering control system.xlsx\n",
                        "48-2 Safety belt anchorage.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 56%|█████████████████████████████████████████████▊                                    | 33/59 [00:31<00:16,  1.56it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "49-1 Seats.xlsx\n",
                        "50 Head restraint.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 59%|████████████████████████████████████████████████▋                                 | 35/59 [00:32<00:11,  2.02it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "51-2 Door latches and retention components.xlsx\n",
                        "52-2 Headlamps (headlamps of gas-discharge type excluded).xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 63%|███████████████████████████████████████████████████▍                              | 37/59 [00:32<00:08,  2.50it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "54-3 Prevention of fire risks for large passenger vehicle.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 64%|████████████████████████████████████████████████████▊                             | 38/59 [00:32<00:07,  2.90it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "55 Strength of super structure for large passenger vehicle.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 66%|██████████████████████████████████████████████████████▏                           | 39/59 [00:32<00:05,  3.64it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "56-3 Electromagnetic Compatibility.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 68%|███████████████████████████████████████████████████████▌                          | 40/59 [00:33<00:05,  3.27it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "58 The frameíªs fatigue strength of small-light moped.pdf.xlsx\n",
                        "59-1 Adaptive front lighting system (AFS).pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 71%|██████████████████████████████████████████████████████████▎                       | 42/59 [00:33<00:04,  4.04it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "61 The installation of the mechanical coupling device or component.pdf.xlsx\n",
                        "62 Mechanical coupling device or component.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 75%|█████████████████████████████████████████████████████████████▏                    | 44/59 [00:33<00:03,  4.47it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "63-1 Low floor vehicle.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 76%|██████████████████████████████████████████████████████████████▌                   | 45/59 [00:34<00:03,  3.62it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "66 fuel tank.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 78%|███████████████████████████████████████████████████████████████▉                  | 46/59 [00:34<00:02,  4.46it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "70 Lane departure warning system.pdf.xlsx\n",
                        "72 Advanced emergency braking system.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 81%|██████████████████████████████████████████████████████████████████▋               | 48/59 [00:34<00:02,  5.42it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "73 Daytime running lamp.xlsx\n",
                        "74 LED light sources.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 85%|█████████████████████████████████████████████████████████████████████▍            | 50/59 [00:34<00:01,  6.82it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "76 Speed limitation devices.pdf.xlsx\n",
                        "77 External projections.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 88%|████████████████████████████████████████████████████████████████████████▎         | 52/59 [00:35<00:01,  5.42it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "78 External projections (commercial vehicle).pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 90%|█████████████████████████████████████████████████████████████████████████▋        | 53/59 [00:35<00:01,  4.19it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "79 Rear marking plates for heavy and long vehicles.pdf.xlsx\n",
                        "83 Specifications of specific components for the compressed hydrogen storage system.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 93%|████████████████████████████████████████████████████████████████████████████▍     | 55/59 [00:35<00:00,  5.03it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "84 Brake assist systems.pdf.xlsx\n",
                        "86 Rear-end collision for prevention of fuel tank fire risks.pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r",
                        " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 57/59 [00:35<00:00,  6.08it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "89 Specifications of the compressed hydrogen storage system(L).pdf.xlsx\n",
                        "90 Specifications of specific components for the compressed hydrogen storage system(L).pdf.xlsx\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:36<00:00,  7.07it/s]\n"
                    ]
                }
            ],
            "source": [
                "train_data = read_labeled_data(data_path=LABELED_DATA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1129"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(train_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenized_df = train_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFzpJREFUeJzt3X+0XWV95/H3RwimCgs1BBclwTCY+pMS9A6DOHVUqFXpCDpaQRcFZTUw4GhVmJV2zSDW2mL9gVoqiAs0MBaMIsqyjAqo9QcKBAgBjAwppHAlQkj8AVUoJN/54+wrh8vN/X25ycP7tdZdZ+9n/zjP3vecz3n2c/d5bqoKSVK7njTbFZAkzSyDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4HWe7AgC77bZbLVq0aLarIUnblWuvvfbeqpo/1nrbRNAvWrSIlStXznY1JGm7kuRfx7OeXTeS1DiDXpIaZ9BLUuO2iT56SZqshx56iMHBQR544IHZrsqMmTt3LgsWLGDOnDmT2t6gl7RdGxwcZJdddmHRokUkme3qTLuqYuPGjQwODrL33ntPah923Ujarj3wwAPMmzevyZAHSMK8efOmdMVi0Eva7rUa8kOmenwGvSQ1zj56SU1ZtOyfpnV/6047dNTlGzdu5OCDDwbgZz/7GTvssAPz5/e+rHr11Vez0047jet5Nm3axIoVKzj++OOnVuERGPTSLJjuMJoJYwWceubNm8eqVasAOPXUU9l555056aSTJryfTZs2cdZZZ81I0Nt1I0kzZPny5RxwwAEsWbKEE044gS1btnDbbbexePFiNm3axObNmznooIP41re+xbJly7jllltYsmQJy5Ytm9Z62KKXpBlw0003cfHFF3PllVey4447snTpUi688ELe8pa38N73vpcTTjiB/fbbj/33359XvvKV7LXXXqxdu/a3VwfTyaCXpBlw+eWXc8011zAwMADAb37zGxYuXAjA8ccfzxe/+EU++9nPcv311894XQx6SZoBVcXb3/52PvCBDzxm2f3338/69evZvHkz999/P0996lNntC720UvSDDjkkENYsWIF9957L9C7O+eOO+4A4OSTT+aYY47hlFNO4bjjjgNgl1124b777puRutiil9SUbeVuoX333Zf3ve99HHLIIWzZsoU5c+Zw1llnceutt3LDDTdwxhlnsMMOO3DRRRdx/vnnc9RRRzEwMMC+++7LoYceymmnnTZtdUlVTdvOJmtgYKCm+x+PbA+3r8G286LU42t7eH1uL6/NNWvW8LznPW+2qzHjRjrOJNdW1cBY29p1I0mNGzPok8xNcnWSG5LcnOT9XfneSa5KcmuSLyTZqSt/cje/tlu+aGYPQZI0mvG06B8EXllV+wFLgFcnORD4EHB6VS0Gfg4c261/LPDzqno2cHq3niTNmG2hC3omTfX4xgz66rm/m53T/RTwSuBLXfly4PBu+rBunm75wWl9aDlJs2bu3Lls3Lix2bAfGo9+7ty5k97HuO66SbIDcC3wbOAfgH8BflFVD3erDAJ7dtN7And2FXw4yS+BecC9k66lJG3FggULGBwcZMOGDbNdlRkz9B+mJmtcQV9Vm4ElSZ4GXAyM9CfuoY/TkVrvj/moTbIUWAqw1157jauykjTcnDlzJv2fl54oJnTXTVX9AvgOcCDwtCRDHxQLgLu66UFgIUC3fFdg0wj7OruqBqpqYGhIT0nS9BvPXTfzu5Y8SX4HOARYA3wbeGO32tHAV7vpS7p5uuXfqlY7zyRpOzCerps9gOVdP/2TgBVV9bUkPwYuTPLXwPXAOd365wDnJ1lLryV/xAzUW5I0TmMGfVWtBvYfofw24IARyh8A3jQttZMkTZnfjJWkxhn0ktQ4g16SGmfQS1LjDHpJapz/eETSdm17GNsfZnd8f1v0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1Lgxgz7JwiTfTrImyc1J3tWVn5rkp0lWdT+v7dvmL5KsTXJLkj+ayQOQJI1uPP9K8GHgvVV1XZJdgGuTXNYtO72qPtK/cpLnA0cALwB+F7g8ye9V1ebprLgkaXzGbNFX1fqquq6bvg9YA+w5yiaHARdW1YNVdTuwFjhgOiorSZq4CfXRJ1kE7A9c1RW9I8nqJOcmeXpXtidwZ99mg4z+wSBJmkHjDvokOwMXAX9eVb8CzgT2AZYA64GPDq06wuY1wv6WJlmZZOWGDRsmXHFJ0viMK+iTzKEX8p+vqi8DVNXdVbW5qrYAn+GR7plBYGHf5guAu4bvs6rOrqqBqhqYP3/+VI5BkjSK8dx1E+AcYE1VfayvfI++1V4P3NRNXwIckeTJSfYGFgNXT1+VJUkTMZ67bl4KHAXcmGRVV/aXwJFJltDrllkHHAdQVTcnWQH8mN4dOyd6x40kzZ4xg76qvs/I/e6XjrLNB4EPTqFekqRp4jdjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNG89/mJJYtOyfZrsK47LutENnuwrSNscWvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjRsz6JMsTPLtJGuS3JzkXV35M5JcluTW7vHpXXmSfDLJ2iSrk7xopg9CkrR142nRPwy8t6qeBxwInJjk+cAy4IqqWgxc0c0DvAZY3P0sBc6c9lpLksZtzKCvqvVVdV03fR+wBtgTOAxY3q22HDi8mz4MOK96fgQ8Lcke015zSdK4TKiPPskiYH/gKuCZVbUeeh8GwO7dansCd/ZtNtiVDd/X0iQrk6zcsGHDxGsuSRqXcQd9kp2Bi4A/r6pfjbbqCGX1mIKqs6tqoKoG5s+fP95qSJImaFxBn2QOvZD/fFV9uSu+e6hLpnu8pysfBBb2bb4AuGt6qitJmqjx3HUT4BxgTVV9rG/RJcDR3fTRwFf7yv+0u/vmQOCXQ108kqTH33iGKX4pcBRwY5JVXdlfAqcBK5IcC9wBvKlbdinwWmAt8GvgbdNaY0nShIwZ9FX1fUbudwc4eIT1CzhxivWSJE0TvxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuPGDPok5ya5J8lNfWWnJvlpklXdz2v7lv1FkrVJbknyRzNVcUnS+IynRf854NUjlJ9eVUu6n0sBkjwfOAJ4QbfNp5LsMF2VlSRN3JhBX1XfBTaNc3+HARdW1YNVdTuwFjhgCvWTJE3RVPro35Fkdde18/SubE/gzr51BrsySdIsmWzQnwnsAywB1gMf7cozwro10g6SLE2yMsnKDRs2TLIakqSxTCroq+ruqtpcVVuAz/BI98wgsLBv1QXAXVvZx9lVNVBVA/Pnz59MNSRJ4zCpoE+yR9/s64GhO3IuAY5I8uQkewOLgaunVkVJ0lTsONYKSS4AXg7slmQQeB/w8iRL6HXLrAOOA6iqm5OsAH4MPAycWFWbZ6bqkqTxGDPoq+rIEYrPGWX9DwIfnEqlJEnTx2/GSlLjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4MYM+yblJ7klyU1/ZM5JcluTW7vHpXXmSfDLJ2iSrk7xoJisvSRrbeFr0nwNePaxsGXBFVS0GrujmAV4DLO5+lgJnTk81JUmTNWbQV9V3gU3Dig8DlnfTy4HD+8rPq54fAU9Lssd0VVaSNHGT7aN/ZlWtB+ged+/K9wTu7FtvsCuTJM2S6f5jbEYoqxFXTJYmWZlk5YYNG6a5GpKkIZMN+ruHumS6x3u68kFgYd96C4C7RtpBVZ1dVQNVNTB//vxJVkOSNJbJBv0lwNHd9NHAV/vK/7S7++ZA4JdDXTySpNmx41grJLkAeDmwW5JB4H3AacCKJMcCdwBv6la/FHgtsBb4NfC2GaizJGkCxgz6qjpyK4sOHmHdAk6caqUkSdPHb8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIat+NUNk6yDrgP2Aw8XFUDSZ4BfAFYBKwD/qSqfj61akqSJms6WvSvqKolVTXQzS8DrqiqxcAV3bwkaZbMRNfNYcDybno5cPgMPIckaZymGvQFfDPJtUmWdmXPrKr1AN3j7iNtmGRpkpVJVm7YsGGK1ZAkbc2U+uiBl1bVXUl2By5L8pPxblhVZwNnAwwMDNQU6yFJ2oopteir6q7u8R7gYuAA4O4kewB0j/dMtZKSpMmbdNAneWqSXYamgVcBNwGXAEd3qx0NfHWqlZQkTd5Uum6eCVycZGg//1hVX09yDbAiybHAHcCbpl5NSdJkTTroq+o2YL8RyjcCB0+lUpKk6eM3YyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklq3IwFfZJXJ7klydoky2bqeSRJo5uRoE+yA/APwGuA5wNHJnn+TDyXJGl0M9WiPwBYW1W3VdW/AxcCh83Qc0mSRjFTQb8ncGff/GBXJkl6nO04Q/vNCGX1qBWSpcDSbvb+JLfMUF2m027AvdO5w3xoOve23fF8Th/P5fTaXs7ns8az0kwF/SCwsG9+AXBX/wpVdTZw9gw9/4xIsrKqBma7Hq3wfE4fz+X0au18zlTXzTXA4iR7J9kJOAK4ZIaeS5I0ihlp0VfVw0neAXwD2AE4t6punonnkiSNbqa6bqiqS4FLZ2r/s2S76mraDng+p4/ncno1dT5TVWOvJUnabjkEgiQ1romgT1JJPto3f1KSU8fY5tQkP02yKsmPkxw5juc5NclJY6xzeP+3gJP8VZJDxnEY26zu/J7fN79jkg1JvtbNv26sYS6S3J7kOcPKPp7kf46yzaIkN021/tuKsc7jBPe1KMlgkicNK1+V5IBRtjsmyRkTfb7tSZL7R1n2uSTHDSs7PMmo3cxJ1iXZbbrq+HhrIuiBB4E3TOIXcXpVLaH3rd1PJ5kzDXU5nN6wDwBU1SlVdfk07Hc2/RvwwiS/083/IfDToYVVdUlVnTbGPi6kd/cVAF1AvRH4wjTXdVs26nmciKpaR+9LiX8wVJbkucAuVXX1FOvZsgvoex12jujKm9VK0D9M748n7x6+IMmzklyRZHX3uNfwdarqVuDXwNO7bfZJ8vUk1yb5XvcGGr7fP0tyTZIbklyU5ClJDgJeB3y4a1nt07Ug3thtc3CS65PcmOTcJE/uytcleX+S67plj3m+bcD/BQ7tpo+k743R30rsjveTSa5MctvQsfPYN9jLgHVV9a9d6/R73fFf153HRxneEk3ytSQv76ZfleSH3bZfTLLzdB74NBvtPB7Qnbfru8fndOXvSXJuN71vkpuSPIXHntPfBlaS/5rkqm5flyd55vCK9L82u/n7+6ZP7l7fq5O8f9qO/nGUZI8k3+3eizcl+QPgcuC5Sfbo1nkKcAjwlW7+K937/ub0vtQ5fJ+PuspMX+/BeHJjtrQS9NAbRO2tSXYdVn4GcF5V/T7weeCTwzdM8iLg1qq6pys6G/gfVfVi4CTgUyM835er6j9W1X7AGuDYqrqS3vcFTq6qJVX1L33PMRf4HPDmqtqX3h1P/71vf/dW1YuAM7vn3NZcCBzRHcfvA1eNsu4ewH8G/hg4DaCqVgNbkuzXrdPfiroH+MPu+N/MCL+jremu4v4XcEi3/UrgPePdfhaMdh5/ArysqvYHTgH+piv/OPDsJK8HPgscV1W/BlYAhycZunvuzd3+Ab4PHNjt60Jgq11kwyV5FbCY3phVS4AXJ3nZhI909r0F+EZ31b4fsKqqNgNfBv6kW+d1wLer6r5u/u3d+34AeGeSeRN4vvHkxqyYsdsrH29V9ask5wHvBH7Tt+glwBu66fOBv+tb9u4kfwb8B+DVAF1r8CDgi8lvR3J48ghP+cIkfw08DdiZ3ncGRvMc4Paq+n/d/HLgRHpvYui9+ACu7avvNqOqVidZRK8VOtZts1+pqi3Aj4e1JC+gF3I30+suO6UrnwOckWQJsBn4vQlU7UB6XWU/6H5fOwE/nMD2j6sxzuOuwPIki+kNGTKn22ZLkmOA1cCnq+oHXfnPunN5cJK7gYeqaqi1uQD4Qtdy3Qm4fQLVfFX3c303vzO94P/uBPaxLbgGODe9LtmvVNWqrvwC4MPAJ+g1OM7r2+ad3Qcq9L7dvxjYONYTTSA3ZkUzQd/5OHAdvVbP1vTfT3p6VX0kyRuA85LsQ+8q5xddK2A0nwMOr6obujfhy8dYf6Txf/o92D1uZtv9vVwCfITesY7W0nmwb7r/uC8Avgn8M7C67wrq3cDd9FpdTwIeGGGfD/PoK9C5ffu/rKrG/GP6NmRr5/ED9FqXr+8+DL7Tt2wxcD/wu8P2NdR9czeP7mf+e+BjVXVJ18V16gj1+O05TS+ddurKA/xtVX16Qke1jamq73ZXIocC5yf5cFWdB/wA2KO7ujyIrvurO0+HAC+pql8n+Q6PvM6GbO11ON7cmBUtdd1QVZvoXc4e21d8JY/0Y76V3iXt8O2+TO+S/+iq+hVwe5I3Qe8N0Nfd0G8XYH3XWnhrX/l93bLhfgIsSvLsbv4oeoG3PTkX+KuqunEyG3ddWRvpdef0h9KuwPruKuAoet+mHm4dsCTJk5IspNetAPAj4KVD5zW9v5VM5IpgNmztPO7KI3+cPWaosOuO/AS9v2vM6+9XBy4CXsuju22G7+vordRjHfDibvowuisIelenbx/6W0eSPZPsPp4D25YkeRZwT1V9BjgHeBFA9b48tILeVfWlVTXUsNgV+HkX8s+ld7U43N3A7knmpfc3tj/u9jne3JgVTQV956P0Rp4b8k7gbUlW0wuRd21lu78C3pPe3SBvBY5NcgMw1M0w3P+m1796Gb0QH3IhcHL3R7B9hgq7F9Pb6F3a3QhsAc6axPHNmqoarKpPTHE3FwDPBS7uK/sUcHSSH9Hrtvm3Ebb7Ab3uhxvptYav6+q0gV4oXtD9jn/U7X+bNcp5/Dvgb5P8gEd/2J0OfKrr9jsWOG0oeKvqF/SO+e6q6u+eOZXea+17bH0Uxs8A/yXJ1cB/ojvvVfVN4B+BH3av1S8xcuNlW/dyYFWS64H/Ru/DcsgF9K4g+z8cvw7s2L2OPkDvvD5KVT1ELyuuAr7Go9/748mNWeE3YyWpcS226CVJfQx6SWqcQS9JjTPoJalxBr0kNc6g1xNORhndsFs+4VEzh48bI21LDHpJapxBryesJDunN6Lp0Kih/V9w2THJ8m70xi91oxyS5MVJ/rkbofAbQ6MgStsyg15PZA8Ar+9GvXwF8NE8MiLVc4Czu1FPfwWc0A138ffAG7sRCs8FPjgL9ZYmZFsdPEt6PAT4m27gqy3AnsDQaJt3Do0SCfwfekNpfB14IXBZ93mwA7D+ca2xNAkGvZ7I3grMB15cVQ8lWccjoxEOHxuk6H0w3FxVL3n8qihNnV03eiLbld7ohg8leQXwrL5leyUZCvQj6Y16egswf6g8yZwkL3hcayxNgkGvJ7LPAwNJVtJr3fePRLiG3oiaq4FnAGdW1b/T+z+3H+pGKFxFbzxzaZvm6JWS1Dhb9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG/X9lWUtdgVSS0QAAAABJRU5ErkJggg==\n",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "count = tokenized_df.groupby(by=\"label\").count().reset_index()\n",
                "num2label = {0: \"NoRelation\",\n",
                "             1: \"MinValue\",\n",
                "             2: \"MaxValue\",\n",
                "             3: \"IsValue\"}\n",
                "count[\"label\"] = count[\"label\"].apply(lambda x: num2label[x])\n",
                "bar = count.plot(kind=\"bar\",x=\"label\", y=\"Text\",rot=0)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc = nlp(\"The mean wind speed measured at a height of at least 1 m above the ground shall be less than 6 m/s with gusts not exceeding 10 m/s.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The mean wind speed measured at a height of at least \n",
                            "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
                            "    1 m\n",
                            "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QuantitativeValue</span>\n",
                            "</mark>\n",
                            " above the ground shall be less than \n",
                            "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
                            "    6 m/s\n",
                            "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QuantitativeValue</span>\n",
                            "</mark>\n",
                            " with gusts not exceeding \n",
                            "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
                            "    10 m/s\n",
                            "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QuantitativeValue</span>\n",
                            "</mark>\n",
                            ".</div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "displacy.render(doc,style='ent')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
                "#bert_model = BertModel.from_pretrained(\"bert-base-cased\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "def bert_token_pre(dataframe, index, output = \"all\"):\n",
                "    \"\"\"\n",
                "    output: \"all\"- output whole sentence\n",
                "    output: \"sub\" - output separately \n",
                "    \"\"\"\n",
                "    end = max(dataframe.loc[index, \"Quant_Token\"][1],dataframe.loc[index, \"target_Token\"][1])\n",
                "    start = min(dataframe.loc[index, \"Quant_Token\"][1],dataframe.loc[index, \"target_Token\"][1])\n",
                "    span_before = \" \".join([t.text for t in dataframe.loc[index,\"Tokens\"][:start-1]])\n",
                "    span_current = \" \".join([t.text for t in dataframe.loc[index, \"Tokens\"][start:end+1]])\n",
                "    span_after = \" \".join([t.text for t in dataframe.loc[index, \"Tokens\"][end+1:]])\n",
                "    ber_tok_before = tokenizer.tokenize(span_before)\n",
                "    ber_tok_span = tokenizer.tokenize(span_current)\n",
                "    ber_tok_after = tokenizer.tokenize(span_after)\n",
                "    ber_tok_all = ber_tok_before + ber_tok_span + ber_tok_after\n",
                "    if output == \"all\":\n",
                "        return ber_tok_all\n",
                "    elif output == \"sub\":\n",
                "        return ber_tok_before, ber_tok_span, ber_tok_after"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {},
            "source": [
                "whole_sent = bert_token_pre(tokenized_df, 0, output = \"all\")\n",
                "bf, main, af = bert_token_pre(tokenized_df,0,output = \"sub\")\n",
                "whole_sent[len(bf):-len(af)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# well let's first get out all the bert embedding\n",
                "tokenized_df_bert = tokenized_df[tokenized_df.Sent_Span!=None]\n",
                "tokenized_df_bert = tokenized_df_bert[tokenized_df_bert.Quant_Token != (None,None)]\n",
                "tokenized_df_bert = tokenized_df_bert[tokenized_df_bert.target_Token!=(None,None)]\n",
                "tokenized_df_bert = tokenized_df_bert.reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1129"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(tokenized_df_bert)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "MAXTEXTSPAN=max(tokenized_df_bert[\"Sent_Span\"].apply(lambda x: len(x)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "#tokenizer.encode_plus(tokenized_df.loc[0,\"Text\"],)\n",
                "def padding(tokenized_list, max_length):\n",
                "    if len(tokenized_list) < max_length:\n",
                "        tokens = [\"[CLS]\"] + tokenized_list + [\"[SEP]\"] + (max_length - len(tokenized_list))*[\"[PAD]\"]\n",
                "    else:\n",
                "        tokens = [\"[CLS]\"] + tokenized_list + [\"[SEP]\"]\n",
                "    return tokens\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "201"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 1. add [CLS] [SEP] tokens\n",
                "def output_maxlen(dataframe):\n",
                "    maxlen = 0\n",
                "    maxlen = max([len(tokenizer.tokenize(text)) for text in dataframe[\"Text\"]])\n",
                "    return maxlen\n",
                "MAX_LEN = output_maxlen(tokenized_df)\n",
                "MAX_LEN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = BertModel.from_pretrained(\"bert-base-cased\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prepare for input_id\n",
                "def get_hidden_state(dataframe):\n",
                "    input_ids = []\n",
                "    attention_masks = []\n",
                "    for index in range(len(dataframe)):\n",
                "        tokenized_list = bert_token_pre(dataframe, index, output = \"all\")\n",
                "        padded = padding(tokenized_list, output_maxlen(dataframe))\n",
                "        attention_mask = [1 if t!=\"[PAD]\" else 0 for t in padded]\n",
                "        encoded = tokenizer.encode_plus(padded, add_special_tokens=False, pad_to_max_length=True,\n",
                "                                       is_pretokenized = True, return_tensors=\"pt\")\n",
                "        input_id = encoded[\"input_ids\"]\n",
                "        input_ids.append(input_id)\n",
                "        attention_masks.append(torch.tensor(attention_mask))\n",
                "    print(len(input_ids))\n",
                "    print(len(attention_masks))\n",
                "    input_ids = torch.cat(input_ids, dim=0)\n",
                "    ats = torch.cat(attention_masks, dim=0)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        last_hidden_states = model(input_ids=input_ids)[0].numpy()\n",
                "    return last_hidden_states\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_train_data(train_df, last_hidden_states_np):\n",
                "    length_bert_tokens = []\n",
                "    lstm_inputs = []\n",
                "    for i in range(len(train_df)):\n",
                "        bf, span, after = bert_token_pre(train_df, i, output = \"sub\")\n",
                "        all_bert_tokens = bert_token_pre(train_df, i, output = \"all\")\n",
                "        bert_index = (len(bf),len(after))\n",
                "        #print(bert_index)\n",
                "        length_bert_tokens.append(len(all_bert_tokens[len(bf):len(bf)+len(span)]))\n",
                "        bert_span_start = len(bf)+1\n",
                "        bert_span_end = len(bf)+len(span)\n",
                "        hidden_state = last_hidden_states_np[i,len(bf):len(bf)+len(span),:]\n",
                "        lstm_inputs.append(hidden_state)\n",
                "    padded = pad_sequences(lstm_inputs, maxlen=MAXTEXTSPAN, padding='post')\n",
                "    return padded\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_classes = len(set(tokenized_df_bert[\"label\"]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEN_LEN = MAXTEXTSPAN\n",
                "DIM = 768"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "52"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "SEN_LEN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"bertforRX\"\n",
                        "__________________________________________________________________________________________________\n",
                        "Layer (type)                    Output Shape         Param #     Connected to                     \n",
                        "==================================================================================================\n",
                        "input_1 (InputLayer)            (None, 52, 768)      0                                            \n",
                        "__________________________________________________________________________________________________\n",
                        "lstm_1 (LSTM)                   [(None, 52, 768), (N 4721664     input_1[0][0]                    \n",
                        "__________________________________________________________________________________________________\n",
                        "lstm_2 (LSTM)                   [(None, 768), (None, 4721664     lstm_1[0][0]                     \n",
                        "__________________________________________________________________________________________________\n",
                        "concatenate_1 (Concatenate)     (None, 1536)         0           lstm_1[0][1]                     \n",
                        "                                                                 lstm_2[0][1]                     \n",
                        "__________________________________________________________________________________________________\n",
                        "dense_1 (Dense)                 (None, 4)            6148        concatenate_1[0][0]              \n",
                        "==================================================================================================\n",
                        "Total params: 9,449,476\n",
                        "Trainable params: 9,449,476\n",
                        "Non-trainable params: 0\n",
                        "__________________________________________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "Bert_input = Input(shape=(SEN_LEN,DIM))\n",
                "X, X_lstm1, _ = LSTM(768, dropout=0.3, return_state=True, return_sequences=True)(Bert_input)\n",
                "X, X_lstm2, _ = LSTM(768, dropout=0.3, go_backwards=True, return_state=True)(X)\n",
                "X = Concatenate()([X_lstm1,X_lstm2])\n",
                "X= Dense(4, activation=\"softmax\")(X)\n",
                "\n",
                "general_model = Model(Bert_input,X, name=\"bertforRX\")\n",
                "general_model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.optimizers import Adam\n",
                "general_model.compile(Adam(5e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.utils import to_categorical\n",
                "from sklearn.model_selection import train_test_split\n",
                "num2label = {0:\"NoRelation\",\n",
                "             1:\"MinValue\",\n",
                "             2: \"MaxValue\",\n",
                "             3: \"IsValue\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(tokenized_df_bert.loc[:,~tokenized_df_bert.columns.isin([\"label\"])], tokenized_df_bert[\"label\"], test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## base model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train[\"span\"] = X_train[\"Sent_Span\"].apply(lambda x: [k.text for k in x])\n",
                "X_test[\"span\"] = X_test[\"Sent_Span\"].apply(lambda x:[k.text for k in x])\n",
                "X_train[\"pos\"] = X_train[\"Sent_Span\"].apply(lambda x: [k.pos_ for k in x])\n",
                "X_test[\"pos\"] = X_test[\"Sent_Span\"].apply(lambda x: [k.pos_ for k in x])\n",
                "X_train[\"dep\"] = X_train[\"Sent_Span\"].apply(lambda x: [k.dep_ for k in x])\n",
                "X_test[\"dep\"] = X_test[\"Sent_Span\"].apply(lambda x: [k.dep_ for k in x])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "for df in [X_train, X_test, y_train, y_test]:\n",
                "    df.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "features_stack_train, features_stack_test = bow_train_feature_stack(X_train, X_test, bow_paradict,\n",
                "                                                                    [\"span\",\"pos\", \"dep\"],bow=False)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
                        "  \"this warning.\", FutureWarning)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[40  5  5  8]\n",
                        " [ 4 27  9  0]\n",
                        " [ 2  7 53  0]\n",
                        " [17  1  0 48]]\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.63      0.69      0.66        58\n",
                        "           1       0.68      0.68      0.68        40\n",
                        "           2       0.79      0.85      0.82        62\n",
                        "           3       0.86      0.73      0.79        66\n",
                        "\n",
                        "   micro avg       0.74      0.74      0.74       226\n",
                        "   macro avg       0.74      0.74      0.74       226\n",
                        "weighted avg       0.75      0.74      0.74       226\n",
                        "\n",
                        "0.7433628318584071\n"
                    ]
                }
            ],
            "source": [
                "lr = LogisticRegression(random_state=45,solver=\"lbfgs\").fit(features_stack_train,y_train)\n",
                "y_pred=lr.predict(features_stack_test)\n",
                "print(confusion_matrix(y_test,y_pred))\n",
                "print(classification_report(y_test,y_pred))\n",
                "print(accuracy_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[43  5  5  5]\n",
                        " [ 3 28  9  0]\n",
                        " [ 2  7 53  0]\n",
                        " [14  1  1 50]]\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.69      0.74      0.72        58\n",
                        "           1       0.68      0.70      0.69        40\n",
                        "           2       0.78      0.85      0.82        62\n",
                        "           3       0.91      0.76      0.83        66\n",
                        "\n",
                        "   micro avg       0.77      0.77      0.77       226\n",
                        "   macro avg       0.77      0.76      0.76       226\n",
                        "weighted avg       0.78      0.77      0.77       226\n",
                        "\n",
                        "0.7699115044247787\n"
                    ]
                }
            ],
            "source": [
                "svclassifier = SVC(kernel='linear')\n",
                "svclassifier.fit(features_stack_train,y_train)\n",
                "y_pred = svclassifier.predict(features_stack_test)\n",
                "\n",
                "print(confusion_matrix(y_test,y_pred))\n",
                "print(classification_report(y_test,y_pred))\n",
                "print(accuracy_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## end of base model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "903\n",
                        "903\n",
                        "226\n",
                        "226\n"
                    ]
                }
            ],
            "source": [
                "# prepare train and test data\n",
                "train_last_hidden_states_np = get_hidden_state(X_train)\n",
                "X_train_input = generate_train_data(X_train, train_last_hidden_states_np)\n",
                "test_last_hidden_states_np = get_hidden_state(X_test)\n",
                "X_test_input = generate_train_data(X_test, test_last_hidden_states_np)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(903, 52, 768)"
                        ]
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train_input.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train on 903 samples, validate on 226 samples\n",
                        "Epoch 1/100\n",
                        "903/903 [==============================] - ETA: 1:15 - loss: 1.3654 - accuracy: 0.37 - ETA: 1:01 - loss: 1.3797 - accuracy: 0.31 - ETA: 56s - loss: 1.3832 - accuracy: 0.2917 - ETA: 53s - loss: 1.3896 - accuracy: 0.289 - ETA: 49s - loss: 1.3869 - accuracy: 0.287 - ETA: 47s - loss: 1.3845 - accuracy: 0.296 - ETA: 44s - loss: 1.3814 - accuracy: 0.312 - ETA: 42s - loss: 1.3827 - accuracy: 0.312 - ETA: 39s - loss: 1.3782 - accuracy: 0.333 - ETA: 37s - loss: 1.3754 - accuracy: 0.334 - ETA: 35s - loss: 1.3763 - accuracy: 0.329 - ETA: 33s - loss: 1.3741 - accuracy: 0.330 - ETA: 31s - loss: 1.3751 - accuracy: 0.322 - ETA: 28s - loss: 1.3770 - accuracy: 0.312 - ETA: 26s - loss: 1.3750 - accuracy: 0.316 - ETA: 24s - loss: 1.3738 - accuracy: 0.318 - ETA: 22s - loss: 1.3728 - accuracy: 0.321 - ETA: 20s - loss: 1.3712 - accuracy: 0.328 - ETA: 18s - loss: 1.3698 - accuracy: 0.335 - ETA: 16s - loss: 1.3666 - accuracy: 0.342 - ETA: 14s - loss: 1.3652 - accuracy: 0.345 - ETA: 12s - loss: 1.3645 - accuracy: 0.349 - ETA: 10s - loss: 1.3632 - accuracy: 0.350 - ETA: 8s - loss: 1.3608 - accuracy: 0.354 - ETA: 6s - loss: 1.3594 - accuracy: 0.35 - ETA: 4s - loss: 1.3585 - accuracy: 0.36 - ETA: 2s - loss: 1.3563 - accuracy: 0.36 - ETA: 0s - loss: 1.3533 - accuracy: 0.37 - 61s 68ms/step - loss: 1.3532 - accuracy: 0.3732 - val_loss: 1.3188 - val_accuracy: 0.4292\n",
                        "Epoch 2/100\n",
                        "903/903 [==============================] - ETA: 55s - loss: 1.3200 - accuracy: 0.437 - ETA: 53s - loss: 1.3209 - accuracy: 0.453 - ETA: 52s - loss: 1.3252 - accuracy: 0.458 - ETA: 50s - loss: 1.3266 - accuracy: 0.460 - ETA: 48s - loss: 1.3245 - accuracy: 0.443 - ETA: 46s - loss: 1.3249 - accuracy: 0.442 - ETA: 44s - loss: 1.3164 - accuracy: 0.446 - ETA: 42s - loss: 1.3118 - accuracy: 0.449 - ETA: 40s - loss: 1.3022 - accuracy: 0.465 - ETA: 38s - loss: 1.3016 - accuracy: 0.459 - ETA: 36s - loss: 1.2998 - accuracy: 0.463 - ETA: 34s - loss: 1.3008 - accuracy: 0.460 - ETA: 32s - loss: 1.2958 - accuracy: 0.459 - ETA: 30s - loss: 1.2972 - accuracy: 0.453 - ETA: 28s - loss: 1.2905 - accuracy: 0.464 - ETA: 26s - loss: 1.2894 - accuracy: 0.466 - ETA: 24s - loss: 1.2868 - accuracy: 0.466 - ETA: 22s - loss: 1.2853 - accuracy: 0.468 - ETA: 20s - loss: 1.2837 - accuracy: 0.467 - ETA: 18s - loss: 1.2834 - accuracy: 0.460 - ETA: 15s - loss: 1.2759 - accuracy: 0.470 - ETA: 13s - loss: 1.2737 - accuracy: 0.473 - ETA: 11s - loss: 1.2685 - accuracy: 0.481 - ETA: 9s - loss: 1.2644 - accuracy: 0.488 - ETA: 7s - loss: 1.2625 - accuracy: 0.49 - ETA: 4s - loss: 1.2598 - accuracy: 0.48 - ETA: 2s - loss: 1.2557 - accuracy: 0.49 - ETA: 0s - loss: 1.2493 - accuracy: 0.49 - 66s 73ms/step - loss: 1.2476 - accuracy: 0.4994 - val_loss: 1.1818 - val_accuracy: 0.4690\n",
                        "Epoch 3/100\n",
                        "903/903 [==============================] - ETA: 57s - loss: 1.1079 - accuracy: 0.625 - ETA: 54s - loss: 1.1152 - accuracy: 0.546 - ETA: 52s - loss: 1.1399 - accuracy: 0.500 - ETA: 50s - loss: 1.1247 - accuracy: 0.515 - ETA: 49s - loss: 1.1263 - accuracy: 0.543 - ETA: 47s - loss: 1.1233 - accuracy: 0.552 - ETA: 46s - loss: 1.1273 - accuracy: 0.540 - ETA: 44s - loss: 1.1188 - accuracy: 0.546 - ETA: 42s - loss: 1.1096 - accuracy: 0.555 - ETA: 40s - loss: 1.0944 - accuracy: 0.571 - ETA: 37s - loss: 1.0992 - accuracy: 0.568 - ETA: 35s - loss: 1.0964 - accuracy: 0.567 - ETA: 33s - loss: 1.0908 - accuracy: 0.564 - ETA: 31s - loss: 1.0891 - accuracy: 0.564 - ETA: 29s - loss: 1.0823 - accuracy: 0.562 - ETA: 27s - loss: 1.0785 - accuracy: 0.562 - ETA: 25s - loss: 1.0692 - accuracy: 0.566 - ETA: 22s - loss: 1.0744 - accuracy: 0.562 - ETA: 20s - loss: 1.0743 - accuracy: 0.564 - ETA: 18s - loss: 1.0713 - accuracy: 0.564 - ETA: 16s - loss: 1.0804 - accuracy: 0.562 - ETA: 13s - loss: 1.0766 - accuracy: 0.565 - ETA: 11s - loss: 1.0705 - accuracy: 0.569 - ETA: 9s - loss: 1.0631 - accuracy: 0.571 - ETA: 7s - loss: 1.0522 - accuracy: 0.57 - ETA: 5s - loss: 1.0485 - accuracy: 0.57 - ETA: 2s - loss: 1.0444 - accuracy: 0.58 - ETA: 0s - loss: 1.0429 - accuracy: 0.58 - 68s 75ms/step - loss: 1.0397 - accuracy: 0.5847 - val_loss: 0.9828 - val_accuracy: 0.5796\n",
                        "Epoch 4/100\n",
                        "903/903 [==============================] - ETA: 56s - loss: 1.0614 - accuracy: 0.531 - ETA: 54s - loss: 1.0089 - accuracy: 0.578 - ETA: 52s - loss: 1.0071 - accuracy: 0.562 - ETA: 51s - loss: 0.9253 - accuracy: 0.601 - ETA: 49s - loss: 0.9386 - accuracy: 0.587 - ETA: 47s - loss: 0.9315 - accuracy: 0.593 - ETA: 45s - loss: 0.9305 - accuracy: 0.598 - ETA: 43s - loss: 0.9633 - accuracy: 0.601 - ETA: 41s - loss: 0.9499 - accuracy: 0.607 - ETA: 39s - loss: 0.9547 - accuracy: 0.621 - ETA: 37s - loss: 0.9391 - accuracy: 0.622 - ETA: 35s - loss: 0.9430 - accuracy: 0.617 - ETA: 33s - loss: 0.9489 - accuracy: 0.617 - ETA: 31s - loss: 0.9404 - accuracy: 0.622 - ETA: 29s - loss: 0.9230 - accuracy: 0.631 - ETA: 27s - loss: 0.9095 - accuracy: 0.634 - ETA: 25s - loss: 0.9025 - accuracy: 0.634 - ETA: 22s - loss: 0.8935 - accuracy: 0.638 - ETA: 20s - loss: 0.8735 - accuracy: 0.644 - ETA: 18s - loss: 0.8690 - accuracy: 0.643 - ETA: 16s - loss: 0.8615 - accuracy: 0.648 - ETA: 13s - loss: 0.8573 - accuracy: 0.647 - ETA: 11s - loss: 0.8518 - accuracy: 0.652 - ETA: 9s - loss: 0.8430 - accuracy: 0.653 - ETA: 7s - loss: 0.8389 - accuracy: 0.65 - ETA: 4s - loss: 0.8436 - accuracy: 0.65 - ETA: 2s - loss: 0.8414 - accuracy: 0.65 - ETA: 0s - loss: 0.8346 - accuracy: 0.65 - 67s 75ms/step - loss: 0.8351 - accuracy: 0.6567 - val_loss: 0.9518 - val_accuracy: 0.6062\n",
                        "Epoch 5/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.8581 - accuracy: 0.71 - ETA: 1:01 - loss: 0.8576 - accuracy: 0.67 - ETA: 58s - loss: 0.8059 - accuracy: 0.6979 - ETA: 55s - loss: 0.8387 - accuracy: 0.656 - ETA: 53s - loss: 0.9519 - accuracy: 0.643 - ETA: 51s - loss: 0.9029 - accuracy: 0.661 - ETA: 48s - loss: 0.9411 - accuracy: 0.651 - ETA: 46s - loss: 0.9100 - accuracy: 0.660 - ETA: 43s - loss: 0.8756 - accuracy: 0.670 - ETA: 41s - loss: 0.8566 - accuracy: 0.671 - ETA: 39s - loss: 0.8472 - accuracy: 0.667 - ETA: 37s - loss: 0.8535 - accuracy: 0.669 - ETA: 34s - loss: 0.8417 - accuracy: 0.673 - ETA: 32s - loss: 0.8537 - accuracy: 0.662 - ETA: 30s - loss: 0.8675 - accuracy: 0.652 - ETA: 27s - loss: 0.8607 - accuracy: 0.648 - ETA: 25s - loss: 0.8573 - accuracy: 0.654 - ETA: 23s - loss: 0.8594 - accuracy: 0.652 - ETA: 20s - loss: 0.8633 - accuracy: 0.656 - ETA: 18s - loss: 0.8637 - accuracy: 0.653 - ETA: 16s - loss: 0.8599 - accuracy: 0.656 - ETA: 14s - loss: 0.8628 - accuracy: 0.654 - ETA: 11s - loss: 0.8579 - accuracy: 0.661 - ETA: 9s - loss: 0.8529 - accuracy: 0.666 - ETA: 7s - loss: 0.8575 - accuracy: 0.66 - ETA: 5s - loss: 0.8449 - accuracy: 0.66 - ETA: 2s - loss: 0.8431 - accuracy: 0.67 - ETA: 0s - loss: 0.8387 - accuracy: 0.67 - 70s 78ms/step - loss: 0.8387 - accuracy: 0.6733 - val_loss: 0.7842 - val_accuracy: 0.6637\n",
                        "Epoch 6/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.8688 - accuracy: 0.62 - ETA: 1:00 - loss: 0.7658 - accuracy: 0.68 - ETA: 58s - loss: 0.7984 - accuracy: 0.6771 - ETA: 56s - loss: 0.7629 - accuracy: 0.671 - ETA: 53s - loss: 0.7677 - accuracy: 0.668 - ETA: 51s - loss: 0.7307 - accuracy: 0.682 - ETA: 48s - loss: 0.7621 - accuracy: 0.656 - ETA: 46s - loss: 0.7648 - accuracy: 0.668 - ETA: 44s - loss: 0.7472 - accuracy: 0.677 - ETA: 41s - loss: 0.7250 - accuracy: 0.690 - ETA: 39s - loss: 0.7188 - accuracy: 0.690 - ETA: 37s - loss: 0.7218 - accuracy: 0.692 - ETA: 34s - loss: 0.7308 - accuracy: 0.687 - ETA: 32s - loss: 0.7328 - accuracy: 0.685 - ETA: 30s - loss: 0.7387 - accuracy: 0.681 - ETA: 27s - loss: 0.7304 - accuracy: 0.687 - ETA: 25s - loss: 0.7234 - accuracy: 0.689 - ETA: 22s - loss: 0.7238 - accuracy: 0.692 - ETA: 20s - loss: 0.7141 - accuracy: 0.699 - ETA: 18s - loss: 0.7162 - accuracy: 0.703 - ETA: 16s - loss: 0.7098 - accuracy: 0.709 - ETA: 13s - loss: 0.7064 - accuracy: 0.715 - ETA: 11s - loss: 0.7058 - accuracy: 0.718 - ETA: 9s - loss: 0.6976 - accuracy: 0.724 - ETA: 7s - loss: 0.6915 - accuracy: 0.72 - ETA: 4s - loss: 0.6835 - accuracy: 0.73 - ETA: 2s - loss: 0.6836 - accuracy: 0.73 - ETA: 0s - loss: 0.6803 - accuracy: 0.72 - 67s 74ms/step - loss: 0.6786 - accuracy: 0.7298 - val_loss: 0.7630 - val_accuracy: 0.7035\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7/100\n",
                        "903/903 [==============================] - ETA: 56s - loss: 0.6206 - accuracy: 0.812 - ETA: 54s - loss: 0.6820 - accuracy: 0.734 - ETA: 52s - loss: 0.6129 - accuracy: 0.750 - ETA: 50s - loss: 0.6184 - accuracy: 0.757 - ETA: 48s - loss: 0.5862 - accuracy: 0.768 - ETA: 46s - loss: 0.5837 - accuracy: 0.760 - ETA: 44s - loss: 0.5955 - accuracy: 0.750 - ETA: 42s - loss: 0.5935 - accuracy: 0.746 - ETA: 40s - loss: 0.6197 - accuracy: 0.743 - ETA: 38s - loss: 0.6389 - accuracy: 0.731 - ETA: 36s - loss: 0.6495 - accuracy: 0.727 - ETA: 34s - loss: 0.6619 - accuracy: 0.726 - ETA: 32s - loss: 0.6598 - accuracy: 0.735 - ETA: 30s - loss: 0.6544 - accuracy: 0.743 - ETA: 27s - loss: 0.6506 - accuracy: 0.743 - ETA: 25s - loss: 0.6441 - accuracy: 0.748 - ETA: 23s - loss: 0.6427 - accuracy: 0.746 - ETA: 21s - loss: 0.6357 - accuracy: 0.748 - ETA: 19s - loss: 0.6345 - accuracy: 0.750 - ETA: 17s - loss: 0.6394 - accuracy: 0.748 - ETA: 15s - loss: 0.6387 - accuracy: 0.747 - ETA: 13s - loss: 0.6365 - accuracy: 0.752 - ETA: 10s - loss: 0.6245 - accuracy: 0.759 - ETA: 8s - loss: 0.6262 - accuracy: 0.757 - ETA: 6s - loss: 0.6175 - accuracy: 0.76 - ETA: 4s - loss: 0.6154 - accuracy: 0.76 - ETA: 2s - loss: 0.6138 - accuracy: 0.76 - ETA: 0s - loss: 0.6117 - accuracy: 0.76 - 63s 70ms/step - loss: 0.6150 - accuracy: 0.7630 - val_loss: 0.7691 - val_accuracy: 0.7080\n",
                        "Epoch 8/100\n",
                        "903/903 [==============================] - ETA: 59s - loss: 0.4996 - accuracy: 0.812 - ETA: 57s - loss: 0.5212 - accuracy: 0.796 - ETA: 55s - loss: 0.4078 - accuracy: 0.854 - ETA: 53s - loss: 0.4445 - accuracy: 0.820 - ETA: 51s - loss: 0.4375 - accuracy: 0.843 - ETA: 49s - loss: 0.4810 - accuracy: 0.828 - ETA: 47s - loss: 0.4710 - accuracy: 0.830 - ETA: 45s - loss: 0.4753 - accuracy: 0.832 - ETA: 42s - loss: 0.4778 - accuracy: 0.833 - ETA: 40s - loss: 0.4975 - accuracy: 0.831 - ETA: 38s - loss: 0.5245 - accuracy: 0.815 - ETA: 35s - loss: 0.5129 - accuracy: 0.825 - ETA: 33s - loss: 0.5250 - accuracy: 0.814 - ETA: 31s - loss: 0.5410 - accuracy: 0.812 - ETA: 28s - loss: 0.5402 - accuracy: 0.810 - ETA: 26s - loss: 0.5376 - accuracy: 0.810 - ETA: 24s - loss: 0.5277 - accuracy: 0.814 - ETA: 22s - loss: 0.5361 - accuracy: 0.814 - ETA: 20s - loss: 0.5324 - accuracy: 0.814 - ETA: 17s - loss: 0.5373 - accuracy: 0.812 - ETA: 15s - loss: 0.5346 - accuracy: 0.817 - ETA: 13s - loss: 0.5291 - accuracy: 0.818 - ETA: 11s - loss: 0.5274 - accuracy: 0.816 - ETA: 9s - loss: 0.5239 - accuracy: 0.816 - ETA: 6s - loss: 0.5288 - accuracy: 0.81 - ETA: 4s - loss: 0.5247 - accuracy: 0.81 - ETA: 2s - loss: 0.5246 - accuracy: 0.81 - ETA: 0s - loss: 0.5178 - accuracy: 0.81 - 65s 72ms/step - loss: 0.5211 - accuracy: 0.8173 - val_loss: 0.6723 - val_accuracy: 0.7257\n",
                        "Epoch 9/100\n",
                        "903/903 [==============================] - ETA: 59s - loss: 0.3813 - accuracy: 0.875 - ETA: 56s - loss: 0.4286 - accuracy: 0.843 - ETA: 54s - loss: 0.4636 - accuracy: 0.833 - ETA: 52s - loss: 0.4880 - accuracy: 0.828 - ETA: 50s - loss: 0.4950 - accuracy: 0.825 - ETA: 48s - loss: 0.4720 - accuracy: 0.828 - ETA: 46s - loss: 0.5162 - accuracy: 0.817 - ETA: 44s - loss: 0.5002 - accuracy: 0.820 - ETA: 41s - loss: 0.4735 - accuracy: 0.826 - ETA: 39s - loss: 0.4787 - accuracy: 0.818 - ETA: 37s - loss: 0.4627 - accuracy: 0.823 - ETA: 35s - loss: 0.4574 - accuracy: 0.828 - ETA: 33s - loss: 0.4538 - accuracy: 0.829 - ETA: 31s - loss: 0.4568 - accuracy: 0.828 - ETA: 28s - loss: 0.4655 - accuracy: 0.829 - ETA: 26s - loss: 0.4695 - accuracy: 0.826 - ETA: 24s - loss: 0.4690 - accuracy: 0.825 - ETA: 22s - loss: 0.4741 - accuracy: 0.826 - ETA: 20s - loss: 0.4726 - accuracy: 0.827 - ETA: 18s - loss: 0.4830 - accuracy: 0.820 - ETA: 15s - loss: 0.4818 - accuracy: 0.821 - ETA: 13s - loss: 0.4902 - accuracy: 0.821 - ETA: 11s - loss: 0.4857 - accuracy: 0.822 - ETA: 9s - loss: 0.4920 - accuracy: 0.819 - ETA: 7s - loss: 0.4888 - accuracy: 0.81 - ETA: 5s - loss: 0.4884 - accuracy: 0.81 - ETA: 2s - loss: 0.4864 - accuracy: 0.81 - ETA: 0s - loss: 0.4870 - accuracy: 0.81 - 68s 76ms/step - loss: 0.4870 - accuracy: 0.8195 - val_loss: 0.6270 - val_accuracy: 0.7566\n",
                        "Epoch 10/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.4020 - accuracy: 0.81 - ETA: 59s - loss: 0.4297 - accuracy: 0.8594 - ETA: 57s - loss: 0.4504 - accuracy: 0.822 - ETA: 54s - loss: 0.4692 - accuracy: 0.812 - ETA: 52s - loss: 0.4485 - accuracy: 0.825 - ETA: 49s - loss: 0.4566 - accuracy: 0.817 - ETA: 47s - loss: 0.4695 - accuracy: 0.821 - ETA: 45s - loss: 0.4763 - accuracy: 0.812 - ETA: 42s - loss: 0.4718 - accuracy: 0.809 - ETA: 40s - loss: 0.4743 - accuracy: 0.809 - ETA: 38s - loss: 0.4894 - accuracy: 0.804 - ETA: 36s - loss: 0.4665 - accuracy: 0.815 - ETA: 33s - loss: 0.4621 - accuracy: 0.817 - ETA: 31s - loss: 0.4553 - accuracy: 0.819 - ETA: 29s - loss: 0.4421 - accuracy: 0.825 - ETA: 27s - loss: 0.4284 - accuracy: 0.832 - ETA: 24s - loss: 0.4346 - accuracy: 0.830 - ETA: 22s - loss: 0.4310 - accuracy: 0.835 - ETA: 20s - loss: 0.4252 - accuracy: 0.835 - ETA: 18s - loss: 0.4183 - accuracy: 0.837 - ETA: 16s - loss: 0.4256 - accuracy: 0.834 - ETA: 13s - loss: 0.4199 - accuracy: 0.838 - ETA: 11s - loss: 0.4221 - accuracy: 0.839 - ETA: 9s - loss: 0.4217 - accuracy: 0.839 - ETA: 7s - loss: 0.4309 - accuracy: 0.83 - ETA: 4s - loss: 0.4212 - accuracy: 0.84 - ETA: 2s - loss: 0.4321 - accuracy: 0.83 - ETA: 0s - loss: 0.4296 - accuracy: 0.84 - 67s 74ms/step - loss: 0.4281 - accuracy: 0.8427 - val_loss: 0.7424 - val_accuracy: 0.7434\n",
                        "Epoch 11/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.4327 - accuracy: 0.87 - ETA: 57s - loss: 0.3635 - accuracy: 0.8906 - ETA: 55s - loss: 0.2979 - accuracy: 0.906 - ETA: 53s - loss: 0.2931 - accuracy: 0.898 - ETA: 51s - loss: 0.2794 - accuracy: 0.900 - ETA: 49s - loss: 0.3235 - accuracy: 0.890 - ETA: 47s - loss: 0.3256 - accuracy: 0.883 - ETA: 44s - loss: 0.3868 - accuracy: 0.871 - ETA: 42s - loss: 0.3879 - accuracy: 0.864 - ETA: 40s - loss: 0.3999 - accuracy: 0.859 - ETA: 38s - loss: 0.4012 - accuracy: 0.863 - ETA: 36s - loss: 0.3896 - accuracy: 0.864 - ETA: 33s - loss: 0.4120 - accuracy: 0.855 - ETA: 31s - loss: 0.4154 - accuracy: 0.857 - ETA: 29s - loss: 0.4050 - accuracy: 0.862 - ETA: 27s - loss: 0.3975 - accuracy: 0.861 - ETA: 25s - loss: 0.4022 - accuracy: 0.858 - ETA: 23s - loss: 0.3960 - accuracy: 0.861 - ETA: 20s - loss: 0.3938 - accuracy: 0.860 - ETA: 18s - loss: 0.3869 - accuracy: 0.864 - ETA: 16s - loss: 0.3756 - accuracy: 0.869 - ETA: 14s - loss: 0.3757 - accuracy: 0.870 - ETA: 11s - loss: 0.3788 - accuracy: 0.869 - ETA: 9s - loss: 0.3788 - accuracy: 0.869 - ETA: 7s - loss: 0.3743 - accuracy: 0.87 - ETA: 5s - loss: 0.3771 - accuracy: 0.86 - ETA: 2s - loss: 0.3862 - accuracy: 0.86 - ETA: 0s - loss: 0.3960 - accuracy: 0.86 - 68s 76ms/step - loss: 0.3976 - accuracy: 0.8616 - val_loss: 0.7181 - val_accuracy: 0.7301\n",
                        "Epoch 12/100\n",
                        "903/903 [==============================] - ETA: 58s - loss: 0.4475 - accuracy: 0.875 - ETA: 55s - loss: 0.4539 - accuracy: 0.875 - ETA: 53s - loss: 0.4353 - accuracy: 0.875 - ETA: 51s - loss: 0.4839 - accuracy: 0.859 - ETA: 49s - loss: 0.5231 - accuracy: 0.843 - ETA: 47s - loss: 0.4845 - accuracy: 0.849 - ETA: 45s - loss: 0.4367 - accuracy: 0.866 - ETA: 43s - loss: 0.4606 - accuracy: 0.859 - ETA: 41s - loss: 0.4724 - accuracy: 0.850 - ETA: 39s - loss: 0.4695 - accuracy: 0.840 - ETA: 36s - loss: 0.4519 - accuracy: 0.849 - ETA: 34s - loss: 0.4571 - accuracy: 0.849 - ETA: 32s - loss: 0.4517 - accuracy: 0.846 - ETA: 30s - loss: 0.4382 - accuracy: 0.854 - ETA: 28s - loss: 0.4343 - accuracy: 0.856 - ETA: 26s - loss: 0.4308 - accuracy: 0.859 - ETA: 24s - loss: 0.4139 - accuracy: 0.867 - ETA: 22s - loss: 0.4029 - accuracy: 0.871 - ETA: 20s - loss: 0.4055 - accuracy: 0.871 - ETA: 18s - loss: 0.4002 - accuracy: 0.873 - ETA: 15s - loss: 0.4132 - accuracy: 0.864 - ETA: 13s - loss: 0.4136 - accuracy: 0.863 - ETA: 11s - loss: 0.4226 - accuracy: 0.860 - ETA: 9s - loss: 0.4267 - accuracy: 0.858 - ETA: 7s - loss: 0.4245 - accuracy: 0.85 - ETA: 4s - loss: 0.4255 - accuracy: 0.85 - ETA: 2s - loss: 0.4276 - accuracy: 0.85 - ETA: 0s - loss: 0.4218 - accuracy: 0.85 - 67s 75ms/step - loss: 0.4191 - accuracy: 0.8605 - val_loss: 0.6147 - val_accuracy: 0.7655\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 13/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.5044 - accuracy: 0.75 - ETA: 1:00 - loss: 0.3663 - accuracy: 0.84 - ETA: 59s - loss: 0.3599 - accuracy: 0.8542 - ETA: 57s - loss: 0.3749 - accuracy: 0.851 - ETA: 54s - loss: 0.3678 - accuracy: 0.856 - ETA: 52s - loss: 0.3856 - accuracy: 0.854 - ETA: 50s - loss: 0.3955 - accuracy: 0.848 - ETA: 47s - loss: 0.3912 - accuracy: 0.851 - ETA: 45s - loss: 0.4021 - accuracy: 0.843 - ETA: 43s - loss: 0.4053 - accuracy: 0.843 - ETA: 41s - loss: 0.4046 - accuracy: 0.843 - ETA: 38s - loss: 0.4033 - accuracy: 0.841 - ETA: 36s - loss: 0.4030 - accuracy: 0.846 - ETA: 34s - loss: 0.4007 - accuracy: 0.848 - ETA: 31s - loss: 0.3991 - accuracy: 0.852 - ETA: 29s - loss: 0.3917 - accuracy: 0.859 - ETA: 27s - loss: 0.3840 - accuracy: 0.864 - ETA: 24s - loss: 0.3868 - accuracy: 0.864 - ETA: 22s - loss: 0.3819 - accuracy: 0.868 - ETA: 20s - loss: 0.3707 - accuracy: 0.873 - ETA: 17s - loss: 0.3669 - accuracy: 0.875 - ETA: 15s - loss: 0.3688 - accuracy: 0.873 - ETA: 12s - loss: 0.3600 - accuracy: 0.877 - ETA: 10s - loss: 0.3571 - accuracy: 0.878 - ETA: 7s - loss: 0.3620 - accuracy: 0.877 - ETA: 5s - loss: 0.3596 - accuracy: 0.87 - ETA: 3s - loss: 0.3608 - accuracy: 0.87 - ETA: 0s - loss: 0.3558 - accuracy: 0.88 - 75s 83ms/step - loss: 0.3564 - accuracy: 0.8793 - val_loss: 0.6675 - val_accuracy: 0.7699\n",
                        "Epoch 14/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.4071 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3631 - accuracy: 0.90 - ETA: 1:00 - loss: 0.3422 - accuracy: 0.88 - ETA: 57s - loss: 0.3459 - accuracy: 0.8906 - ETA: 54s - loss: 0.3890 - accuracy: 0.887 - ETA: 52s - loss: 0.4161 - accuracy: 0.875 - ETA: 50s - loss: 0.4125 - accuracy: 0.870 - ETA: 47s - loss: 0.4460 - accuracy: 0.851 - ETA: 45s - loss: 0.4294 - accuracy: 0.854 - ETA: 42s - loss: 0.4064 - accuracy: 0.859 - ETA: 40s - loss: 0.4130 - accuracy: 0.860 - ETA: 38s - loss: 0.4011 - accuracy: 0.867 - ETA: 36s - loss: 0.4139 - accuracy: 0.863 - ETA: 33s - loss: 0.3999 - accuracy: 0.866 - ETA: 31s - loss: 0.3875 - accuracy: 0.870 - ETA: 28s - loss: 0.3835 - accuracy: 0.869 - ETA: 26s - loss: 0.3798 - accuracy: 0.871 - ETA: 24s - loss: 0.3782 - accuracy: 0.873 - ETA: 21s - loss: 0.3770 - accuracy: 0.871 - ETA: 19s - loss: 0.3691 - accuracy: 0.873 - ETA: 17s - loss: 0.3609 - accuracy: 0.878 - ETA: 14s - loss: 0.3557 - accuracy: 0.880 - ETA: 12s - loss: 0.3502 - accuracy: 0.880 - ETA: 10s - loss: 0.3575 - accuracy: 0.877 - ETA: 7s - loss: 0.3503 - accuracy: 0.881 - ETA: 5s - loss: 0.3437 - accuracy: 0.88 - ETA: 2s - loss: 0.3398 - accuracy: 0.88 - ETA: 0s - loss: 0.3391 - accuracy: 0.88 - 72s 80ms/step - loss: 0.3421 - accuracy: 0.8826 - val_loss: 0.7310 - val_accuracy: 0.7478\n",
                        "Epoch 15/100\n",
                        "903/903 [==============================] - ETA: 1:10 - loss: 0.3174 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2662 - accuracy: 0.92 - ETA: 1:04 - loss: 0.3715 - accuracy: 0.90 - ETA: 1:02 - loss: 0.4276 - accuracy: 0.89 - ETA: 1:00 - loss: 0.4390 - accuracy: 0.89 - ETA: 58s - loss: 0.4001 - accuracy: 0.9010 - ETA: 55s - loss: 0.3867 - accuracy: 0.906 - ETA: 52s - loss: 0.3782 - accuracy: 0.902 - ETA: 49s - loss: 0.3594 - accuracy: 0.906 - ETA: 46s - loss: 0.3517 - accuracy: 0.903 - ETA: 43s - loss: 0.3823 - accuracy: 0.894 - ETA: 40s - loss: 0.3846 - accuracy: 0.888 - ETA: 38s - loss: 0.3999 - accuracy: 0.884 - ETA: 35s - loss: 0.4113 - accuracy: 0.879 - ETA: 33s - loss: 0.4157 - accuracy: 0.872 - ETA: 30s - loss: 0.4065 - accuracy: 0.875 - ETA: 28s - loss: 0.4020 - accuracy: 0.876 - ETA: 25s - loss: 0.3978 - accuracy: 0.878 - ETA: 23s - loss: 0.3935 - accuracy: 0.881 - ETA: 20s - loss: 0.3875 - accuracy: 0.881 - ETA: 18s - loss: 0.3789 - accuracy: 0.883 - ETA: 15s - loss: 0.3796 - accuracy: 0.883 - ETA: 13s - loss: 0.3864 - accuracy: 0.880 - ETA: 10s - loss: 0.3940 - accuracy: 0.876 - ETA: 8s - loss: 0.3967 - accuracy: 0.873 - ETA: 5s - loss: 0.3915 - accuracy: 0.87 - ETA: 3s - loss: 0.3856 - accuracy: 0.87 - ETA: 0s - loss: 0.3896 - accuracy: 0.87 - 76s 85ms/step - loss: 0.3884 - accuracy: 0.8760 - val_loss: 0.6184 - val_accuracy: 0.7788\n",
                        "Epoch 16/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.2973 - accuracy: 0.90 - ETA: 1:05 - loss: 0.3549 - accuracy: 0.89 - ETA: 1:03 - loss: 0.3118 - accuracy: 0.89 - ETA: 1:01 - loss: 0.3399 - accuracy: 0.88 - ETA: 58s - loss: 0.3456 - accuracy: 0.8813 - ETA: 56s - loss: 0.3494 - accuracy: 0.869 - ETA: 53s - loss: 0.3157 - accuracy: 0.888 - ETA: 51s - loss: 0.3132 - accuracy: 0.886 - ETA: 48s - loss: 0.3214 - accuracy: 0.871 - ETA: 46s - loss: 0.3030 - accuracy: 0.881 - ETA: 43s - loss: 0.3079 - accuracy: 0.877 - ETA: 41s - loss: 0.3204 - accuracy: 0.877 - ETA: 38s - loss: 0.3290 - accuracy: 0.877 - ETA: 35s - loss: 0.3453 - accuracy: 0.872 - ETA: 33s - loss: 0.3432 - accuracy: 0.870 - ETA: 30s - loss: 0.3364 - accuracy: 0.873 - ETA: 28s - loss: 0.3309 - accuracy: 0.876 - ETA: 25s - loss: 0.3189 - accuracy: 0.881 - ETA: 23s - loss: 0.3079 - accuracy: 0.888 - ETA: 20s - loss: 0.3009 - accuracy: 0.889 - ETA: 18s - loss: 0.3022 - accuracy: 0.891 - ETA: 15s - loss: 0.3021 - accuracy: 0.892 - ETA: 13s - loss: 0.3000 - accuracy: 0.894 - ETA: 10s - loss: 0.3022 - accuracy: 0.891 - ETA: 8s - loss: 0.3017 - accuracy: 0.890 - ETA: 5s - loss: 0.3023 - accuracy: 0.89 - ETA: 3s - loss: 0.2983 - accuracy: 0.89 - ETA: 0s - loss: 0.2949 - accuracy: 0.89 - 75s 83ms/step - loss: 0.2928 - accuracy: 0.8970 - val_loss: 0.7649 - val_accuracy: 0.7434\n",
                        "Epoch 17/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.3442 - accuracy: 0.84 - ETA: 1:01 - loss: 0.2722 - accuracy: 0.89 - ETA: 58s - loss: 0.3301 - accuracy: 0.8854 - ETA: 55s - loss: 0.3508 - accuracy: 0.875 - ETA: 53s - loss: 0.3199 - accuracy: 0.887 - ETA: 51s - loss: 0.2845 - accuracy: 0.901 - ETA: 49s - loss: 0.2782 - accuracy: 0.897 - ETA: 46s - loss: 0.2668 - accuracy: 0.902 - ETA: 43s - loss: 0.2748 - accuracy: 0.899 - ETA: 41s - loss: 0.2772 - accuracy: 0.903 - ETA: 39s - loss: 0.2830 - accuracy: 0.903 - ETA: 36s - loss: 0.2911 - accuracy: 0.906 - ETA: 34s - loss: 0.2903 - accuracy: 0.901 - ETA: 32s - loss: 0.2764 - accuracy: 0.906 - ETA: 30s - loss: 0.2726 - accuracy: 0.906 - ETA: 28s - loss: 0.2872 - accuracy: 0.902 - ETA: 25s - loss: 0.2998 - accuracy: 0.898 - ETA: 23s - loss: 0.2960 - accuracy: 0.901 - ETA: 21s - loss: 0.2974 - accuracy: 0.898 - ETA: 18s - loss: 0.2929 - accuracy: 0.898 - ETA: 16s - loss: 0.2952 - accuracy: 0.897 - ETA: 14s - loss: 0.3066 - accuracy: 0.894 - ETA: 12s - loss: 0.3083 - accuracy: 0.892 - ETA: 9s - loss: 0.3193 - accuracy: 0.888 - ETA: 7s - loss: 0.3265 - accuracy: 0.88 - ETA: 5s - loss: 0.3287 - accuracy: 0.88 - ETA: 2s - loss: 0.3211 - accuracy: 0.88 - ETA: 0s - loss: 0.3138 - accuracy: 0.89 - 69s 77ms/step - loss: 0.3124 - accuracy: 0.8937 - val_loss: 0.6678 - val_accuracy: 0.7699\n",
                        "Epoch 18/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.2350 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3323 - accuracy: 0.85 - ETA: 57s - loss: 0.3363 - accuracy: 0.8750 - ETA: 55s - loss: 0.3251 - accuracy: 0.875 - ETA: 54s - loss: 0.3346 - accuracy: 0.875 - ETA: 51s - loss: 0.3186 - accuracy: 0.885 - ETA: 49s - loss: 0.3033 - accuracy: 0.883 - ETA: 47s - loss: 0.3184 - accuracy: 0.878 - ETA: 45s - loss: 0.2973 - accuracy: 0.888 - ETA: 42s - loss: 0.2933 - accuracy: 0.893 - ETA: 40s - loss: 0.2782 - accuracy: 0.900 - ETA: 38s - loss: 0.2756 - accuracy: 0.903 - ETA: 35s - loss: 0.2816 - accuracy: 0.901 - ETA: 33s - loss: 0.2859 - accuracy: 0.904 - ETA: 31s - loss: 0.2890 - accuracy: 0.902 - ETA: 28s - loss: 0.2812 - accuracy: 0.902 - ETA: 26s - loss: 0.2817 - accuracy: 0.904 - ETA: 23s - loss: 0.2719 - accuracy: 0.909 - ETA: 21s - loss: 0.2705 - accuracy: 0.907 - ETA: 19s - loss: 0.2789 - accuracy: 0.903 - ETA: 16s - loss: 0.2769 - accuracy: 0.906 - ETA: 14s - loss: 0.2757 - accuracy: 0.909 - ETA: 12s - loss: 0.2687 - accuracy: 0.911 - ETA: 9s - loss: 0.2633 - accuracy: 0.912 - ETA: 7s - loss: 0.2571 - accuracy: 0.91 - ETA: 5s - loss: 0.2613 - accuracy: 0.91 - ETA: 2s - loss: 0.2611 - accuracy: 0.91 - ETA: 0s - loss: 0.2644 - accuracy: 0.91 - 71s 78ms/step - loss: 0.2639 - accuracy: 0.9125 - val_loss: 0.7022 - val_accuracy: 0.7743\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.1629 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1266 - accuracy: 0.98 - ETA: 1:00 - loss: 0.2098 - accuracy: 0.95 - ETA: 58s - loss: 0.2410 - accuracy: 0.9297 - ETA: 56s - loss: 0.2794 - accuracy: 0.906 - ETA: 54s - loss: 0.2623 - accuracy: 0.911 - ETA: 51s - loss: 0.3021 - accuracy: 0.892 - ETA: 49s - loss: 0.3059 - accuracy: 0.890 - ETA: 46s - loss: 0.2913 - accuracy: 0.899 - ETA: 44s - loss: 0.2846 - accuracy: 0.896 - ETA: 41s - loss: 0.2791 - accuracy: 0.900 - ETA: 39s - loss: 0.2770 - accuracy: 0.903 - ETA: 36s - loss: 0.2968 - accuracy: 0.901 - ETA: 34s - loss: 0.2941 - accuracy: 0.901 - ETA: 31s - loss: 0.2889 - accuracy: 0.904 - ETA: 29s - loss: 0.2966 - accuracy: 0.900 - ETA: 26s - loss: 0.2856 - accuracy: 0.904 - ETA: 24s - loss: 0.2754 - accuracy: 0.908 - ETA: 21s - loss: 0.2725 - accuracy: 0.907 - ETA: 19s - loss: 0.2804 - accuracy: 0.904 - ETA: 17s - loss: 0.2719 - accuracy: 0.907 - ETA: 14s - loss: 0.2773 - accuracy: 0.906 - ETA: 12s - loss: 0.2770 - accuracy: 0.904 - ETA: 10s - loss: 0.2845 - accuracy: 0.902 - ETA: 7s - loss: 0.2857 - accuracy: 0.902 - ETA: 5s - loss: 0.2828 - accuracy: 0.90 - ETA: 2s - loss: 0.2811 - accuracy: 0.90 - ETA: 0s - loss: 0.2791 - accuracy: 0.90 - 71s 79ms/step - loss: 0.2832 - accuracy: 0.9037 - val_loss: 0.6707 - val_accuracy: 0.7788\n",
                        "Epoch 20/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.2594 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2896 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2408 - accuracy: 0.91 - ETA: 59s - loss: 0.2888 - accuracy: 0.8984 - ETA: 56s - loss: 0.3176 - accuracy: 0.881 - ETA: 53s - loss: 0.3395 - accuracy: 0.875 - ETA: 51s - loss: 0.3311 - accuracy: 0.879 - ETA: 48s - loss: 0.2951 - accuracy: 0.894 - ETA: 46s - loss: 0.2795 - accuracy: 0.899 - ETA: 43s - loss: 0.2848 - accuracy: 0.896 - ETA: 41s - loss: 0.2847 - accuracy: 0.897 - ETA: 39s - loss: 0.2856 - accuracy: 0.898 - ETA: 36s - loss: 0.2780 - accuracy: 0.901 - ETA: 34s - loss: 0.2746 - accuracy: 0.904 - ETA: 31s - loss: 0.2967 - accuracy: 0.893 - ETA: 29s - loss: 0.2957 - accuracy: 0.892 - ETA: 26s - loss: 0.2929 - accuracy: 0.893 - ETA: 24s - loss: 0.2858 - accuracy: 0.895 - ETA: 22s - loss: 0.2833 - accuracy: 0.898 - ETA: 19s - loss: 0.2756 - accuracy: 0.901 - ETA: 17s - loss: 0.2802 - accuracy: 0.900 - ETA: 15s - loss: 0.2741 - accuracy: 0.900 - ETA: 12s - loss: 0.2701 - accuracy: 0.903 - ETA: 10s - loss: 0.2801 - accuracy: 0.901 - ETA: 7s - loss: 0.2825 - accuracy: 0.898 - ETA: 5s - loss: 0.2860 - accuracy: 0.89 - ETA: 2s - loss: 0.2860 - accuracy: 0.89 - ETA: 0s - loss: 0.2841 - accuracy: 0.90 - 72s 80ms/step - loss: 0.2842 - accuracy: 0.8992 - val_loss: 0.6712 - val_accuracy: 0.7876\n",
                        "Epoch 21/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.3250 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3134 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2588 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2910 - accuracy: 0.89 - ETA: 58s - loss: 0.3088 - accuracy: 0.9000 - ETA: 55s - loss: 0.2938 - accuracy: 0.901 - ETA: 53s - loss: 0.2825 - accuracy: 0.897 - ETA: 50s - loss: 0.2809 - accuracy: 0.902 - ETA: 48s - loss: 0.2893 - accuracy: 0.902 - ETA: 45s - loss: 0.2892 - accuracy: 0.900 - ETA: 42s - loss: 0.2767 - accuracy: 0.906 - ETA: 40s - loss: 0.2773 - accuracy: 0.908 - ETA: 38s - loss: 0.2710 - accuracy: 0.906 - ETA: 35s - loss: 0.2715 - accuracy: 0.904 - ETA: 33s - loss: 0.2801 - accuracy: 0.902 - ETA: 31s - loss: 0.2768 - accuracy: 0.904 - ETA: 28s - loss: 0.2677 - accuracy: 0.908 - ETA: 26s - loss: 0.2575 - accuracy: 0.911 - ETA: 23s - loss: 0.2535 - accuracy: 0.914 - ETA: 21s - loss: 0.2507 - accuracy: 0.914 - ETA: 18s - loss: 0.2481 - accuracy: 0.913 - ETA: 15s - loss: 0.2463 - accuracy: 0.913 - ETA: 13s - loss: 0.2446 - accuracy: 0.911 - ETA: 10s - loss: 0.2465 - accuracy: 0.910 - ETA: 8s - loss: 0.2500 - accuracy: 0.911 - ETA: 5s - loss: 0.2461 - accuracy: 0.91 - ETA: 3s - loss: 0.2521 - accuracy: 0.91 - ETA: 0s - loss: 0.2480 - accuracy: 0.91 - 77s 85ms/step - loss: 0.2473 - accuracy: 0.9147 - val_loss: 0.6790 - val_accuracy: 0.7832\n",
                        "Epoch 22/100\n",
                        "903/903 [==============================] - ETA: 1:12 - loss: 0.0719 - accuracy: 1.00 - ETA: 1:09 - loss: 0.2826 - accuracy: 0.93 - ETA: 1:08 - loss: 0.3378 - accuracy: 0.91 - ETA: 1:05 - loss: 0.3292 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2766 - accuracy: 0.92 - ETA: 59s - loss: 0.2492 - accuracy: 0.9323 - ETA: 56s - loss: 0.2482 - accuracy: 0.924 - ETA: 53s - loss: 0.2385 - accuracy: 0.925 - ETA: 50s - loss: 0.2482 - accuracy: 0.923 - ETA: 47s - loss: 0.2275 - accuracy: 0.931 - ETA: 45s - loss: 0.2341 - accuracy: 0.929 - ETA: 42s - loss: 0.2451 - accuracy: 0.929 - ETA: 39s - loss: 0.2483 - accuracy: 0.927 - ETA: 37s - loss: 0.2442 - accuracy: 0.926 - ETA: 34s - loss: 0.2347 - accuracy: 0.931 - ETA: 31s - loss: 0.2335 - accuracy: 0.931 - ETA: 29s - loss: 0.2360 - accuracy: 0.928 - ETA: 26s - loss: 0.2306 - accuracy: 0.930 - ETA: 24s - loss: 0.2207 - accuracy: 0.934 - ETA: 21s - loss: 0.2319 - accuracy: 0.931 - ETA: 18s - loss: 0.2336 - accuracy: 0.931 - ETA: 16s - loss: 0.2367 - accuracy: 0.927 - ETA: 13s - loss: 0.2329 - accuracy: 0.929 - ETA: 10s - loss: 0.2316 - accuracy: 0.929 - ETA: 8s - loss: 0.2331 - accuracy: 0.928 - ETA: 5s - loss: 0.2525 - accuracy: 0.92 - ETA: 3s - loss: 0.2514 - accuracy: 0.92 - ETA: 0s - loss: 0.2500 - accuracy: 0.92 - 77s 86ms/step - loss: 0.2493 - accuracy: 0.9236 - val_loss: 0.7087 - val_accuracy: 0.7743\n",
                        "Epoch 23/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.3439 - accuracy: 0.90 - ETA: 1:05 - loss: 0.3092 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2673 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2189 - accuracy: 0.92 - ETA: 59s - loss: 0.1989 - accuracy: 0.9312 - ETA: 57s - loss: 0.2462 - accuracy: 0.906 - ETA: 54s - loss: 0.2448 - accuracy: 0.906 - ETA: 52s - loss: 0.2447 - accuracy: 0.906 - ETA: 49s - loss: 0.2677 - accuracy: 0.899 - ETA: 46s - loss: 0.2488 - accuracy: 0.909 - ETA: 44s - loss: 0.2456 - accuracy: 0.911 - ETA: 41s - loss: 0.2387 - accuracy: 0.916 - ETA: 39s - loss: 0.2310 - accuracy: 0.918 - ETA: 36s - loss: 0.2268 - accuracy: 0.919 - ETA: 33s - loss: 0.2429 - accuracy: 0.912 - ETA: 31s - loss: 0.2389 - accuracy: 0.912 - ETA: 28s - loss: 0.2439 - accuracy: 0.913 - ETA: 26s - loss: 0.2470 - accuracy: 0.914 - ETA: 23s - loss: 0.2405 - accuracy: 0.917 - ETA: 21s - loss: 0.2501 - accuracy: 0.914 - ETA: 18s - loss: 0.2592 - accuracy: 0.912 - ETA: 15s - loss: 0.2603 - accuracy: 0.911 - ETA: 13s - loss: 0.2542 - accuracy: 0.914 - ETA: 10s - loss: 0.2589 - accuracy: 0.912 - ETA: 8s - loss: 0.2568 - accuracy: 0.913 - ETA: 5s - loss: 0.2524 - accuracy: 0.91 - ETA: 3s - loss: 0.2494 - accuracy: 0.91 - ETA: 0s - loss: 0.2528 - accuracy: 0.91 - 76s 85ms/step - loss: 0.2512 - accuracy: 0.9169 - val_loss: 0.7330 - val_accuracy: 0.7876\n",
                        "Epoch 24/100\n",
                        "903/903 [==============================] - ETA: 1:09 - loss: 0.2355 - accuracy: 0.93 - ETA: 1:06 - loss: 0.2343 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1701 - accuracy: 0.93 - ETA: 58s - loss: 0.1636 - accuracy: 0.9438 - ETA: 56s - loss: 0.2063 - accuracy: 0.927 - ETA: 53s - loss: 0.2139 - accuracy: 0.924 - ETA: 51s - loss: 0.2114 - accuracy: 0.925 - ETA: 49s - loss: 0.1947 - accuracy: 0.934 - ETA: 46s - loss: 0.2168 - accuracy: 0.931 - ETA: 43s - loss: 0.2076 - accuracy: 0.934 - ETA: 41s - loss: 0.2108 - accuracy: 0.932 - ETA: 38s - loss: 0.2008 - accuracy: 0.935 - ETA: 36s - loss: 0.2058 - accuracy: 0.930 - ETA: 33s - loss: 0.2205 - accuracy: 0.925 - ETA: 31s - loss: 0.2186 - accuracy: 0.925 - ETA: 28s - loss: 0.2251 - accuracy: 0.922 - ETA: 25s - loss: 0.2337 - accuracy: 0.921 - ETA: 23s - loss: 0.2290 - accuracy: 0.922 - ETA: 20s - loss: 0.2285 - accuracy: 0.923 - ETA: 18s - loss: 0.2370 - accuracy: 0.919 - ETA: 15s - loss: 0.2380 - accuracy: 0.917 - ETA: 13s - loss: 0.2382 - accuracy: 0.915 - ETA: 10s - loss: 0.2374 - accuracy: 0.915 - ETA: 8s - loss: 0.2335 - accuracy: 0.917 - ETA: 5s - loss: 0.2435 - accuracy: 0.91 - ETA: 3s - loss: 0.2475 - accuracy: 0.91 - ETA: 0s - loss: 0.2458 - accuracy: 0.91 - 75s 83ms/step - loss: 0.2458 - accuracy: 0.9169 - val_loss: 0.7004 - val_accuracy: 0.7699\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 25/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.1662 - accuracy: 0.90 - ETA: 1:02 - loss: 0.1662 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1701 - accuracy: 0.92 - ETA: 58s - loss: 0.1609 - accuracy: 0.9375 - ETA: 55s - loss: 0.1463 - accuracy: 0.943 - ETA: 53s - loss: 0.2081 - accuracy: 0.927 - ETA: 51s - loss: 0.2524 - accuracy: 0.919 - ETA: 48s - loss: 0.2478 - accuracy: 0.921 - ETA: 46s - loss: 0.2318 - accuracy: 0.930 - ETA: 43s - loss: 0.2276 - accuracy: 0.934 - ETA: 40s - loss: 0.2117 - accuracy: 0.940 - ETA: 38s - loss: 0.2134 - accuracy: 0.937 - ETA: 36s - loss: 0.2121 - accuracy: 0.935 - ETA: 33s - loss: 0.2069 - accuracy: 0.933 - ETA: 31s - loss: 0.2062 - accuracy: 0.933 - ETA: 28s - loss: 0.2139 - accuracy: 0.929 - ETA: 26s - loss: 0.2082 - accuracy: 0.930 - ETA: 24s - loss: 0.2066 - accuracy: 0.930 - ETA: 21s - loss: 0.2049 - accuracy: 0.930 - ETA: 19s - loss: 0.2098 - accuracy: 0.928 - ETA: 17s - loss: 0.2165 - accuracy: 0.925 - ETA: 14s - loss: 0.2095 - accuracy: 0.929 - ETA: 12s - loss: 0.2183 - accuracy: 0.926 - ETA: 10s - loss: 0.2244 - accuracy: 0.925 - ETA: 7s - loss: 0.2251 - accuracy: 0.926 - ETA: 5s - loss: 0.2220 - accuracy: 0.92 - ETA: 2s - loss: 0.2184 - accuracy: 0.92 - ETA: 0s - loss: 0.2157 - accuracy: 0.92 - 71s 79ms/step - loss: 0.2191 - accuracy: 0.9280 - val_loss: 0.7672 - val_accuracy: 0.7566\n",
                        "Epoch 26/100\n",
                        "903/903 [==============================] - ETA: 1:10 - loss: 0.0582 - accuracy: 1.00 - ETA: 1:06 - loss: 0.0784 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0973 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1412 - accuracy: 0.95 - ETA: 57s - loss: 0.1517 - accuracy: 0.9427 - ETA: 54s - loss: 0.1653 - accuracy: 0.937 - ETA: 52s - loss: 0.1755 - accuracy: 0.937 - ETA: 49s - loss: 0.1675 - accuracy: 0.941 - ETA: 46s - loss: 0.1725 - accuracy: 0.940 - ETA: 43s - loss: 0.1849 - accuracy: 0.934 - ETA: 40s - loss: 0.1858 - accuracy: 0.937 - ETA: 38s - loss: 0.1914 - accuracy: 0.935 - ETA: 35s - loss: 0.1935 - accuracy: 0.933 - ETA: 32s - loss: 0.1883 - accuracy: 0.935 - ETA: 30s - loss: 0.1942 - accuracy: 0.933 - ETA: 28s - loss: 0.1869 - accuracy: 0.935 - ETA: 25s - loss: 0.1854 - accuracy: 0.937 - ETA: 22s - loss: 0.1861 - accuracy: 0.937 - ETA: 20s - loss: 0.1924 - accuracy: 0.932 - ETA: 17s - loss: 0.1851 - accuracy: 0.936 - ETA: 15s - loss: 0.1824 - accuracy: 0.936 - ETA: 12s - loss: 0.1804 - accuracy: 0.937 - ETA: 10s - loss: 0.1882 - accuracy: 0.937 - ETA: 7s - loss: 0.1847 - accuracy: 0.938 - ETA: 5s - loss: 0.1825 - accuracy: 0.93 - ETA: 3s - loss: 0.1860 - accuracy: 0.93 - ETA: 0s - loss: 0.1827 - accuracy: 0.93 - 75s 83ms/step - loss: 0.1829 - accuracy: 0.9391 - val_loss: 0.6577 - val_accuracy: 0.7876\n",
                        "Epoch 27/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.0789 - accuracy: 0.96 - ETA: 1:05 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0625 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0802 - accuracy: 0.97 - ETA: 57s - loss: 0.1096 - accuracy: 0.9688 - ETA: 55s - loss: 0.1288 - accuracy: 0.963 - ETA: 52s - loss: 0.1623 - accuracy: 0.950 - ETA: 50s - loss: 0.1543 - accuracy: 0.953 - ETA: 48s - loss: 0.1775 - accuracy: 0.944 - ETA: 45s - loss: 0.1963 - accuracy: 0.934 - ETA: 43s - loss: 0.2050 - accuracy: 0.931 - ETA: 40s - loss: 0.1961 - accuracy: 0.934 - ETA: 38s - loss: 0.1932 - accuracy: 0.932 - ETA: 35s - loss: 0.1912 - accuracy: 0.933 - ETA: 33s - loss: 0.1861 - accuracy: 0.935 - ETA: 30s - loss: 0.1967 - accuracy: 0.931 - ETA: 28s - loss: 0.1964 - accuracy: 0.932 - ETA: 25s - loss: 0.1950 - accuracy: 0.934 - ETA: 23s - loss: 0.1933 - accuracy: 0.934 - ETA: 20s - loss: 0.1939 - accuracy: 0.932 - ETA: 17s - loss: 0.1934 - accuracy: 0.933 - ETA: 15s - loss: 0.1893 - accuracy: 0.936 - ETA: 12s - loss: 0.1895 - accuracy: 0.936 - ETA: 10s - loss: 0.1864 - accuracy: 0.937 - ETA: 7s - loss: 0.1919 - accuracy: 0.933 - ETA: 5s - loss: 0.1927 - accuracy: 0.93 - ETA: 3s - loss: 0.1975 - accuracy: 0.93 - ETA: 0s - loss: 0.1940 - accuracy: 0.93 - 74s 82ms/step - loss: 0.1927 - accuracy: 0.9324 - val_loss: 0.7819 - val_accuracy: 0.7611\n",
                        "Epoch 28/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0968 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1474 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1841 - accuracy: 0.93 - ETA: 58s - loss: 0.1771 - accuracy: 0.9375 - ETA: 55s - loss: 0.1577 - accuracy: 0.950 - ETA: 53s - loss: 0.1650 - accuracy: 0.947 - ETA: 51s - loss: 0.2048 - accuracy: 0.928 - ETA: 48s - loss: 0.2116 - accuracy: 0.929 - ETA: 45s - loss: 0.2255 - accuracy: 0.923 - ETA: 43s - loss: 0.2104 - accuracy: 0.928 - ETA: 40s - loss: 0.2135 - accuracy: 0.929 - ETA: 38s - loss: 0.2007 - accuracy: 0.932 - ETA: 36s - loss: 0.2040 - accuracy: 0.932 - ETA: 33s - loss: 0.1925 - accuracy: 0.937 - ETA: 31s - loss: 0.1891 - accuracy: 0.937 - ETA: 29s - loss: 0.1911 - accuracy: 0.935 - ETA: 26s - loss: 0.1909 - accuracy: 0.935 - ETA: 24s - loss: 0.1818 - accuracy: 0.939 - ETA: 21s - loss: 0.1805 - accuracy: 0.937 - ETA: 19s - loss: 0.1750 - accuracy: 0.940 - ETA: 17s - loss: 0.1796 - accuracy: 0.940 - ETA: 14s - loss: 0.1797 - accuracy: 0.941 - ETA: 12s - loss: 0.1884 - accuracy: 0.937 - ETA: 10s - loss: 0.2034 - accuracy: 0.933 - ETA: 7s - loss: 0.2013 - accuracy: 0.935 - ETA: 5s - loss: 0.2024 - accuracy: 0.93 - ETA: 2s - loss: 0.2046 - accuracy: 0.93 - ETA: 0s - loss: 0.1991 - accuracy: 0.93 - 73s 81ms/step - loss: 0.1982 - accuracy: 0.9369 - val_loss: 0.7147 - val_accuracy: 0.7832\n",
                        "Epoch 29/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.1780 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1277 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1008 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1210 - accuracy: 0.96 - ETA: 58s - loss: 0.1580 - accuracy: 0.9438 - ETA: 57s - loss: 0.2339 - accuracy: 0.916 - ETA: 55s - loss: 0.2082 - accuracy: 0.924 - ETA: 52s - loss: 0.1895 - accuracy: 0.933 - ETA: 49s - loss: 0.1964 - accuracy: 0.930 - ETA: 47s - loss: 0.1934 - accuracy: 0.934 - ETA: 44s - loss: 0.1849 - accuracy: 0.937 - ETA: 41s - loss: 0.1866 - accuracy: 0.937 - ETA: 39s - loss: 0.1833 - accuracy: 0.937 - ETA: 36s - loss: 0.1804 - accuracy: 0.939 - ETA: 34s - loss: 0.1735 - accuracy: 0.943 - ETA: 31s - loss: 0.1666 - accuracy: 0.945 - ETA: 29s - loss: 0.1660 - accuracy: 0.944 - ETA: 26s - loss: 0.1681 - accuracy: 0.941 - ETA: 24s - loss: 0.1665 - accuracy: 0.942 - ETA: 21s - loss: 0.1659 - accuracy: 0.940 - ETA: 18s - loss: 0.1758 - accuracy: 0.934 - ETA: 16s - loss: 0.1786 - accuracy: 0.933 - ETA: 13s - loss: 0.1774 - accuracy: 0.933 - ETA: 10s - loss: 0.1731 - accuracy: 0.934 - ETA: 8s - loss: 0.1777 - accuracy: 0.933 - ETA: 5s - loss: 0.1741 - accuracy: 0.93 - ETA: 3s - loss: 0.1715 - accuracy: 0.93 - ETA: 0s - loss: 0.1733 - accuracy: 0.93 - 77s 85ms/step - loss: 0.1728 - accuracy: 0.9347 - val_loss: 0.7959 - val_accuracy: 0.7699\n",
                        "Epoch 30/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0612 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1358 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1585 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1279 - accuracy: 0.95 - ETA: 59s - loss: 0.1701 - accuracy: 0.9375 - ETA: 56s - loss: 0.1538 - accuracy: 0.942 - ETA: 53s - loss: 0.1605 - accuracy: 0.937 - ETA: 50s - loss: 0.1494 - accuracy: 0.945 - ETA: 47s - loss: 0.1462 - accuracy: 0.944 - ETA: 45s - loss: 0.1578 - accuracy: 0.940 - ETA: 42s - loss: 0.1590 - accuracy: 0.940 - ETA: 40s - loss: 0.1639 - accuracy: 0.942 - ETA: 37s - loss: 0.1573 - accuracy: 0.944 - ETA: 35s - loss: 0.1730 - accuracy: 0.944 - ETA: 32s - loss: 0.1641 - accuracy: 0.947 - ETA: 30s - loss: 0.1575 - accuracy: 0.949 - ETA: 27s - loss: 0.1568 - accuracy: 0.948 - ETA: 24s - loss: 0.1563 - accuracy: 0.947 - ETA: 22s - loss: 0.1568 - accuracy: 0.949 - ETA: 19s - loss: 0.1605 - accuracy: 0.948 - ETA: 17s - loss: 0.1547 - accuracy: 0.950 - ETA: 15s - loss: 0.1540 - accuracy: 0.951 - ETA: 12s - loss: 0.1617 - accuracy: 0.949 - ETA: 10s - loss: 0.1664 - accuracy: 0.946 - ETA: 7s - loss: 0.1646 - accuracy: 0.947 - ETA: 5s - loss: 0.1640 - accuracy: 0.94 - ETA: 2s - loss: 0.1629 - accuracy: 0.94 - ETA: 0s - loss: 0.1620 - accuracy: 0.94 - 71s 79ms/step - loss: 0.1622 - accuracy: 0.9457 - val_loss: 0.7677 - val_accuracy: 0.7832\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 31/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.1340 - accuracy: 0.96 - ETA: 58s - loss: 0.2067 - accuracy: 0.9531 - ETA: 56s - loss: 0.1929 - accuracy: 0.947 - ETA: 53s - loss: 0.2036 - accuracy: 0.929 - ETA: 51s - loss: 0.1949 - accuracy: 0.925 - ETA: 49s - loss: 0.2093 - accuracy: 0.916 - ETA: 47s - loss: 0.1884 - accuracy: 0.928 - ETA: 45s - loss: 0.1731 - accuracy: 0.937 - ETA: 43s - loss: 0.1838 - accuracy: 0.937 - ETA: 41s - loss: 0.1795 - accuracy: 0.940 - ETA: 39s - loss: 0.1670 - accuracy: 0.946 - ETA: 36s - loss: 0.1745 - accuracy: 0.942 - ETA: 34s - loss: 0.1636 - accuracy: 0.947 - ETA: 32s - loss: 0.1547 - accuracy: 0.950 - ETA: 30s - loss: 0.1539 - accuracy: 0.950 - ETA: 27s - loss: 0.1680 - accuracy: 0.945 - ETA: 25s - loss: 0.1715 - accuracy: 0.944 - ETA: 23s - loss: 0.1698 - accuracy: 0.944 - ETA: 21s - loss: 0.1714 - accuracy: 0.944 - ETA: 18s - loss: 0.1679 - accuracy: 0.943 - ETA: 16s - loss: 0.1710 - accuracy: 0.940 - ETA: 14s - loss: 0.1680 - accuracy: 0.940 - ETA: 11s - loss: 0.1618 - accuracy: 0.942 - ETA: 9s - loss: 0.1665 - accuracy: 0.942 - ETA: 7s - loss: 0.1628 - accuracy: 0.94 - ETA: 5s - loss: 0.1651 - accuracy: 0.94 - ETA: 2s - loss: 0.1652 - accuracy: 0.94 - ETA: 0s - loss: 0.1655 - accuracy: 0.93 - 68s 75ms/step - loss: 0.1671 - accuracy: 0.9391 - val_loss: 0.7349 - val_accuracy: 0.7832\n",
                        "Epoch 32/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.1014 - accuracy: 0.96 - ETA: 59s - loss: 0.0863 - accuracy: 0.9844 - ETA: 56s - loss: 0.1178 - accuracy: 0.968 - ETA: 53s - loss: 0.1746 - accuracy: 0.945 - ETA: 51s - loss: 0.1806 - accuracy: 0.950 - ETA: 49s - loss: 0.1556 - accuracy: 0.958 - ETA: 47s - loss: 0.1495 - accuracy: 0.955 - ETA: 45s - loss: 0.1535 - accuracy: 0.949 - ETA: 43s - loss: 0.1468 - accuracy: 0.951 - ETA: 40s - loss: 0.1515 - accuracy: 0.950 - ETA: 38s - loss: 0.1678 - accuracy: 0.943 - ETA: 36s - loss: 0.1687 - accuracy: 0.945 - ETA: 34s - loss: 0.1814 - accuracy: 0.942 - ETA: 32s - loss: 0.2057 - accuracy: 0.935 - ETA: 29s - loss: 0.1955 - accuracy: 0.939 - ETA: 27s - loss: 0.1923 - accuracy: 0.941 - ETA: 25s - loss: 0.1912 - accuracy: 0.943 - ETA: 23s - loss: 0.1908 - accuracy: 0.941 - ETA: 21s - loss: 0.1973 - accuracy: 0.935 - ETA: 18s - loss: 0.2030 - accuracy: 0.932 - ETA: 16s - loss: 0.2066 - accuracy: 0.930 - ETA: 14s - loss: 0.2098 - accuracy: 0.926 - ETA: 12s - loss: 0.2205 - accuracy: 0.923 - ETA: 9s - loss: 0.2153 - accuracy: 0.927 - ETA: 7s - loss: 0.2138 - accuracy: 0.92 - ETA: 5s - loss: 0.2313 - accuracy: 0.91 - ETA: 2s - loss: 0.2347 - accuracy: 0.91 - ETA: 0s - loss: 0.2430 - accuracy: 0.91 - 70s 78ms/step - loss: 0.2419 - accuracy: 0.9158 - val_loss: 0.6780 - val_accuracy: 0.7522\n",
                        "Epoch 33/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.1601 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1703 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1856 - accuracy: 0.94 - ETA: 59s - loss: 0.2184 - accuracy: 0.9375 - ETA: 56s - loss: 0.2283 - accuracy: 0.931 - ETA: 54s - loss: 0.2457 - accuracy: 0.921 - ETA: 51s - loss: 0.2632 - accuracy: 0.906 - ETA: 49s - loss: 0.2578 - accuracy: 0.906 - ETA: 46s - loss: 0.2801 - accuracy: 0.895 - ETA: 44s - loss: 0.2754 - accuracy: 0.890 - ETA: 41s - loss: 0.2883 - accuracy: 0.886 - ETA: 39s - loss: 0.2726 - accuracy: 0.895 - ETA: 36s - loss: 0.2639 - accuracy: 0.899 - ETA: 34s - loss: 0.2573 - accuracy: 0.901 - ETA: 32s - loss: 0.2542 - accuracy: 0.904 - ETA: 29s - loss: 0.2525 - accuracy: 0.904 - ETA: 27s - loss: 0.2477 - accuracy: 0.908 - ETA: 25s - loss: 0.2418 - accuracy: 0.911 - ETA: 22s - loss: 0.2399 - accuracy: 0.914 - ETA: 20s - loss: 0.2376 - accuracy: 0.917 - ETA: 17s - loss: 0.2329 - accuracy: 0.918 - ETA: 15s - loss: 0.2275 - accuracy: 0.921 - ETA: 12s - loss: 0.2264 - accuracy: 0.921 - ETA: 10s - loss: 0.2245 - accuracy: 0.923 - ETA: 7s - loss: 0.2182 - accuracy: 0.926 - ETA: 5s - loss: 0.2161 - accuracy: 0.92 - ETA: 2s - loss: 0.2129 - accuracy: 0.92 - ETA: 0s - loss: 0.2117 - accuracy: 0.92 - 74s 82ms/step - loss: 0.2110 - accuracy: 0.9302 - val_loss: 0.7069 - val_accuracy: 0.7788\n",
                        "Epoch 34/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.2474 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2182 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1642 - accuracy: 0.93 - ETA: 58s - loss: 0.1783 - accuracy: 0.9297 - ETA: 55s - loss: 0.1631 - accuracy: 0.937 - ETA: 53s - loss: 0.1490 - accuracy: 0.942 - ETA: 51s - loss: 0.1632 - accuracy: 0.937 - ETA: 48s - loss: 0.1476 - accuracy: 0.945 - ETA: 46s - loss: 0.1479 - accuracy: 0.944 - ETA: 43s - loss: 0.1454 - accuracy: 0.946 - ETA: 41s - loss: 0.1660 - accuracy: 0.940 - ETA: 38s - loss: 0.1600 - accuracy: 0.942 - ETA: 36s - loss: 0.1559 - accuracy: 0.944 - ETA: 34s - loss: 0.1502 - accuracy: 0.948 - ETA: 31s - loss: 0.1461 - accuracy: 0.950 - ETA: 29s - loss: 0.1395 - accuracy: 0.953 - ETA: 27s - loss: 0.1422 - accuracy: 0.952 - ETA: 24s - loss: 0.1442 - accuracy: 0.953 - ETA: 22s - loss: 0.1570 - accuracy: 0.950 - ETA: 19s - loss: 0.1577 - accuracy: 0.950 - ETA: 17s - loss: 0.1527 - accuracy: 0.952 - ETA: 15s - loss: 0.1498 - accuracy: 0.953 - ETA: 12s - loss: 0.1493 - accuracy: 0.952 - ETA: 10s - loss: 0.1511 - accuracy: 0.950 - ETA: 7s - loss: 0.1589 - accuracy: 0.946 - ETA: 5s - loss: 0.1689 - accuracy: 0.94 - ETA: 3s - loss: 0.1680 - accuracy: 0.94 - ETA: 0s - loss: 0.1651 - accuracy: 0.94 - 75s 83ms/step - loss: 0.1638 - accuracy: 0.9480 - val_loss: 0.7713 - val_accuracy: 0.7876\n",
                        "Epoch 35/100\n",
                        "903/903 [==============================] - ETA: 1:08 - loss: 0.0564 - accuracy: 1.00 - ETA: 1:04 - loss: 0.1257 - accuracy: 0.98 - ETA: 1:01 - loss: 0.1601 - accuracy: 0.95 - ETA: 58s - loss: 0.1779 - accuracy: 0.9453 - ETA: 55s - loss: 0.1643 - accuracy: 0.943 - ETA: 53s - loss: 0.1608 - accuracy: 0.947 - ETA: 50s - loss: 0.1442 - accuracy: 0.955 - ETA: 47s - loss: 0.1464 - accuracy: 0.957 - ETA: 45s - loss: 0.1373 - accuracy: 0.958 - ETA: 43s - loss: 0.1331 - accuracy: 0.956 - ETA: 40s - loss: 0.1474 - accuracy: 0.951 - ETA: 38s - loss: 0.1385 - accuracy: 0.955 - ETA: 35s - loss: 0.1394 - accuracy: 0.954 - ETA: 33s - loss: 0.1379 - accuracy: 0.950 - ETA: 31s - loss: 0.1316 - accuracy: 0.954 - ETA: 28s - loss: 0.1519 - accuracy: 0.949 - ETA: 26s - loss: 0.1569 - accuracy: 0.946 - ETA: 23s - loss: 0.1507 - accuracy: 0.949 - ETA: 21s - loss: 0.1494 - accuracy: 0.949 - ETA: 19s - loss: 0.1438 - accuracy: 0.951 - ETA: 16s - loss: 0.1381 - accuracy: 0.953 - ETA: 14s - loss: 0.1478 - accuracy: 0.951 - ETA: 12s - loss: 0.1519 - accuracy: 0.948 - ETA: 9s - loss: 0.1546 - accuracy: 0.947 - ETA: 7s - loss: 0.1659 - accuracy: 0.94 - ETA: 5s - loss: 0.1636 - accuracy: 0.94 - ETA: 2s - loss: 0.1657 - accuracy: 0.94 - ETA: 0s - loss: 0.1638 - accuracy: 0.94 - 69s 77ms/step - loss: 0.1627 - accuracy: 0.9480 - val_loss: 0.8445 - val_accuracy: 0.7699\n",
                        "Epoch 36/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.1269 - accuracy: 0.93 - ETA: 59s - loss: 0.1341 - accuracy: 0.9219 - ETA: 57s - loss: 0.1386 - accuracy: 0.927 - ETA: 55s - loss: 0.1296 - accuracy: 0.937 - ETA: 52s - loss: 0.1285 - accuracy: 0.937 - ETA: 50s - loss: 0.1588 - accuracy: 0.927 - ETA: 48s - loss: 0.1570 - accuracy: 0.933 - ETA: 46s - loss: 0.1577 - accuracy: 0.933 - ETA: 43s - loss: 0.1510 - accuracy: 0.937 - ETA: 41s - loss: 0.1569 - accuracy: 0.934 - ETA: 39s - loss: 0.1512 - accuracy: 0.937 - ETA: 37s - loss: 0.1515 - accuracy: 0.934 - ETA: 35s - loss: 0.1503 - accuracy: 0.937 - ETA: 32s - loss: 0.1484 - accuracy: 0.937 - ETA: 30s - loss: 0.1430 - accuracy: 0.939 - ETA: 28s - loss: 0.1453 - accuracy: 0.937 - ETA: 26s - loss: 0.1525 - accuracy: 0.935 - ETA: 23s - loss: 0.1463 - accuracy: 0.939 - ETA: 21s - loss: 0.1420 - accuracy: 0.940 - ETA: 19s - loss: 0.1483 - accuracy: 0.940 - ETA: 16s - loss: 0.1546 - accuracy: 0.940 - ETA: 14s - loss: 0.1539 - accuracy: 0.940 - ETA: 12s - loss: 0.1527 - accuracy: 0.941 - ETA: 9s - loss: 0.1512 - accuracy: 0.941 - ETA: 7s - loss: 0.1569 - accuracy: 0.93 - ETA: 5s - loss: 0.1549 - accuracy: 0.93 - ETA: 2s - loss: 0.1566 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.94 - 70s 77ms/step - loss: 0.1561 - accuracy: 0.9402 - val_loss: 0.8521 - val_accuracy: 0.7743\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 37/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.4334 - accuracy: 0.84 - ETA: 59s - loss: 0.2869 - accuracy: 0.8906 - ETA: 56s - loss: 0.2799 - accuracy: 0.885 - ETA: 54s - loss: 0.2405 - accuracy: 0.898 - ETA: 52s - loss: 0.2054 - accuracy: 0.918 - ETA: 50s - loss: 0.1862 - accuracy: 0.927 - ETA: 48s - loss: 0.1836 - accuracy: 0.933 - ETA: 45s - loss: 0.1784 - accuracy: 0.933 - ETA: 43s - loss: 0.1951 - accuracy: 0.930 - ETA: 41s - loss: 0.2121 - accuracy: 0.928 - ETA: 39s - loss: 0.2115 - accuracy: 0.926 - ETA: 36s - loss: 0.2016 - accuracy: 0.929 - ETA: 34s - loss: 0.1921 - accuracy: 0.932 - ETA: 32s - loss: 0.1875 - accuracy: 0.933 - ETA: 30s - loss: 0.1864 - accuracy: 0.931 - ETA: 27s - loss: 0.1795 - accuracy: 0.933 - ETA: 25s - loss: 0.1943 - accuracy: 0.932 - ETA: 23s - loss: 0.1877 - accuracy: 0.934 - ETA: 21s - loss: 0.1937 - accuracy: 0.932 - ETA: 18s - loss: 0.1875 - accuracy: 0.935 - ETA: 16s - loss: 0.1807 - accuracy: 0.939 - ETA: 14s - loss: 0.1772 - accuracy: 0.940 - ETA: 11s - loss: 0.1861 - accuracy: 0.937 - ETA: 9s - loss: 0.1822 - accuracy: 0.940 - ETA: 7s - loss: 0.1779 - accuracy: 0.94 - ETA: 5s - loss: 0.1779 - accuracy: 0.94 - ETA: 2s - loss: 0.1744 - accuracy: 0.94 - ETA: 0s - loss: 0.1786 - accuracy: 0.94 - 69s 77ms/step - loss: 0.1775 - accuracy: 0.9435 - val_loss: 0.6522 - val_accuracy: 0.8053\n",
                        "Epoch 38/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.3264 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2881 - accuracy: 0.90 - ETA: 1:00 - loss: 0.3348 - accuracy: 0.88 - ETA: 58s - loss: 0.3192 - accuracy: 0.8984 - ETA: 56s - loss: 0.3218 - accuracy: 0.900 - ETA: 54s - loss: 0.2984 - accuracy: 0.906 - ETA: 51s - loss: 0.2700 - accuracy: 0.915 - ETA: 49s - loss: 0.2712 - accuracy: 0.914 - ETA: 47s - loss: 0.2460 - accuracy: 0.923 - ETA: 44s - loss: 0.2293 - accuracy: 0.928 - ETA: 42s - loss: 0.2155 - accuracy: 0.934 - ETA: 39s - loss: 0.2291 - accuracy: 0.929 - ETA: 37s - loss: 0.2201 - accuracy: 0.932 - ETA: 34s - loss: 0.2125 - accuracy: 0.935 - ETA: 32s - loss: 0.2131 - accuracy: 0.933 - ETA: 29s - loss: 0.2033 - accuracy: 0.935 - ETA: 27s - loss: 0.1981 - accuracy: 0.935 - ETA: 24s - loss: 0.1949 - accuracy: 0.937 - ETA: 22s - loss: 0.1895 - accuracy: 0.939 - ETA: 19s - loss: 0.1924 - accuracy: 0.937 - ETA: 17s - loss: 0.1858 - accuracy: 0.940 - ETA: 15s - loss: 0.1828 - accuracy: 0.941 - ETA: 12s - loss: 0.1852 - accuracy: 0.940 - ETA: 10s - loss: 0.1819 - accuracy: 0.941 - ETA: 7s - loss: 0.1789 - accuracy: 0.942 - ETA: 5s - loss: 0.1787 - accuracy: 0.94 - ETA: 2s - loss: 0.1775 - accuracy: 0.94 - ETA: 0s - loss: 0.1770 - accuracy: 0.94 - 73s 80ms/step - loss: 0.1760 - accuracy: 0.9435 - val_loss: 0.7196 - val_accuracy: 0.7655\n",
                        "Epoch 39/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.2576 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2267 - accuracy: 0.90 - ETA: 1:00 - loss: 0.1680 - accuracy: 0.93 - ETA: 57s - loss: 0.1419 - accuracy: 0.9453 - ETA: 55s - loss: 0.1195 - accuracy: 0.956 - ETA: 52s - loss: 0.1105 - accuracy: 0.958 - ETA: 50s - loss: 0.1031 - accuracy: 0.964 - ETA: 48s - loss: 0.0942 - accuracy: 0.968 - ETA: 45s - loss: 0.1086 - accuracy: 0.965 - ETA: 43s - loss: 0.1156 - accuracy: 0.959 - ETA: 40s - loss: 0.1222 - accuracy: 0.957 - ETA: 38s - loss: 0.1230 - accuracy: 0.955 - ETA: 36s - loss: 0.1277 - accuracy: 0.956 - ETA: 33s - loss: 0.1267 - accuracy: 0.957 - ETA: 31s - loss: 0.1243 - accuracy: 0.956 - ETA: 29s - loss: 0.1192 - accuracy: 0.959 - ETA: 26s - loss: 0.1165 - accuracy: 0.959 - ETA: 24s - loss: 0.1280 - accuracy: 0.958 - ETA: 22s - loss: 0.1225 - accuracy: 0.960 - ETA: 19s - loss: 0.1237 - accuracy: 0.957 - ETA: 17s - loss: 0.1231 - accuracy: 0.958 - ETA: 14s - loss: 0.1198 - accuracy: 0.960 - ETA: 12s - loss: 0.1263 - accuracy: 0.959 - ETA: 10s - loss: 0.1411 - accuracy: 0.954 - ETA: 7s - loss: 0.1397 - accuracy: 0.955 - ETA: 5s - loss: 0.1403 - accuracy: 0.95 - ETA: 2s - loss: 0.1356 - accuracy: 0.95 - ETA: 0s - loss: 0.1409 - accuracy: 0.95 - 72s 80ms/step - loss: 0.1435 - accuracy: 0.9546 - val_loss: 0.8101 - val_accuracy: 0.7876\n",
                        "Epoch 40/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.0791 - accuracy: 0.96 - ETA: 59s - loss: 0.1637 - accuracy: 0.9531 - ETA: 57s - loss: 0.1302 - accuracy: 0.958 - ETA: 54s - loss: 0.1406 - accuracy: 0.945 - ETA: 52s - loss: 0.1439 - accuracy: 0.943 - ETA: 50s - loss: 0.1356 - accuracy: 0.947 - ETA: 47s - loss: 0.1729 - accuracy: 0.937 - ETA: 45s - loss: 0.1685 - accuracy: 0.941 - ETA: 43s - loss: 0.1586 - accuracy: 0.947 - ETA: 40s - loss: 0.1547 - accuracy: 0.946 - ETA: 38s - loss: 0.1587 - accuracy: 0.948 - ETA: 36s - loss: 0.1715 - accuracy: 0.945 - ETA: 34s - loss: 0.1622 - accuracy: 0.949 - ETA: 31s - loss: 0.1633 - accuracy: 0.950 - ETA: 29s - loss: 0.1673 - accuracy: 0.947 - ETA: 27s - loss: 0.1706 - accuracy: 0.945 - ETA: 25s - loss: 0.1633 - accuracy: 0.948 - ETA: 22s - loss: 0.1629 - accuracy: 0.947 - ETA: 20s - loss: 0.1555 - accuracy: 0.950 - ETA: 18s - loss: 0.1505 - accuracy: 0.951 - ETA: 16s - loss: 0.1490 - accuracy: 0.952 - ETA: 13s - loss: 0.1598 - accuracy: 0.948 - ETA: 11s - loss: 0.1704 - accuracy: 0.945 - ETA: 9s - loss: 0.1724 - accuracy: 0.945 - ETA: 7s - loss: 0.1688 - accuracy: 0.94 - ETA: 4s - loss: 0.1703 - accuracy: 0.94 - ETA: 2s - loss: 0.1695 - accuracy: 0.94 - ETA: 0s - loss: 0.1655 - accuracy: 0.94 - 67s 74ms/step - loss: 0.1643 - accuracy: 0.9502 - val_loss: 0.6993 - val_accuracy: 0.7965\n",
                        "Epoch 41/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.0288 - accuracy: 1.00 - ETA: 57s - loss: 0.0734 - accuracy: 0.9844 - ETA: 55s - loss: 0.0866 - accuracy: 0.968 - ETA: 53s - loss: 0.1010 - accuracy: 0.968 - ETA: 50s - loss: 0.1325 - accuracy: 0.956 - ETA: 48s - loss: 0.1389 - accuracy: 0.953 - ETA: 46s - loss: 0.1506 - accuracy: 0.946 - ETA: 44s - loss: 0.1554 - accuracy: 0.945 - ETA: 42s - loss: 0.1519 - accuracy: 0.947 - ETA: 39s - loss: 0.1562 - accuracy: 0.946 - ETA: 37s - loss: 0.1596 - accuracy: 0.943 - ETA: 35s - loss: 0.1651 - accuracy: 0.940 - ETA: 33s - loss: 0.1564 - accuracy: 0.942 - ETA: 30s - loss: 0.1608 - accuracy: 0.939 - ETA: 28s - loss: 0.1527 - accuracy: 0.943 - ETA: 26s - loss: 0.1464 - accuracy: 0.947 - ETA: 24s - loss: 0.1472 - accuracy: 0.946 - ETA: 22s - loss: 0.1483 - accuracy: 0.946 - ETA: 20s - loss: 0.1516 - accuracy: 0.944 - ETA: 18s - loss: 0.1492 - accuracy: 0.945 - ETA: 15s - loss: 0.1487 - accuracy: 0.944 - ETA: 13s - loss: 0.1561 - accuracy: 0.938 - ETA: 11s - loss: 0.1643 - accuracy: 0.936 - ETA: 9s - loss: 0.1623 - accuracy: 0.936 - ETA: 7s - loss: 0.1583 - accuracy: 0.93 - ETA: 4s - loss: 0.1542 - accuracy: 0.93 - ETA: 2s - loss: 0.1565 - accuracy: 0.93 - ETA: 0s - loss: 0.1554 - accuracy: 0.94 - 66s 73ms/step - loss: 0.1556 - accuracy: 0.9413 - val_loss: 0.9013 - val_accuracy: 0.7743\n",
                        "Epoch 42/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.0348 - accuracy: 1.00 - ETA: 58s - loss: 0.2116 - accuracy: 0.9531 - ETA: 56s - loss: 0.2827 - accuracy: 0.927 - ETA: 54s - loss: 0.2652 - accuracy: 0.929 - ETA: 51s - loss: 0.2393 - accuracy: 0.937 - ETA: 49s - loss: 0.2336 - accuracy: 0.937 - ETA: 47s - loss: 0.2361 - accuracy: 0.933 - ETA: 44s - loss: 0.2254 - accuracy: 0.933 - ETA: 42s - loss: 0.2084 - accuracy: 0.937 - ETA: 40s - loss: 0.2056 - accuracy: 0.937 - ETA: 38s - loss: 0.1885 - accuracy: 0.943 - ETA: 35s - loss: 0.1783 - accuracy: 0.945 - ETA: 33s - loss: 0.1739 - accuracy: 0.947 - ETA: 31s - loss: 0.1780 - accuracy: 0.937 - ETA: 29s - loss: 0.1726 - accuracy: 0.941 - ETA: 27s - loss: 0.1669 - accuracy: 0.943 - ETA: 24s - loss: 0.1609 - accuracy: 0.944 - ETA: 22s - loss: 0.1543 - accuracy: 0.947 - ETA: 20s - loss: 0.1575 - accuracy: 0.944 - ETA: 18s - loss: 0.1603 - accuracy: 0.943 - ETA: 16s - loss: 0.1555 - accuracy: 0.944 - ETA: 13s - loss: 0.1524 - accuracy: 0.946 - ETA: 11s - loss: 0.1586 - accuracy: 0.944 - ETA: 9s - loss: 0.1534 - accuracy: 0.946 - ETA: 7s - loss: 0.1498 - accuracy: 0.94 - ETA: 4s - loss: 0.1453 - accuracy: 0.95 - ETA: 2s - loss: 0.1410 - accuracy: 0.95 - ETA: 0s - loss: 0.1459 - accuracy: 0.94 - 67s 74ms/step - loss: 0.1448 - accuracy: 0.9491 - val_loss: 0.9347 - val_accuracy: 0.7699\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 43/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.2309 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1592 - accuracy: 0.95 - ETA: 58s - loss: 0.1458 - accuracy: 0.9583 - ETA: 55s - loss: 0.1459 - accuracy: 0.953 - ETA: 53s - loss: 0.1230 - accuracy: 0.962 - ETA: 51s - loss: 0.1151 - accuracy: 0.963 - ETA: 49s - loss: 0.1060 - accuracy: 0.968 - ETA: 46s - loss: 0.1030 - accuracy: 0.968 - ETA: 44s - loss: 0.1096 - accuracy: 0.968 - ETA: 42s - loss: 0.1075 - accuracy: 0.971 - ETA: 40s - loss: 0.1046 - accuracy: 0.971 - ETA: 38s - loss: 0.1014 - accuracy: 0.971 - ETA: 35s - loss: 0.1018 - accuracy: 0.971 - ETA: 33s - loss: 0.0993 - accuracy: 0.971 - ETA: 31s - loss: 0.1010 - accuracy: 0.970 - ETA: 28s - loss: 0.0975 - accuracy: 0.972 - ETA: 26s - loss: 0.1082 - accuracy: 0.968 - ETA: 24s - loss: 0.1111 - accuracy: 0.967 - ETA: 21s - loss: 0.1080 - accuracy: 0.968 - ETA: 19s - loss: 0.1043 - accuracy: 0.970 - ETA: 16s - loss: 0.1115 - accuracy: 0.968 - ETA: 14s - loss: 0.1120 - accuracy: 0.968 - ETA: 12s - loss: 0.1179 - accuracy: 0.967 - ETA: 9s - loss: 0.1142 - accuracy: 0.968 - ETA: 7s - loss: 0.1149 - accuracy: 0.96 - ETA: 5s - loss: 0.1116 - accuracy: 0.96 - ETA: 2s - loss: 0.1173 - accuracy: 0.96 - ETA: 0s - loss: 0.1160 - accuracy: 0.96 - 70s 78ms/step - loss: 0.1153 - accuracy: 0.9668 - val_loss: 0.9339 - val_accuracy: 0.7920\n",
                        "Epoch 44/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.1755 - accuracy: 0.90 - ETA: 1:01 - loss: 0.1682 - accuracy: 0.92 - ETA: 58s - loss: 0.2014 - accuracy: 0.8958 - ETA: 56s - loss: 0.1842 - accuracy: 0.898 - ETA: 54s - loss: 0.1775 - accuracy: 0.906 - ETA: 52s - loss: 0.1611 - accuracy: 0.916 - ETA: 49s - loss: 0.1409 - accuracy: 0.928 - ETA: 47s - loss: 0.1267 - accuracy: 0.937 - ETA: 45s - loss: 0.1181 - accuracy: 0.944 - ETA: 42s - loss: 0.1119 - accuracy: 0.950 - ETA: 40s - loss: 0.1218 - accuracy: 0.946 - ETA: 38s - loss: 0.1167 - accuracy: 0.947 - ETA: 36s - loss: 0.1244 - accuracy: 0.947 - ETA: 33s - loss: 0.1470 - accuracy: 0.944 - ETA: 31s - loss: 0.1506 - accuracy: 0.943 - ETA: 29s - loss: 0.1506 - accuracy: 0.943 - ETA: 26s - loss: 0.1641 - accuracy: 0.935 - ETA: 24s - loss: 0.1720 - accuracy: 0.937 - ETA: 21s - loss: 0.1730 - accuracy: 0.935 - ETA: 19s - loss: 0.1670 - accuracy: 0.939 - ETA: 17s - loss: 0.1683 - accuracy: 0.940 - ETA: 14s - loss: 0.1661 - accuracy: 0.940 - ETA: 12s - loss: 0.1611 - accuracy: 0.941 - ETA: 10s - loss: 0.1616 - accuracy: 0.940 - ETA: 7s - loss: 0.1644 - accuracy: 0.938 - ETA: 5s - loss: 0.1659 - accuracy: 0.93 - ETA: 2s - loss: 0.1637 - accuracy: 0.93 - ETA: 0s - loss: 0.1589 - accuracy: 0.94 - 74s 82ms/step - loss: 0.1579 - accuracy: 0.9413 - val_loss: 0.8106 - val_accuracy: 0.7832\n",
                        "Epoch 45/100\n",
                        "903/903 [==============================] - ETA: 1:10 - loss: 0.0298 - accuracy: 1.00 - ETA: 1:07 - loss: 0.1301 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1374 - accuracy: 0.94 - ETA: 1:02 - loss: 0.1587 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1582 - accuracy: 0.94 - ETA: 58s - loss: 0.1858 - accuracy: 0.9323 - ETA: 55s - loss: 0.1812 - accuracy: 0.933 - ETA: 52s - loss: 0.1603 - accuracy: 0.941 - ETA: 49s - loss: 0.1622 - accuracy: 0.941 - ETA: 46s - loss: 0.1607 - accuracy: 0.940 - ETA: 43s - loss: 0.1612 - accuracy: 0.943 - ETA: 40s - loss: 0.1604 - accuracy: 0.945 - ETA: 38s - loss: 0.1675 - accuracy: 0.939 - ETA: 35s - loss: 0.1746 - accuracy: 0.937 - ETA: 32s - loss: 0.1727 - accuracy: 0.937 - ETA: 30s - loss: 0.1717 - accuracy: 0.935 - ETA: 27s - loss: 0.1699 - accuracy: 0.937 - ETA: 24s - loss: 0.1670 - accuracy: 0.937 - ETA: 22s - loss: 0.1644 - accuracy: 0.939 - ETA: 19s - loss: 0.1580 - accuracy: 0.942 - ETA: 17s - loss: 0.1519 - accuracy: 0.944 - ETA: 15s - loss: 0.1475 - accuracy: 0.947 - ETA: 12s - loss: 0.1489 - accuracy: 0.948 - ETA: 10s - loss: 0.1511 - accuracy: 0.946 - ETA: 7s - loss: 0.1467 - accuracy: 0.948 - ETA: 5s - loss: 0.1431 - accuracy: 0.95 - ETA: 2s - loss: 0.1432 - accuracy: 0.95 - ETA: 0s - loss: 0.1463 - accuracy: 0.94 - 71s 79ms/step - loss: 0.1455 - accuracy: 0.9502 - val_loss: 0.7076 - val_accuracy: 0.8097\n",
                        "Epoch 46/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.0559 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0613 - accuracy: 1.00 - ETA: 58s - loss: 0.0716 - accuracy: 0.9896 - ETA: 55s - loss: 0.0647 - accuracy: 0.992 - ETA: 53s - loss: 0.0785 - accuracy: 0.981 - ETA: 51s - loss: 0.0759 - accuracy: 0.979 - ETA: 49s - loss: 0.0816 - accuracy: 0.977 - ETA: 46s - loss: 0.0817 - accuracy: 0.980 - ETA: 44s - loss: 0.0822 - accuracy: 0.975 - ETA: 42s - loss: 0.0956 - accuracy: 0.971 - ETA: 40s - loss: 0.0901 - accuracy: 0.974 - ETA: 37s - loss: 0.0922 - accuracy: 0.974 - ETA: 35s - loss: 0.0875 - accuracy: 0.976 - ETA: 33s - loss: 0.0844 - accuracy: 0.975 - ETA: 31s - loss: 0.0843 - accuracy: 0.975 - ETA: 28s - loss: 0.0897 - accuracy: 0.970 - ETA: 26s - loss: 0.0886 - accuracy: 0.970 - ETA: 23s - loss: 0.0897 - accuracy: 0.968 - ETA: 21s - loss: 0.0944 - accuracy: 0.963 - ETA: 19s - loss: 0.0980 - accuracy: 0.962 - ETA: 16s - loss: 0.0966 - accuracy: 0.962 - ETA: 14s - loss: 0.0990 - accuracy: 0.961 - ETA: 12s - loss: 0.0989 - accuracy: 0.962 - ETA: 9s - loss: 0.1035 - accuracy: 0.960 - ETA: 7s - loss: 0.1083 - accuracy: 0.95 - ETA: 5s - loss: 0.1091 - accuracy: 0.95 - ETA: 2s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 70s 78ms/step - loss: 0.1145 - accuracy: 0.9590 - val_loss: 0.8094 - val_accuracy: 0.7832\n",
                        "Epoch 47/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.0763 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0956 - accuracy: 0.95 - ETA: 57s - loss: 0.0948 - accuracy: 0.9688 - ETA: 56s - loss: 0.0963 - accuracy: 0.960 - ETA: 54s - loss: 0.0812 - accuracy: 0.968 - ETA: 51s - loss: 0.1363 - accuracy: 0.947 - ETA: 49s - loss: 0.1335 - accuracy: 0.946 - ETA: 46s - loss: 0.1231 - accuracy: 0.953 - ETA: 44s - loss: 0.1448 - accuracy: 0.947 - ETA: 41s - loss: 0.1650 - accuracy: 0.943 - ETA: 39s - loss: 0.1745 - accuracy: 0.940 - ETA: 37s - loss: 0.1658 - accuracy: 0.945 - ETA: 34s - loss: 0.1622 - accuracy: 0.944 - ETA: 32s - loss: 0.1700 - accuracy: 0.942 - ETA: 30s - loss: 0.1639 - accuracy: 0.943 - ETA: 28s - loss: 0.1608 - accuracy: 0.945 - ETA: 25s - loss: 0.1550 - accuracy: 0.948 - ETA: 23s - loss: 0.1586 - accuracy: 0.947 - ETA: 21s - loss: 0.1592 - accuracy: 0.947 - ETA: 18s - loss: 0.1556 - accuracy: 0.950 - ETA: 16s - loss: 0.1521 - accuracy: 0.950 - ETA: 14s - loss: 0.1606 - accuracy: 0.947 - ETA: 11s - loss: 0.1611 - accuracy: 0.945 - ETA: 9s - loss: 0.1602 - accuracy: 0.945 - ETA: 7s - loss: 0.1611 - accuracy: 0.94 - ETA: 5s - loss: 0.1574 - accuracy: 0.94 - ETA: 2s - loss: 0.1546 - accuracy: 0.94 - ETA: 0s - loss: 0.1566 - accuracy: 0.94 - 68s 75ms/step - loss: 0.1593 - accuracy: 0.9435 - val_loss: 0.6476 - val_accuracy: 0.8230\n",
                        "Epoch 48/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.0611 - accuracy: 1.00 - ETA: 59s - loss: 0.1302 - accuracy: 0.9688 - ETA: 56s - loss: 0.1186 - accuracy: 0.968 - ETA: 54s - loss: 0.1267 - accuracy: 0.960 - ETA: 52s - loss: 0.1160 - accuracy: 0.962 - ETA: 50s - loss: 0.1226 - accuracy: 0.958 - ETA: 48s - loss: 0.1270 - accuracy: 0.955 - ETA: 45s - loss: 0.1280 - accuracy: 0.953 - ETA: 43s - loss: 0.1201 - accuracy: 0.958 - ETA: 41s - loss: 0.1233 - accuracy: 0.959 - ETA: 39s - loss: 0.1209 - accuracy: 0.960 - ETA: 37s - loss: 0.1236 - accuracy: 0.960 - ETA: 35s - loss: 0.1378 - accuracy: 0.956 - ETA: 33s - loss: 0.1366 - accuracy: 0.955 - ETA: 30s - loss: 0.1328 - accuracy: 0.956 - ETA: 28s - loss: 0.1282 - accuracy: 0.959 - ETA: 26s - loss: 0.1237 - accuracy: 0.961 - ETA: 24s - loss: 0.1240 - accuracy: 0.961 - ETA: 21s - loss: 0.1278 - accuracy: 0.962 - ETA: 19s - loss: 0.1236 - accuracy: 0.964 - ETA: 17s - loss: 0.1314 - accuracy: 0.959 - ETA: 14s - loss: 0.1264 - accuracy: 0.961 - ETA: 12s - loss: 0.1228 - accuracy: 0.962 - ETA: 9s - loss: 0.1233 - accuracy: 0.959 - ETA: 7s - loss: 0.1220 - accuracy: 0.96 - ETA: 5s - loss: 0.1189 - accuracy: 0.96 - ETA: 2s - loss: 0.1172 - accuracy: 0.96 - ETA: 0s - loss: 0.1190 - accuracy: 0.96 - 70s 78ms/step - loss: 0.1183 - accuracy: 0.9612 - val_loss: 0.6784 - val_accuracy: 0.8097\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 49/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0661 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1460 - accuracy: 0.93 - ETA: 58s - loss: 0.1070 - accuracy: 0.9583 - ETA: 56s - loss: 0.1173 - accuracy: 0.945 - ETA: 53s - loss: 0.1326 - accuracy: 0.937 - ETA: 51s - loss: 0.1160 - accuracy: 0.947 - ETA: 49s - loss: 0.1329 - accuracy: 0.942 - ETA: 47s - loss: 0.1252 - accuracy: 0.949 - ETA: 44s - loss: 0.1304 - accuracy: 0.951 - ETA: 42s - loss: 0.1263 - accuracy: 0.953 - ETA: 40s - loss: 0.1277 - accuracy: 0.954 - ETA: 37s - loss: 0.1230 - accuracy: 0.955 - ETA: 35s - loss: 0.1203 - accuracy: 0.956 - ETA: 33s - loss: 0.1250 - accuracy: 0.957 - ETA: 30s - loss: 0.1228 - accuracy: 0.958 - ETA: 28s - loss: 0.1191 - accuracy: 0.959 - ETA: 26s - loss: 0.1248 - accuracy: 0.955 - ETA: 23s - loss: 0.1239 - accuracy: 0.956 - ETA: 21s - loss: 0.1183 - accuracy: 0.958 - ETA: 19s - loss: 0.1129 - accuracy: 0.960 - ETA: 16s - loss: 0.1153 - accuracy: 0.959 - ETA: 14s - loss: 0.1115 - accuracy: 0.961 - ETA: 12s - loss: 0.1135 - accuracy: 0.959 - ETA: 9s - loss: 0.1111 - accuracy: 0.959 - ETA: 7s - loss: 0.1128 - accuracy: 0.95 - ETA: 5s - loss: 0.1146 - accuracy: 0.95 - ETA: 2s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - 70s 77ms/step - loss: 0.1118 - accuracy: 0.9601 - val_loss: 0.8346 - val_accuracy: 0.7699\n",
                        "Epoch 50/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.0947 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0905 - accuracy: 0.96 - ETA: 58s - loss: 0.0787 - accuracy: 0.9792 - ETA: 55s - loss: 0.0812 - accuracy: 0.968 - ETA: 53s - loss: 0.0819 - accuracy: 0.962 - ETA: 51s - loss: 0.0694 - accuracy: 0.968 - ETA: 49s - loss: 0.0868 - accuracy: 0.968 - ETA: 47s - loss: 0.0833 - accuracy: 0.968 - ETA: 45s - loss: 0.0835 - accuracy: 0.968 - ETA: 42s - loss: 0.0816 - accuracy: 0.968 - ETA: 40s - loss: 0.0819 - accuracy: 0.965 - ETA: 38s - loss: 0.0853 - accuracy: 0.966 - ETA: 35s - loss: 0.0812 - accuracy: 0.968 - ETA: 33s - loss: 0.0832 - accuracy: 0.968 - ETA: 31s - loss: 0.0956 - accuracy: 0.966 - ETA: 28s - loss: 0.0962 - accuracy: 0.964 - ETA: 26s - loss: 0.0948 - accuracy: 0.965 - ETA: 23s - loss: 0.0928 - accuracy: 0.965 - ETA: 21s - loss: 0.0985 - accuracy: 0.960 - ETA: 19s - loss: 0.1027 - accuracy: 0.959 - ETA: 16s - loss: 0.1053 - accuracy: 0.956 - ETA: 14s - loss: 0.1064 - accuracy: 0.954 - ETA: 12s - loss: 0.1053 - accuracy: 0.953 - ETA: 9s - loss: 0.1104 - accuracy: 0.951 - ETA: 7s - loss: 0.1068 - accuracy: 0.95 - ETA: 5s - loss: 0.1118 - accuracy: 0.95 - ETA: 2s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - 70s 78ms/step - loss: 0.1137 - accuracy: 0.9535 - val_loss: 0.7245 - val_accuracy: 0.8097\n",
                        "Epoch 51/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.1973 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1088 - accuracy: 0.96 - ETA: 58s - loss: 0.1313 - accuracy: 0.9688 - ETA: 55s - loss: 0.1228 - accuracy: 0.960 - ETA: 53s - loss: 0.1142 - accuracy: 0.968 - ETA: 51s - loss: 0.1026 - accuracy: 0.974 - ETA: 49s - loss: 0.0958 - accuracy: 0.977 - ETA: 46s - loss: 0.0858 - accuracy: 0.980 - ETA: 44s - loss: 0.0794 - accuracy: 0.982 - ETA: 42s - loss: 0.0813 - accuracy: 0.978 - ETA: 40s - loss: 0.0824 - accuracy: 0.977 - ETA: 37s - loss: 0.0939 - accuracy: 0.976 - ETA: 35s - loss: 0.0936 - accuracy: 0.976 - ETA: 33s - loss: 0.0953 - accuracy: 0.975 - ETA: 30s - loss: 0.0927 - accuracy: 0.977 - ETA: 28s - loss: 0.0887 - accuracy: 0.978 - ETA: 26s - loss: 0.0878 - accuracy: 0.976 - ETA: 23s - loss: 0.0890 - accuracy: 0.974 - ETA: 21s - loss: 0.0896 - accuracy: 0.973 - ETA: 19s - loss: 0.0885 - accuracy: 0.975 - ETA: 16s - loss: 0.0851 - accuracy: 0.976 - ETA: 14s - loss: 0.0855 - accuracy: 0.975 - ETA: 12s - loss: 0.0853 - accuracy: 0.975 - ETA: 9s - loss: 0.0850 - accuracy: 0.975 - ETA: 7s - loss: 0.0868 - accuracy: 0.97 - ETA: 5s - loss: 0.0891 - accuracy: 0.97 - ETA: 2s - loss: 0.0934 - accuracy: 0.97 - ETA: 0s - loss: 0.0941 - accuracy: 0.97 - 70s 77ms/step - loss: 0.0934 - accuracy: 0.9712 - val_loss: 0.8151 - val_accuracy: 0.8053\n",
                        "Epoch 52/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0344 - accuracy: 1.00 - ETA: 1:02 - loss: 0.1291 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0969 - accuracy: 0.97 - ETA: 58s - loss: 0.1022 - accuracy: 0.9688 - ETA: 55s - loss: 0.0894 - accuracy: 0.968 - ETA: 52s - loss: 0.0937 - accuracy: 0.968 - ETA: 50s - loss: 0.0901 - accuracy: 0.968 - ETA: 48s - loss: 0.0924 - accuracy: 0.964 - ETA: 46s - loss: 0.1033 - accuracy: 0.961 - ETA: 44s - loss: 0.1127 - accuracy: 0.959 - ETA: 41s - loss: 0.1116 - accuracy: 0.957 - ETA: 39s - loss: 0.1064 - accuracy: 0.960 - ETA: 36s - loss: 0.1066 - accuracy: 0.961 - ETA: 34s - loss: 0.1135 - accuracy: 0.957 - ETA: 31s - loss: 0.1171 - accuracy: 0.954 - ETA: 29s - loss: 0.1111 - accuracy: 0.957 - ETA: 26s - loss: 0.1123 - accuracy: 0.955 - ETA: 24s - loss: 0.1067 - accuracy: 0.958 - ETA: 21s - loss: 0.1102 - accuracy: 0.957 - ETA: 19s - loss: 0.1165 - accuracy: 0.956 - ETA: 17s - loss: 0.1160 - accuracy: 0.956 - ETA: 14s - loss: 0.1212 - accuracy: 0.957 - ETA: 12s - loss: 0.1184 - accuracy: 0.959 - ETA: 9s - loss: 0.1196 - accuracy: 0.958 - ETA: 7s - loss: 0.1162 - accuracy: 0.96 - ETA: 5s - loss: 0.1148 - accuracy: 0.96 - ETA: 2s - loss: 0.1115 - accuracy: 0.96 - ETA: 0s - loss: 0.1092 - accuracy: 0.96 - 70s 78ms/step - loss: 0.1084 - accuracy: 0.9646 - val_loss: 0.7135 - val_accuracy: 0.8097\n",
                        "Epoch 53/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.0958 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1050 - accuracy: 0.96 - ETA: 57s - loss: 0.0958 - accuracy: 0.9792 - ETA: 55s - loss: 0.0799 - accuracy: 0.984 - ETA: 53s - loss: 0.0696 - accuracy: 0.987 - ETA: 50s - loss: 0.0980 - accuracy: 0.963 - ETA: 48s - loss: 0.1001 - accuracy: 0.959 - ETA: 46s - loss: 0.0912 - accuracy: 0.964 - ETA: 44s - loss: 0.0912 - accuracy: 0.961 - ETA: 41s - loss: 0.0858 - accuracy: 0.965 - ETA: 39s - loss: 0.1071 - accuracy: 0.960 - ETA: 37s - loss: 0.1013 - accuracy: 0.963 - ETA: 35s - loss: 0.1020 - accuracy: 0.961 - ETA: 32s - loss: 0.1126 - accuracy: 0.955 - ETA: 30s - loss: 0.1092 - accuracy: 0.956 - ETA: 28s - loss: 0.1079 - accuracy: 0.957 - ETA: 25s - loss: 0.1022 - accuracy: 0.959 - ETA: 23s - loss: 0.0989 - accuracy: 0.961 - ETA: 21s - loss: 0.0951 - accuracy: 0.963 - ETA: 19s - loss: 0.0931 - accuracy: 0.964 - ETA: 16s - loss: 0.0913 - accuracy: 0.965 - ETA: 14s - loss: 0.0881 - accuracy: 0.967 - ETA: 12s - loss: 0.0878 - accuracy: 0.967 - ETA: 9s - loss: 0.0870 - accuracy: 0.966 - ETA: 7s - loss: 0.0947 - accuracy: 0.96 - ETA: 5s - loss: 0.1030 - accuracy: 0.96 - ETA: 2s - loss: 0.1038 - accuracy: 0.96 - ETA: 0s - loss: 0.1059 - accuracy: 0.96 - 70s 78ms/step - loss: 0.1052 - accuracy: 0.9635 - val_loss: 0.7814 - val_accuracy: 0.8009\n",
                        "Epoch 54/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.1022 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0692 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0836 - accuracy: 0.97 - ETA: 57s - loss: 0.0744 - accuracy: 0.9766 - ETA: 55s - loss: 0.0649 - accuracy: 0.981 - ETA: 52s - loss: 0.0700 - accuracy: 0.979 - ETA: 50s - loss: 0.0627 - accuracy: 0.982 - ETA: 47s - loss: 0.0637 - accuracy: 0.980 - ETA: 44s - loss: 0.0596 - accuracy: 0.982 - ETA: 42s - loss: 0.0612 - accuracy: 0.981 - ETA: 40s - loss: 0.0737 - accuracy: 0.977 - ETA: 37s - loss: 0.0711 - accuracy: 0.976 - ETA: 35s - loss: 0.0863 - accuracy: 0.971 - ETA: 33s - loss: 0.0963 - accuracy: 0.968 - ETA: 30s - loss: 0.0903 - accuracy: 0.970 - ETA: 28s - loss: 0.0859 - accuracy: 0.972 - ETA: 26s - loss: 0.1073 - accuracy: 0.963 - ETA: 23s - loss: 0.1027 - accuracy: 0.965 - ETA: 21s - loss: 0.1086 - accuracy: 0.963 - ETA: 19s - loss: 0.1046 - accuracy: 0.965 - ETA: 16s - loss: 0.1023 - accuracy: 0.967 - ETA: 14s - loss: 0.1049 - accuracy: 0.964 - ETA: 12s - loss: 0.1144 - accuracy: 0.963 - ETA: 9s - loss: 0.1132 - accuracy: 0.963 - ETA: 7s - loss: 0.1114 - accuracy: 0.96 - ETA: 5s - loss: 0.1124 - accuracy: 0.96 - ETA: 2s - loss: 0.1146 - accuracy: 0.96 - ETA: 0s - loss: 0.1253 - accuracy: 0.95 - 70s 77ms/step - loss: 0.1245 - accuracy: 0.9601 - val_loss: 0.7915 - val_accuracy: 0.7920\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 55/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0345 - accuracy: 1.00 - ETA: 1:01 - loss: 0.0946 - accuracy: 0.98 - ETA: 59s - loss: 0.0800 - accuracy: 0.9896 - ETA: 57s - loss: 0.1040 - accuracy: 0.976 - ETA: 54s - loss: 0.1520 - accuracy: 0.962 - ETA: 52s - loss: 0.1286 - accuracy: 0.968 - ETA: 49s - loss: 0.1231 - accuracy: 0.968 - ETA: 47s - loss: 0.1143 - accuracy: 0.968 - ETA: 45s - loss: 0.1235 - accuracy: 0.961 - ETA: 43s - loss: 0.1245 - accuracy: 0.959 - ETA: 40s - loss: 0.1335 - accuracy: 0.954 - ETA: 38s - loss: 0.1381 - accuracy: 0.953 - ETA: 36s - loss: 0.1439 - accuracy: 0.951 - ETA: 33s - loss: 0.1378 - accuracy: 0.955 - ETA: 31s - loss: 0.1340 - accuracy: 0.958 - ETA: 29s - loss: 0.1272 - accuracy: 0.960 - ETA: 26s - loss: 0.1204 - accuracy: 0.963 - ETA: 24s - loss: 0.1220 - accuracy: 0.960 - ETA: 22s - loss: 0.1172 - accuracy: 0.962 - ETA: 19s - loss: 0.1126 - accuracy: 0.964 - ETA: 17s - loss: 0.1088 - accuracy: 0.965 - ETA: 14s - loss: 0.1094 - accuracy: 0.965 - ETA: 12s - loss: 0.1084 - accuracy: 0.967 - ETA: 10s - loss: 0.1062 - accuracy: 0.967 - ETA: 7s - loss: 0.1052 - accuracy: 0.967 - ETA: 5s - loss: 0.1041 - accuracy: 0.96 - ETA: 2s - loss: 0.1059 - accuracy: 0.96 - ETA: 0s - loss: 0.1101 - accuracy: 0.96 - 72s 79ms/step - loss: 0.1130 - accuracy: 0.9635 - val_loss: 0.8223 - val_accuracy: 0.7788\n",
                        "Epoch 56/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0861 - accuracy: 0.93 - ETA: 1:01 - loss: 0.0617 - accuracy: 0.95 - ETA: 59s - loss: 0.0790 - accuracy: 0.9583 - ETA: 57s - loss: 0.0800 - accuracy: 0.953 - ETA: 54s - loss: 0.0908 - accuracy: 0.950 - ETA: 52s - loss: 0.0957 - accuracy: 0.953 - ETA: 50s - loss: 0.0893 - accuracy: 0.955 - ETA: 47s - loss: 0.0919 - accuracy: 0.953 - ETA: 45s - loss: 0.0857 - accuracy: 0.958 - ETA: 43s - loss: 0.1115 - accuracy: 0.953 - ETA: 40s - loss: 0.1045 - accuracy: 0.957 - ETA: 38s - loss: 0.1017 - accuracy: 0.958 - ETA: 36s - loss: 0.0963 - accuracy: 0.961 - ETA: 33s - loss: 0.0903 - accuracy: 0.964 - ETA: 31s - loss: 0.0937 - accuracy: 0.962 - ETA: 29s - loss: 0.0980 - accuracy: 0.962 - ETA: 26s - loss: 0.0948 - accuracy: 0.965 - ETA: 24s - loss: 0.1098 - accuracy: 0.958 - ETA: 21s - loss: 0.1185 - accuracy: 0.953 - ETA: 19s - loss: 0.1179 - accuracy: 0.954 - ETA: 17s - loss: 0.1174 - accuracy: 0.953 - ETA: 14s - loss: 0.1146 - accuracy: 0.956 - ETA: 12s - loss: 0.1141 - accuracy: 0.955 - ETA: 9s - loss: 0.1126 - accuracy: 0.954 - ETA: 7s - loss: 0.1146 - accuracy: 0.95 - ETA: 5s - loss: 0.1125 - accuracy: 0.95 - ETA: 2s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - 71s 79ms/step - loss: 0.1146 - accuracy: 0.9557 - val_loss: 0.7690 - val_accuracy: 0.7876\n",
                        "Epoch 57/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.3068 - accuracy: 0.93 - ETA: 1:04 - loss: 0.2589 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1996 - accuracy: 0.95 - ETA: 59s - loss: 0.1678 - accuracy: 0.9688 - ETA: 56s - loss: 0.1750 - accuracy: 0.962 - ETA: 54s - loss: 0.1548 - accuracy: 0.963 - ETA: 52s - loss: 0.1625 - accuracy: 0.959 - ETA: 49s - loss: 0.1561 - accuracy: 0.964 - ETA: 47s - loss: 0.1496 - accuracy: 0.965 - ETA: 44s - loss: 0.1453 - accuracy: 0.962 - ETA: 41s - loss: 0.1517 - accuracy: 0.960 - ETA: 39s - loss: 0.1550 - accuracy: 0.955 - ETA: 36s - loss: 0.1546 - accuracy: 0.954 - ETA: 34s - loss: 0.1472 - accuracy: 0.957 - ETA: 31s - loss: 0.1477 - accuracy: 0.956 - ETA: 29s - loss: 0.1406 - accuracy: 0.959 - ETA: 26s - loss: 0.1383 - accuracy: 0.959 - ETA: 24s - loss: 0.1324 - accuracy: 0.961 - ETA: 21s - loss: 0.1369 - accuracy: 0.958 - ETA: 19s - loss: 0.1372 - accuracy: 0.957 - ETA: 17s - loss: 0.1337 - accuracy: 0.958 - ETA: 14s - loss: 0.1298 - accuracy: 0.958 - ETA: 12s - loss: 0.1286 - accuracy: 0.959 - ETA: 9s - loss: 0.1238 - accuracy: 0.960 - ETA: 7s - loss: 0.1241 - accuracy: 0.96 - ETA: 5s - loss: 0.1226 - accuracy: 0.96 - ETA: 2s - loss: 0.1248 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - 71s 78ms/step - loss: 0.1263 - accuracy: 0.9601 - val_loss: 0.8485 - val_accuracy: 0.7876\n",
                        "Epoch 58/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.1923 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1486 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1788 - accuracy: 0.91 - ETA: 58s - loss: 0.1759 - accuracy: 0.9062 - ETA: 55s - loss: 0.1495 - accuracy: 0.918 - ETA: 53s - loss: 0.1297 - accuracy: 0.932 - ETA: 51s - loss: 0.1130 - accuracy: 0.942 - ETA: 48s - loss: 0.1035 - accuracy: 0.949 - ETA: 46s - loss: 0.0966 - accuracy: 0.954 - ETA: 43s - loss: 0.0925 - accuracy: 0.959 - ETA: 41s - loss: 0.0922 - accuracy: 0.960 - ETA: 38s - loss: 0.1027 - accuracy: 0.958 - ETA: 36s - loss: 0.1058 - accuracy: 0.951 - ETA: 33s - loss: 0.1030 - accuracy: 0.953 - ETA: 31s - loss: 0.1041 - accuracy: 0.952 - ETA: 29s - loss: 0.1033 - accuracy: 0.953 - ETA: 26s - loss: 0.1063 - accuracy: 0.952 - ETA: 24s - loss: 0.1068 - accuracy: 0.951 - ETA: 21s - loss: 0.1047 - accuracy: 0.952 - ETA: 19s - loss: 0.1031 - accuracy: 0.953 - ETA: 17s - loss: 0.1039 - accuracy: 0.953 - ETA: 14s - loss: 0.1020 - accuracy: 0.954 - ETA: 12s - loss: 0.1078 - accuracy: 0.952 - ETA: 9s - loss: 0.1045 - accuracy: 0.954 - ETA: 7s - loss: 0.1068 - accuracy: 0.95 - ETA: 5s - loss: 0.1058 - accuracy: 0.95 - ETA: 2s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - 72s 79ms/step - loss: 0.1095 - accuracy: 0.9524 - val_loss: 0.8502 - val_accuracy: 0.7788\n",
                        "Epoch 59/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.2824 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1508 - accuracy: 0.94 - ETA: 57s - loss: 0.1269 - accuracy: 0.9531 - ETA: 55s - loss: 0.1200 - accuracy: 0.956 - ETA: 53s - loss: 0.1044 - accuracy: 0.963 - ETA: 51s - loss: 0.1136 - accuracy: 0.955 - ETA: 49s - loss: 0.1047 - accuracy: 0.960 - ETA: 46s - loss: 0.1244 - accuracy: 0.951 - ETA: 44s - loss: 0.1159 - accuracy: 0.956 - ETA: 42s - loss: 0.1124 - accuracy: 0.954 - ETA: 39s - loss: 0.1057 - accuracy: 0.958 - ETA: 37s - loss: 0.1060 - accuracy: 0.956 - ETA: 34s - loss: 0.1031 - accuracy: 0.957 - ETA: 32s - loss: 0.1027 - accuracy: 0.958 - ETA: 29s - loss: 0.1051 - accuracy: 0.957 - ETA: 27s - loss: 0.1012 - accuracy: 0.959 - ETA: 24s - loss: 0.1050 - accuracy: 0.958 - ETA: 22s - loss: 0.1010 - accuracy: 0.960 - ETA: 20s - loss: 0.1006 - accuracy: 0.960 - ETA: 17s - loss: 0.0981 - accuracy: 0.962 - ETA: 15s - loss: 0.0948 - accuracy: 0.964 - ETA: 12s - loss: 0.0936 - accuracy: 0.964 - ETA: 10s - loss: 0.0903 - accuracy: 0.966 - ETA: 7s - loss: 0.0884 - accuracy: 0.966 - ETA: 5s - loss: 0.0877 - accuracy: 0.96 - ETA: 2s - loss: 0.0865 - accuracy: 0.96 - ETA: 0s - loss: 0.0897 - accuracy: 0.96 - 73s 81ms/step - loss: 0.0897 - accuracy: 0.9679 - val_loss: 0.9054 - val_accuracy: 0.7655\n",
                        "Epoch 60/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.2112 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1478 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1019 - accuracy: 0.96 - ETA: 59s - loss: 0.0839 - accuracy: 0.9766 - ETA: 58s - loss: 0.0755 - accuracy: 0.981 - ETA: 56s - loss: 0.0724 - accuracy: 0.979 - ETA: 53s - loss: 0.0709 - accuracy: 0.977 - ETA: 50s - loss: 0.0657 - accuracy: 0.980 - ETA: 48s - loss: 0.0846 - accuracy: 0.979 - ETA: 45s - loss: 0.0991 - accuracy: 0.978 - ETA: 43s - loss: 0.0943 - accuracy: 0.977 - ETA: 40s - loss: 0.0902 - accuracy: 0.976 - ETA: 38s - loss: 0.0884 - accuracy: 0.976 - ETA: 35s - loss: 0.0896 - accuracy: 0.973 - ETA: 33s - loss: 0.1016 - accuracy: 0.966 - ETA: 30s - loss: 0.1025 - accuracy: 0.964 - ETA: 28s - loss: 0.1052 - accuracy: 0.963 - ETA: 25s - loss: 0.1011 - accuracy: 0.965 - ETA: 23s - loss: 0.0974 - accuracy: 0.967 - ETA: 20s - loss: 0.1021 - accuracy: 0.965 - ETA: 18s - loss: 0.1000 - accuracy: 0.967 - ETA: 15s - loss: 0.0964 - accuracy: 0.968 - ETA: 13s - loss: 0.0956 - accuracy: 0.968 - ETA: 10s - loss: 0.0923 - accuracy: 0.970 - ETA: 7s - loss: 0.0889 - accuracy: 0.971 - ETA: 5s - loss: 0.0910 - accuracy: 0.96 - ETA: 3s - loss: 0.0919 - accuracy: 0.96 - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - 74s 82ms/step - loss: 0.0971 - accuracy: 0.9679 - val_loss: 0.8309 - val_accuracy: 0.7920\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 61/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0301 - accuracy: 1.00 - ETA: 1:03 - loss: 0.1029 - accuracy: 0.98 - ETA: 1:01 - loss: 0.1590 - accuracy: 0.94 - ETA: 58s - loss: 0.1382 - accuracy: 0.9453 - ETA: 56s - loss: 0.1569 - accuracy: 0.950 - ETA: 53s - loss: 0.1360 - accuracy: 0.958 - ETA: 51s - loss: 0.1269 - accuracy: 0.959 - ETA: 48s - loss: 0.1249 - accuracy: 0.960 - ETA: 46s - loss: 0.1244 - accuracy: 0.958 - ETA: 43s - loss: 0.1323 - accuracy: 0.956 - ETA: 41s - loss: 0.1246 - accuracy: 0.960 - ETA: 38s - loss: 0.1313 - accuracy: 0.958 - ETA: 36s - loss: 0.1273 - accuracy: 0.959 - ETA: 34s - loss: 0.1253 - accuracy: 0.957 - ETA: 31s - loss: 0.1204 - accuracy: 0.958 - ETA: 29s - loss: 0.1243 - accuracy: 0.955 - ETA: 26s - loss: 0.1230 - accuracy: 0.955 - ETA: 24s - loss: 0.1175 - accuracy: 0.958 - ETA: 22s - loss: 0.1132 - accuracy: 0.960 - ETA: 19s - loss: 0.1119 - accuracy: 0.960 - ETA: 17s - loss: 0.1092 - accuracy: 0.961 - ETA: 14s - loss: 0.1092 - accuracy: 0.960 - ETA: 12s - loss: 0.1068 - accuracy: 0.960 - ETA: 10s - loss: 0.1066 - accuracy: 0.959 - ETA: 7s - loss: 0.1056 - accuracy: 0.960 - ETA: 5s - loss: 0.1032 - accuracy: 0.96 - ETA: 2s - loss: 0.1008 - accuracy: 0.96 - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - 72s 80ms/step - loss: 0.0991 - accuracy: 0.9623 - val_loss: 0.9515 - val_accuracy: 0.7699\n",
                        "Epoch 62/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.1638 - accuracy: 0.90 - ETA: 1:03 - loss: 0.0969 - accuracy: 0.95 - ETA: 1:01 - loss: 0.0978 - accuracy: 0.95 - ETA: 59s - loss: 0.1123 - accuracy: 0.9531 - ETA: 57s - loss: 0.1189 - accuracy: 0.950 - ETA: 54s - loss: 0.1674 - accuracy: 0.932 - ETA: 52s - loss: 0.1683 - accuracy: 0.937 - ETA: 50s - loss: 0.1610 - accuracy: 0.941 - ETA: 48s - loss: 0.1476 - accuracy: 0.944 - ETA: 46s - loss: 0.1344 - accuracy: 0.950 - ETA: 43s - loss: 0.1231 - accuracy: 0.954 - ETA: 41s - loss: 0.1145 - accuracy: 0.958 - ETA: 38s - loss: 0.1198 - accuracy: 0.956 - ETA: 36s - loss: 0.1216 - accuracy: 0.957 - ETA: 33s - loss: 0.1196 - accuracy: 0.956 - ETA: 31s - loss: 0.1183 - accuracy: 0.957 - ETA: 29s - loss: 0.1150 - accuracy: 0.957 - ETA: 26s - loss: 0.1112 - accuracy: 0.958 - ETA: 24s - loss: 0.1069 - accuracy: 0.960 - ETA: 21s - loss: 0.1023 - accuracy: 0.962 - ETA: 18s - loss: 0.0988 - accuracy: 0.964 - ETA: 16s - loss: 0.0967 - accuracy: 0.964 - ETA: 13s - loss: 0.0943 - accuracy: 0.964 - ETA: 10s - loss: 0.0961 - accuracy: 0.964 - ETA: 8s - loss: 0.0988 - accuracy: 0.963 - ETA: 5s - loss: 0.0961 - accuracy: 0.96 - ETA: 3s - loss: 0.0934 - accuracy: 0.96 - ETA: 0s - loss: 0.0917 - accuracy: 0.96 - 77s 85ms/step - loss: 0.0916 - accuracy: 0.9679 - val_loss: 0.7713 - val_accuracy: 0.8186\n",
                        "Epoch 63/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.1390 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1362 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1299 - accuracy: 0.94 - ETA: 58s - loss: 0.1071 - accuracy: 0.9609 - ETA: 56s - loss: 0.0958 - accuracy: 0.962 - ETA: 53s - loss: 0.1263 - accuracy: 0.958 - ETA: 51s - loss: 0.1158 - accuracy: 0.959 - ETA: 49s - loss: 0.1147 - accuracy: 0.957 - ETA: 46s - loss: 0.1068 - accuracy: 0.958 - ETA: 44s - loss: 0.1027 - accuracy: 0.959 - ETA: 41s - loss: 0.0959 - accuracy: 0.963 - ETA: 39s - loss: 0.0988 - accuracy: 0.960 - ETA: 36s - loss: 0.0930 - accuracy: 0.963 - ETA: 34s - loss: 0.0915 - accuracy: 0.962 - ETA: 32s - loss: 0.0896 - accuracy: 0.962 - ETA: 29s - loss: 0.0941 - accuracy: 0.960 - ETA: 27s - loss: 0.0924 - accuracy: 0.961 - ETA: 24s - loss: 0.0879 - accuracy: 0.963 - ETA: 22s - loss: 0.0900 - accuracy: 0.963 - ETA: 20s - loss: 0.0870 - accuracy: 0.965 - ETA: 17s - loss: 0.0837 - accuracy: 0.967 - ETA: 15s - loss: 0.0819 - accuracy: 0.968 - ETA: 12s - loss: 0.0801 - accuracy: 0.970 - ETA: 10s - loss: 0.0835 - accuracy: 0.967 - ETA: 7s - loss: 0.0818 - accuracy: 0.968 - ETA: 5s - loss: 0.0850 - accuracy: 0.96 - ETA: 3s - loss: 0.0849 - accuracy: 0.96 - ETA: 0s - loss: 0.0919 - accuracy: 0.96 - 74s 82ms/step - loss: 0.0912 - accuracy: 0.9657 - val_loss: 0.8950 - val_accuracy: 0.8053\n",
                        "Epoch 64/100\n",
                        "903/903 [==============================] - ETA: 1:11 - loss: 0.0225 - accuracy: 1.00 - ETA: 1:07 - loss: 0.1319 - accuracy: 0.96 - ETA: 1:04 - loss: 0.0966 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1193 - accuracy: 0.97 - ETA: 58s - loss: 0.1067 - accuracy: 0.9750 - ETA: 56s - loss: 0.1182 - accuracy: 0.974 - ETA: 54s - loss: 0.1388 - accuracy: 0.968 - ETA: 51s - loss: 0.1397 - accuracy: 0.964 - ETA: 49s - loss: 0.1361 - accuracy: 0.965 - ETA: 47s - loss: 0.1415 - accuracy: 0.962 - ETA: 45s - loss: 0.1421 - accuracy: 0.963 - ETA: 42s - loss: 0.1351 - accuracy: 0.963 - ETA: 39s - loss: 0.1312 - accuracy: 0.961 - ETA: 37s - loss: 0.1328 - accuracy: 0.957 - ETA: 34s - loss: 0.1298 - accuracy: 0.956 - ETA: 32s - loss: 0.1292 - accuracy: 0.957 - ETA: 29s - loss: 0.1361 - accuracy: 0.955 - ETA: 26s - loss: 0.1353 - accuracy: 0.954 - ETA: 24s - loss: 0.1301 - accuracy: 0.957 - ETA: 21s - loss: 0.1287 - accuracy: 0.957 - ETA: 18s - loss: 0.1243 - accuracy: 0.959 - ETA: 16s - loss: 0.1226 - accuracy: 0.958 - ETA: 13s - loss: 0.1279 - accuracy: 0.956 - ETA: 11s - loss: 0.1278 - accuracy: 0.957 - ETA: 8s - loss: 0.1281 - accuracy: 0.956 - ETA: 5s - loss: 0.1281 - accuracy: 0.95 - ETA: 3s - loss: 0.1276 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - 80s 89ms/step - loss: 0.1266 - accuracy: 0.9535 - val_loss: 0.7899 - val_accuracy: 0.7965\n",
                        "Epoch 65/100\n",
                        "903/903 [==============================] - ETA: 1:13 - loss: 0.0825 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1335 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1096 - accuracy: 0.94 - ETA: 1:07 - loss: 0.1070 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1089 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1117 - accuracy: 0.94 - ETA: 59s - loss: 0.1247 - accuracy: 0.9509 - ETA: 57s - loss: 0.1470 - accuracy: 0.945 - ETA: 55s - loss: 0.1349 - accuracy: 0.951 - ETA: 52s - loss: 0.1255 - accuracy: 0.956 - ETA: 49s - loss: 0.1164 - accuracy: 0.960 - ETA: 46s - loss: 0.1086 - accuracy: 0.963 - ETA: 43s - loss: 0.1103 - accuracy: 0.961 - ETA: 40s - loss: 0.1060 - accuracy: 0.964 - ETA: 37s - loss: 0.0998 - accuracy: 0.966 - ETA: 34s - loss: 0.0955 - accuracy: 0.968 - ETA: 32s - loss: 0.0955 - accuracy: 0.968 - ETA: 29s - loss: 0.0971 - accuracy: 0.968 - ETA: 26s - loss: 0.0974 - accuracy: 0.967 - ETA: 23s - loss: 0.0950 - accuracy: 0.967 - ETA: 20s - loss: 0.1047 - accuracy: 0.964 - ETA: 17s - loss: 0.1013 - accuracy: 0.965 - ETA: 14s - loss: 0.1075 - accuracy: 0.964 - ETA: 11s - loss: 0.1081 - accuracy: 0.962 - ETA: 8s - loss: 0.1048 - accuracy: 0.963 - ETA: 6s - loss: 0.1035 - accuracy: 0.96 - ETA: 3s - loss: 0.1001 - accuracy: 0.96 - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - 82s 91ms/step - loss: 0.0973 - accuracy: 0.9668 - val_loss: 0.8282 - val_accuracy: 0.7788\n",
                        "Epoch 66/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.0484 - accuracy: 1.00 - ETA: 1:03 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0544 - accuracy: 0.98 - ETA: 58s - loss: 0.0758 - accuracy: 0.9766 - ETA: 56s - loss: 0.0644 - accuracy: 0.981 - ETA: 53s - loss: 0.0669 - accuracy: 0.979 - ETA: 51s - loss: 0.0749 - accuracy: 0.977 - ETA: 49s - loss: 0.0843 - accuracy: 0.972 - ETA: 46s - loss: 0.0795 - accuracy: 0.975 - ETA: 44s - loss: 0.0733 - accuracy: 0.978 - ETA: 41s - loss: 0.0686 - accuracy: 0.980 - ETA: 39s - loss: 0.0669 - accuracy: 0.979 - ETA: 37s - loss: 0.0651 - accuracy: 0.978 - ETA: 34s - loss: 0.0625 - accuracy: 0.979 - ETA: 32s - loss: 0.0614 - accuracy: 0.979 - ETA: 29s - loss: 0.0586 - accuracy: 0.980 - ETA: 27s - loss: 0.0580 - accuracy: 0.981 - ETA: 24s - loss: 0.0606 - accuracy: 0.980 - ETA: 22s - loss: 0.0593 - accuracy: 0.980 - ETA: 20s - loss: 0.0568 - accuracy: 0.981 - ETA: 17s - loss: 0.0546 - accuracy: 0.982 - ETA: 15s - loss: 0.0546 - accuracy: 0.981 - ETA: 12s - loss: 0.0671 - accuracy: 0.978 - ETA: 10s - loss: 0.0683 - accuracy: 0.977 - ETA: 7s - loss: 0.0702 - accuracy: 0.976 - ETA: 5s - loss: 0.0694 - accuracy: 0.97 - ETA: 3s - loss: 0.0674 - accuracy: 0.97 - ETA: 0s - loss: 0.0656 - accuracy: 0.97 - 75s 83ms/step - loss: 0.0660 - accuracy: 0.9767 - val_loss: 0.7793 - val_accuracy: 0.8009\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 67/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0303 - accuracy: 1.00 - ETA: 1:04 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0436 - accuracy: 0.98 - ETA: 59s - loss: 0.0875 - accuracy: 0.9688 - ETA: 56s - loss: 0.0785 - accuracy: 0.975 - ETA: 54s - loss: 0.1014 - accuracy: 0.963 - ETA: 51s - loss: 0.0899 - accuracy: 0.968 - ETA: 49s - loss: 0.0993 - accuracy: 0.960 - ETA: 46s - loss: 0.0922 - accuracy: 0.965 - ETA: 44s - loss: 0.0999 - accuracy: 0.965 - ETA: 42s - loss: 0.0945 - accuracy: 0.968 - ETA: 39s - loss: 0.0915 - accuracy: 0.968 - ETA: 37s - loss: 0.0975 - accuracy: 0.966 - ETA: 35s - loss: 0.1003 - accuracy: 0.966 - ETA: 32s - loss: 0.0974 - accuracy: 0.966 - ETA: 30s - loss: 0.0934 - accuracy: 0.968 - ETA: 27s - loss: 0.0961 - accuracy: 0.968 - ETA: 25s - loss: 0.0940 - accuracy: 0.968 - ETA: 22s - loss: 0.0960 - accuracy: 0.967 - ETA: 20s - loss: 0.0944 - accuracy: 0.967 - ETA: 17s - loss: 0.0919 - accuracy: 0.967 - ETA: 15s - loss: 0.0881 - accuracy: 0.968 - ETA: 12s - loss: 0.0854 - accuracy: 0.970 - ETA: 10s - loss: 0.0829 - accuracy: 0.971 - ETA: 7s - loss: 0.0804 - accuracy: 0.972 - ETA: 5s - loss: 0.0778 - accuracy: 0.97 - ETA: 3s - loss: 0.0766 - accuracy: 0.97 - ETA: 0s - loss: 0.0752 - accuracy: 0.97 - 75s 83ms/step - loss: 0.0762 - accuracy: 0.9734 - val_loss: 1.1166 - val_accuracy: 0.7522\n",
                        "Epoch 68/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.0498 - accuracy: 1.00 - ETA: 1:05 - loss: 0.0418 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0310 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0702 - accuracy: 0.98 - ETA: 57s - loss: 0.0733 - accuracy: 0.9812 - ETA: 55s - loss: 0.0831 - accuracy: 0.979 - ETA: 52s - loss: 0.0969 - accuracy: 0.973 - ETA: 50s - loss: 0.0864 - accuracy: 0.976 - ETA: 48s - loss: 0.0857 - accuracy: 0.975 - ETA: 45s - loss: 0.0888 - accuracy: 0.971 - ETA: 43s - loss: 0.1019 - accuracy: 0.965 - ETA: 40s - loss: 0.0996 - accuracy: 0.966 - ETA: 38s - loss: 0.1057 - accuracy: 0.961 - ETA: 35s - loss: 0.1045 - accuracy: 0.962 - ETA: 33s - loss: 0.0986 - accuracy: 0.964 - ETA: 30s - loss: 0.0942 - accuracy: 0.966 - ETA: 28s - loss: 0.0903 - accuracy: 0.968 - ETA: 25s - loss: 0.0907 - accuracy: 0.968 - ETA: 23s - loss: 0.0983 - accuracy: 0.967 - ETA: 20s - loss: 0.1015 - accuracy: 0.965 - ETA: 18s - loss: 0.1045 - accuracy: 0.962 - ETA: 15s - loss: 0.1032 - accuracy: 0.963 - ETA: 13s - loss: 0.1008 - accuracy: 0.963 - ETA: 10s - loss: 0.1034 - accuracy: 0.960 - ETA: 8s - loss: 0.1111 - accuracy: 0.958 - ETA: 5s - loss: 0.1080 - accuracy: 0.95 - ETA: 3s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - 74s 82ms/step - loss: 0.1138 - accuracy: 0.9568 - val_loss: 1.0844 - val_accuracy: 0.7389\n",
                        "Epoch 69/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.1893 - accuracy: 0.87 - ETA: 1:03 - loss: 0.1690 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1531 - accuracy: 0.92 - ETA: 58s - loss: 0.1245 - accuracy: 0.9453 - ETA: 55s - loss: 0.1138 - accuracy: 0.950 - ETA: 53s - loss: 0.1150 - accuracy: 0.953 - ETA: 50s - loss: 0.1191 - accuracy: 0.955 - ETA: 48s - loss: 0.1085 - accuracy: 0.960 - ETA: 45s - loss: 0.0999 - accuracy: 0.965 - ETA: 43s - loss: 0.1041 - accuracy: 0.962 - ETA: 41s - loss: 0.0992 - accuracy: 0.965 - ETA: 38s - loss: 0.0940 - accuracy: 0.968 - ETA: 36s - loss: 0.0887 - accuracy: 0.971 - ETA: 34s - loss: 0.0863 - accuracy: 0.973 - ETA: 31s - loss: 0.0956 - accuracy: 0.968 - ETA: 29s - loss: 0.0940 - accuracy: 0.970 - ETA: 26s - loss: 0.0916 - accuracy: 0.970 - ETA: 24s - loss: 0.0878 - accuracy: 0.972 - ETA: 22s - loss: 0.0950 - accuracy: 0.968 - ETA: 19s - loss: 0.0933 - accuracy: 0.968 - ETA: 17s - loss: 0.0914 - accuracy: 0.968 - ETA: 14s - loss: 0.0914 - accuracy: 0.968 - ETA: 12s - loss: 0.0934 - accuracy: 0.967 - ETA: 10s - loss: 0.0913 - accuracy: 0.968 - ETA: 7s - loss: 0.0951 - accuracy: 0.967 - ETA: 5s - loss: 0.0928 - accuracy: 0.96 - ETA: 2s - loss: 0.0998 - accuracy: 0.96 - ETA: 0s - loss: 0.1079 - accuracy: 0.96 - 72s 80ms/step - loss: 0.1075 - accuracy: 0.9646 - val_loss: 0.7982 - val_accuracy: 0.7965\n",
                        "Epoch 70/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0232 - accuracy: 1.00 - ETA: 1:03 - loss: 0.0238 - accuracy: 1.00 - ETA: 1:01 - loss: 0.0377 - accuracy: 0.98 - ETA: 59s - loss: 0.0638 - accuracy: 0.9766 - ETA: 56s - loss: 0.0662 - accuracy: 0.975 - ETA: 54s - loss: 0.0793 - accuracy: 0.974 - ETA: 51s - loss: 0.0886 - accuracy: 0.973 - ETA: 49s - loss: 0.0998 - accuracy: 0.968 - ETA: 46s - loss: 0.0978 - accuracy: 0.968 - ETA: 44s - loss: 0.1015 - accuracy: 0.968 - ETA: 41s - loss: 0.1049 - accuracy: 0.968 - ETA: 39s - loss: 0.1031 - accuracy: 0.966 - ETA: 36s - loss: 0.0990 - accuracy: 0.968 - ETA: 34s - loss: 0.0956 - accuracy: 0.971 - ETA: 32s - loss: 0.0927 - accuracy: 0.970 - ETA: 29s - loss: 0.0929 - accuracy: 0.970 - ETA: 27s - loss: 0.0884 - accuracy: 0.972 - ETA: 24s - loss: 0.0857 - accuracy: 0.974 - ETA: 22s - loss: 0.0823 - accuracy: 0.975 - ETA: 19s - loss: 0.0784 - accuracy: 0.976 - ETA: 17s - loss: 0.0824 - accuracy: 0.974 - ETA: 15s - loss: 0.0824 - accuracy: 0.974 - ETA: 12s - loss: 0.0793 - accuracy: 0.975 - ETA: 10s - loss: 0.0814 - accuracy: 0.975 - ETA: 7s - loss: 0.0784 - accuracy: 0.976 - ETA: 5s - loss: 0.0800 - accuracy: 0.97 - ETA: 2s - loss: 0.0779 - accuracy: 0.97 - ETA: 0s - loss: 0.0789 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.8958 - val_accuracy: 0.7699\n",
                        "Epoch 71/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.1310 - accuracy: 0.93 - ETA: 1:04 - loss: 0.0944 - accuracy: 0.95 - ETA: 1:02 - loss: 0.0903 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1127 - accuracy: 0.94 - ETA: 58s - loss: 0.0951 - accuracy: 0.9563 - ETA: 55s - loss: 0.0989 - accuracy: 0.953 - ETA: 53s - loss: 0.1013 - accuracy: 0.955 - ETA: 50s - loss: 0.0936 - accuracy: 0.957 - ETA: 48s - loss: 0.0902 - accuracy: 0.958 - ETA: 45s - loss: 0.0859 - accuracy: 0.962 - ETA: 43s - loss: 0.1011 - accuracy: 0.960 - ETA: 40s - loss: 0.0956 - accuracy: 0.960 - ETA: 38s - loss: 0.1007 - accuracy: 0.961 - ETA: 35s - loss: 0.0967 - accuracy: 0.964 - ETA: 33s - loss: 0.0995 - accuracy: 0.960 - ETA: 30s - loss: 0.0949 - accuracy: 0.962 - ETA: 28s - loss: 0.0917 - accuracy: 0.965 - ETA: 25s - loss: 0.0996 - accuracy: 0.963 - ETA: 23s - loss: 0.0957 - accuracy: 0.965 - ETA: 20s - loss: 0.0976 - accuracy: 0.964 - ETA: 18s - loss: 0.0936 - accuracy: 0.965 - ETA: 15s - loss: 0.0919 - accuracy: 0.965 - ETA: 13s - loss: 0.0889 - accuracy: 0.967 - ETA: 10s - loss: 0.0901 - accuracy: 0.966 - ETA: 8s - loss: 0.0869 - accuracy: 0.967 - ETA: 5s - loss: 0.0883 - accuracy: 0.96 - ETA: 3s - loss: 0.0896 - accuracy: 0.96 - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 76s 84ms/step - loss: 0.0897 - accuracy: 0.9668 - val_loss: 0.8576 - val_accuracy: 0.7832\n",
                        "Epoch 72/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0668 - accuracy: 0.96 - ETA: 1:04 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0335 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0614 - accuracy: 0.98 - ETA: 58s - loss: 0.0628 - accuracy: 0.9875 - ETA: 55s - loss: 0.0737 - accuracy: 0.984 - ETA: 53s - loss: 0.0822 - accuracy: 0.982 - ETA: 50s - loss: 0.0740 - accuracy: 0.984 - ETA: 48s - loss: 0.0687 - accuracy: 0.986 - ETA: 45s - loss: 0.0631 - accuracy: 0.987 - ETA: 43s - loss: 0.0605 - accuracy: 0.988 - ETA: 40s - loss: 0.0640 - accuracy: 0.987 - ETA: 38s - loss: 0.0667 - accuracy: 0.985 - ETA: 35s - loss: 0.0686 - accuracy: 0.984 - ETA: 33s - loss: 0.0731 - accuracy: 0.983 - ETA: 30s - loss: 0.0739 - accuracy: 0.982 - ETA: 28s - loss: 0.0723 - accuracy: 0.983 - ETA: 25s - loss: 0.0691 - accuracy: 0.984 - ETA: 23s - loss: 0.0679 - accuracy: 0.985 - ETA: 20s - loss: 0.0653 - accuracy: 0.985 - ETA: 18s - loss: 0.0638 - accuracy: 0.986 - ETA: 15s - loss: 0.0616 - accuracy: 0.987 - ETA: 13s - loss: 0.0645 - accuracy: 0.986 - ETA: 10s - loss: 0.0635 - accuracy: 0.985 - ETA: 8s - loss: 0.0617 - accuracy: 0.986 - ETA: 5s - loss: 0.0618 - accuracy: 0.98 - ETA: 3s - loss: 0.0649 - accuracy: 0.98 - ETA: 0s - loss: 0.0658 - accuracy: 0.98 - 74s 82ms/step - loss: 0.0666 - accuracy: 0.9834 - val_loss: 0.9075 - val_accuracy: 0.8142\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 73/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.0354 - accuracy: 1.00 - ETA: 1:03 - loss: 0.0391 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0401 - accuracy: 1.00 - ETA: 58s - loss: 0.0753 - accuracy: 0.9922 - ETA: 56s - loss: 0.0756 - accuracy: 0.987 - ETA: 54s - loss: 0.0695 - accuracy: 0.989 - ETA: 52s - loss: 0.0905 - accuracy: 0.977 - ETA: 50s - loss: 0.0869 - accuracy: 0.976 - ETA: 47s - loss: 0.0918 - accuracy: 0.975 - ETA: 45s - loss: 0.1001 - accuracy: 0.975 - ETA: 42s - loss: 0.0935 - accuracy: 0.977 - ETA: 40s - loss: 0.0911 - accuracy: 0.976 - ETA: 37s - loss: 0.0939 - accuracy: 0.976 - ETA: 35s - loss: 0.0901 - accuracy: 0.977 - ETA: 32s - loss: 0.0922 - accuracy: 0.975 - ETA: 30s - loss: 0.0896 - accuracy: 0.974 - ETA: 27s - loss: 0.1025 - accuracy: 0.972 - ETA: 25s - loss: 0.0997 - accuracy: 0.972 - ETA: 22s - loss: 0.0970 - accuracy: 0.972 - ETA: 20s - loss: 0.1053 - accuracy: 0.968 - ETA: 17s - loss: 0.1011 - accuracy: 0.970 - ETA: 15s - loss: 0.0985 - accuracy: 0.971 - ETA: 12s - loss: 0.0958 - accuracy: 0.972 - ETA: 10s - loss: 0.0937 - accuracy: 0.974 - ETA: 7s - loss: 0.0923 - accuracy: 0.973 - ETA: 5s - loss: 0.0942 - accuracy: 0.97 - ETA: 2s - loss: 0.0940 - accuracy: 0.97 - ETA: 0s - loss: 0.0939 - accuracy: 0.97 - 72s 80ms/step - loss: 0.0934 - accuracy: 0.9723 - val_loss: 0.8876 - val_accuracy: 0.8053\n",
                        "Epoch 74/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0249 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0333 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0303 - accuracy: 1.00 - ETA: 57s - loss: 0.0358 - accuracy: 0.9922 - ETA: 54s - loss: 0.0583 - accuracy: 0.981 - ETA: 52s - loss: 0.0657 - accuracy: 0.979 - ETA: 49s - loss: 0.0655 - accuracy: 0.977 - ETA: 47s - loss: 0.0745 - accuracy: 0.976 - ETA: 45s - loss: 0.0870 - accuracy: 0.975 - ETA: 43s - loss: 0.0969 - accuracy: 0.971 - ETA: 40s - loss: 0.0946 - accuracy: 0.971 - ETA: 38s - loss: 0.0876 - accuracy: 0.974 - ETA: 35s - loss: 0.0826 - accuracy: 0.976 - ETA: 33s - loss: 0.0790 - accuracy: 0.977 - ETA: 31s - loss: 0.0750 - accuracy: 0.979 - ETA: 28s - loss: 0.0775 - accuracy: 0.978 - ETA: 26s - loss: 0.0750 - accuracy: 0.979 - ETA: 24s - loss: 0.0736 - accuracy: 0.979 - ETA: 21s - loss: 0.0735 - accuracy: 0.978 - ETA: 19s - loss: 0.0747 - accuracy: 0.978 - ETA: 17s - loss: 0.0715 - accuracy: 0.979 - ETA: 14s - loss: 0.0694 - accuracy: 0.980 - ETA: 12s - loss: 0.0681 - accuracy: 0.981 - ETA: 9s - loss: 0.0664 - accuracy: 0.981 - ETA: 7s - loss: 0.0685 - accuracy: 0.98 - ETA: 5s - loss: 0.0691 - accuracy: 0.98 - ETA: 2s - loss: 0.0690 - accuracy: 0.98 - ETA: 0s - loss: 0.0744 - accuracy: 0.97 - 71s 79ms/step - loss: 0.0740 - accuracy: 0.9779 - val_loss: 0.8547 - val_accuracy: 0.8186\n",
                        "Epoch 75/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.0811 - accuracy: 0.93 - ETA: 1:05 - loss: 0.0467 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0445 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0552 - accuracy: 0.96 - ETA: 57s - loss: 0.0647 - accuracy: 0.9625 - ETA: 55s - loss: 0.0547 - accuracy: 0.968 - ETA: 52s - loss: 0.0668 - accuracy: 0.968 - ETA: 50s - loss: 0.0869 - accuracy: 0.960 - ETA: 47s - loss: 0.0797 - accuracy: 0.965 - ETA: 44s - loss: 0.0947 - accuracy: 0.962 - ETA: 42s - loss: 0.0872 - accuracy: 0.965 - ETA: 39s - loss: 0.0843 - accuracy: 0.966 - ETA: 37s - loss: 0.0793 - accuracy: 0.968 - ETA: 34s - loss: 0.0782 - accuracy: 0.968 - ETA: 32s - loss: 0.0823 - accuracy: 0.966 - ETA: 29s - loss: 0.0790 - accuracy: 0.966 - ETA: 27s - loss: 0.0756 - accuracy: 0.968 - ETA: 24s - loss: 0.0724 - accuracy: 0.970 - ETA: 22s - loss: 0.0697 - accuracy: 0.972 - ETA: 20s - loss: 0.0707 - accuracy: 0.970 - ETA: 17s - loss: 0.0693 - accuracy: 0.970 - ETA: 15s - loss: 0.0807 - accuracy: 0.968 - ETA: 12s - loss: 0.0780 - accuracy: 0.970 - ETA: 10s - loss: 0.0767 - accuracy: 0.970 - ETA: 7s - loss: 0.0781 - accuracy: 0.968 - ETA: 5s - loss: 0.0755 - accuracy: 0.97 - ETA: 2s - loss: 0.0775 - accuracy: 0.96 - ETA: 0s - loss: 0.0753 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0776 - accuracy: 0.9701 - val_loss: 0.9282 - val_accuracy: 0.7965\n",
                        "Epoch 76/100\n",
                        "903/903 [==============================] - ETA: 1:13 - loss: 0.0648 - accuracy: 0.96 - ETA: 1:09 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0453 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0472 - accuracy: 0.97 - ETA: 59s - loss: 0.0417 - accuracy: 0.9812 - ETA: 57s - loss: 0.0381 - accuracy: 0.984 - ETA: 54s - loss: 0.0448 - accuracy: 0.982 - ETA: 51s - loss: 0.0546 - accuracy: 0.980 - ETA: 48s - loss: 0.0612 - accuracy: 0.979 - ETA: 46s - loss: 0.1017 - accuracy: 0.971 - ETA: 43s - loss: 0.1067 - accuracy: 0.965 - ETA: 40s - loss: 0.1009 - accuracy: 0.968 - ETA: 38s - loss: 0.0946 - accuracy: 0.971 - ETA: 35s - loss: 0.0893 - accuracy: 0.973 - ETA: 33s - loss: 0.0882 - accuracy: 0.972 - ETA: 30s - loss: 0.0944 - accuracy: 0.970 - ETA: 28s - loss: 0.1095 - accuracy: 0.966 - ETA: 25s - loss: 0.1120 - accuracy: 0.963 - ETA: 23s - loss: 0.1066 - accuracy: 0.965 - ETA: 20s - loss: 0.1042 - accuracy: 0.965 - ETA: 18s - loss: 0.1041 - accuracy: 0.965 - ETA: 15s - loss: 0.1004 - accuracy: 0.967 - ETA: 13s - loss: 0.0975 - accuracy: 0.967 - ETA: 10s - loss: 0.0990 - accuracy: 0.964 - ETA: 8s - loss: 0.1018 - accuracy: 0.965 - ETA: 5s - loss: 0.1006 - accuracy: 0.96 - ETA: 3s - loss: 0.1034 - accuracy: 0.96 - ETA: 0s - loss: 0.1042 - accuracy: 0.96 - 77s 85ms/step - loss: 0.1045 - accuracy: 0.9612 - val_loss: 0.8120 - val_accuracy: 0.7876\n",
                        "Epoch 77/100\n",
                        "903/903 [==============================] - ETA: 1:09 - loss: 0.0960 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1057 - accuracy: 0.95 - ETA: 1:04 - loss: 0.0821 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0758 - accuracy: 0.97 - ETA: 59s - loss: 0.0727 - accuracy: 0.9750 - ETA: 56s - loss: 0.0709 - accuracy: 0.974 - ETA: 54s - loss: 0.0705 - accuracy: 0.973 - ETA: 51s - loss: 0.0637 - accuracy: 0.976 - ETA: 48s - loss: 0.0642 - accuracy: 0.979 - ETA: 46s - loss: 0.0622 - accuracy: 0.981 - ETA: 43s - loss: 0.0668 - accuracy: 0.977 - ETA: 41s - loss: 0.0625 - accuracy: 0.979 - ETA: 38s - loss: 0.0617 - accuracy: 0.980 - ETA: 36s - loss: 0.0609 - accuracy: 0.979 - ETA: 33s - loss: 0.0688 - accuracy: 0.975 - ETA: 30s - loss: 0.0714 - accuracy: 0.974 - ETA: 28s - loss: 0.0706 - accuracy: 0.974 - ETA: 25s - loss: 0.0721 - accuracy: 0.972 - ETA: 23s - loss: 0.0765 - accuracy: 0.970 - ETA: 20s - loss: 0.0742 - accuracy: 0.971 - ETA: 18s - loss: 0.0713 - accuracy: 0.973 - ETA: 15s - loss: 0.0697 - accuracy: 0.974 - ETA: 13s - loss: 0.0680 - accuracy: 0.975 - ETA: 10s - loss: 0.0697 - accuracy: 0.975 - ETA: 8s - loss: 0.0734 - accuracy: 0.972 - ETA: 5s - loss: 0.0730 - accuracy: 0.97 - ETA: 3s - loss: 0.0707 - accuracy: 0.97 - ETA: 0s - loss: 0.0699 - accuracy: 0.97 - 75s 83ms/step - loss: 0.0694 - accuracy: 0.9734 - val_loss: 0.7593 - val_accuracy: 0.8186\n",
                        "Epoch 78/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.0273 - accuracy: 1.00 - ETA: 1:04 - loss: 0.2248 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1554 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1685 - accuracy: 0.95 - ETA: 57s - loss: 0.1375 - accuracy: 0.9625 - ETA: 55s - loss: 0.1199 - accuracy: 0.968 - ETA: 52s - loss: 0.1335 - accuracy: 0.964 - ETA: 50s - loss: 0.1205 - accuracy: 0.968 - ETA: 47s - loss: 0.1179 - accuracy: 0.968 - ETA: 45s - loss: 0.1074 - accuracy: 0.971 - ETA: 43s - loss: 0.1043 - accuracy: 0.971 - ETA: 40s - loss: 0.1056 - accuracy: 0.971 - ETA: 38s - loss: 0.0990 - accuracy: 0.973 - ETA: 35s - loss: 0.0971 - accuracy: 0.971 - ETA: 32s - loss: 0.0916 - accuracy: 0.972 - ETA: 30s - loss: 0.0886 - accuracy: 0.972 - ETA: 27s - loss: 0.0891 - accuracy: 0.970 - ETA: 25s - loss: 0.0864 - accuracy: 0.972 - ETA: 22s - loss: 0.0861 - accuracy: 0.972 - ETA: 20s - loss: 0.0935 - accuracy: 0.965 - ETA: 17s - loss: 0.0904 - accuracy: 0.967 - ETA: 15s - loss: 0.0876 - accuracy: 0.968 - ETA: 12s - loss: 0.0857 - accuracy: 0.970 - ETA: 10s - loss: 0.0828 - accuracy: 0.971 - ETA: 7s - loss: 0.0806 - accuracy: 0.972 - ETA: 5s - loss: 0.0780 - accuracy: 0.97 - ETA: 3s - loss: 0.0758 - accuracy: 0.97 - ETA: 0s - loss: 0.0756 - accuracy: 0.97 - 74s 82ms/step - loss: 0.0752 - accuracy: 0.9745 - val_loss: 0.7841 - val_accuracy: 0.8186\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 79/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0184 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0498 - accuracy: 0.98 - ETA: 58s - loss: 0.0609 - accuracy: 0.9844 - ETA: 56s - loss: 0.0653 - accuracy: 0.975 - ETA: 53s - loss: 0.0574 - accuracy: 0.979 - ETA: 51s - loss: 0.0506 - accuracy: 0.982 - ETA: 48s - loss: 0.0455 - accuracy: 0.984 - ETA: 46s - loss: 0.0411 - accuracy: 0.986 - ETA: 43s - loss: 0.0442 - accuracy: 0.984 - ETA: 41s - loss: 0.0436 - accuracy: 0.985 - ETA: 38s - loss: 0.0472 - accuracy: 0.984 - ETA: 36s - loss: 0.0445 - accuracy: 0.985 - ETA: 34s - loss: 0.0480 - accuracy: 0.984 - ETA: 31s - loss: 0.0554 - accuracy: 0.981 - ETA: 29s - loss: 0.0576 - accuracy: 0.980 - ETA: 26s - loss: 0.0545 - accuracy: 0.981 - ETA: 24s - loss: 0.0524 - accuracy: 0.982 - ETA: 22s - loss: 0.0572 - accuracy: 0.980 - ETA: 19s - loss: 0.0550 - accuracy: 0.981 - ETA: 17s - loss: 0.0644 - accuracy: 0.977 - ETA: 15s - loss: 0.0623 - accuracy: 0.978 - ETA: 12s - loss: 0.0608 - accuracy: 0.979 - ETA: 10s - loss: 0.0652 - accuracy: 0.976 - ETA: 7s - loss: 0.0700 - accuracy: 0.975 - ETA: 5s - loss: 0.0687 - accuracy: 0.97 - ETA: 2s - loss: 0.0667 - accuracy: 0.97 - ETA: 0s - loss: 0.0657 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0659 - accuracy: 0.9767 - val_loss: 0.9037 - val_accuracy: 0.8230\n",
                        "Epoch 80/100\n",
                        "903/903 [==============================] - ETA: 1:08 - loss: 0.3133 - accuracy: 0.87 - ETA: 1:05 - loss: 0.1841 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1305 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1038 - accuracy: 0.96 - ETA: 57s - loss: 0.1011 - accuracy: 0.9625 - ETA: 55s - loss: 0.0981 - accuracy: 0.963 - ETA: 52s - loss: 0.0884 - accuracy: 0.968 - ETA: 50s - loss: 0.0816 - accuracy: 0.972 - ETA: 47s - loss: 0.0744 - accuracy: 0.975 - ETA: 45s - loss: 0.0739 - accuracy: 0.975 - ETA: 42s - loss: 0.0877 - accuracy: 0.971 - ETA: 40s - loss: 0.0835 - accuracy: 0.974 - ETA: 37s - loss: 0.0794 - accuracy: 0.976 - ETA: 35s - loss: 0.0751 - accuracy: 0.977 - ETA: 32s - loss: 0.0753 - accuracy: 0.977 - ETA: 30s - loss: 0.0741 - accuracy: 0.976 - ETA: 27s - loss: 0.0851 - accuracy: 0.976 - ETA: 25s - loss: 0.0843 - accuracy: 0.975 - ETA: 22s - loss: 0.0850 - accuracy: 0.973 - ETA: 20s - loss: 0.0815 - accuracy: 0.975 - ETA: 17s - loss: 0.0825 - accuracy: 0.974 - ETA: 15s - loss: 0.0824 - accuracy: 0.974 - ETA: 12s - loss: 0.0807 - accuracy: 0.975 - ETA: 10s - loss: 0.0823 - accuracy: 0.974 - ETA: 7s - loss: 0.0875 - accuracy: 0.973 - ETA: 5s - loss: 0.0889 - accuracy: 0.97 - ETA: 3s - loss: 0.0902 - accuracy: 0.97 - ETA: 0s - loss: 0.0887 - accuracy: 0.97 - 74s 82ms/step - loss: 0.0887 - accuracy: 0.9723 - val_loss: 0.8906 - val_accuracy: 0.8186\n",
                        "Epoch 81/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0389 - accuracy: 1.00 - ETA: 1:04 - loss: 0.0454 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0971 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0826 - accuracy: 0.98 - ETA: 57s - loss: 0.1138 - accuracy: 0.9750 - ETA: 55s - loss: 0.0997 - accuracy: 0.979 - ETA: 52s - loss: 0.0920 - accuracy: 0.977 - ETA: 50s - loss: 0.0886 - accuracy: 0.976 - ETA: 47s - loss: 0.0807 - accuracy: 0.979 - ETA: 45s - loss: 0.0733 - accuracy: 0.981 - ETA: 43s - loss: 0.0714 - accuracy: 0.983 - ETA: 41s - loss: 0.0733 - accuracy: 0.981 - ETA: 39s - loss: 0.1068 - accuracy: 0.976 - ETA: 37s - loss: 0.1020 - accuracy: 0.975 - ETA: 34s - loss: 0.0959 - accuracy: 0.977 - ETA: 32s - loss: 0.0957 - accuracy: 0.976 - ETA: 29s - loss: 0.0917 - accuracy: 0.977 - ETA: 26s - loss: 0.0944 - accuracy: 0.977 - ETA: 24s - loss: 0.0968 - accuracy: 0.975 - ETA: 21s - loss: 0.0937 - accuracy: 0.976 - ETA: 18s - loss: 0.0958 - accuracy: 0.974 - ETA: 16s - loss: 0.0968 - accuracy: 0.973 - ETA: 13s - loss: 0.0941 - accuracy: 0.974 - ETA: 10s - loss: 0.0908 - accuracy: 0.975 - ETA: 8s - loss: 0.0891 - accuracy: 0.975 - ETA: 5s - loss: 0.0977 - accuracy: 0.97 - ETA: 3s - loss: 0.0954 - accuracy: 0.97 - ETA: 0s - loss: 0.0958 - accuracy: 0.97 - 79s 87ms/step - loss: 0.0952 - accuracy: 0.9723 - val_loss: 0.8599 - val_accuracy: 0.7743\n",
                        "Epoch 82/100\n",
                        "903/903 [==============================] - ETA: 1:10 - loss: 0.1590 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1515 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1374 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1044 - accuracy: 0.95 - ETA: 1:02 - loss: 0.0873 - accuracy: 0.96 - ETA: 59s - loss: 0.0790 - accuracy: 0.9635 - ETA: 56s - loss: 0.0857 - accuracy: 0.964 - ETA: 53s - loss: 0.0952 - accuracy: 0.960 - ETA: 50s - loss: 0.0881 - accuracy: 0.965 - ETA: 48s - loss: 0.0931 - accuracy: 0.965 - ETA: 45s - loss: 0.0917 - accuracy: 0.965 - ETA: 42s - loss: 0.0859 - accuracy: 0.968 - ETA: 40s - loss: 0.0930 - accuracy: 0.963 - ETA: 37s - loss: 0.0880 - accuracy: 0.966 - ETA: 34s - loss: 0.0906 - accuracy: 0.966 - ETA: 31s - loss: 0.0894 - accuracy: 0.966 - ETA: 29s - loss: 0.0853 - accuracy: 0.968 - ETA: 26s - loss: 0.0817 - accuracy: 0.970 - ETA: 23s - loss: 0.0793 - accuracy: 0.970 - ETA: 21s - loss: 0.0789 - accuracy: 0.970 - ETA: 18s - loss: 0.0778 - accuracy: 0.970 - ETA: 15s - loss: 0.0793 - accuracy: 0.970 - ETA: 13s - loss: 0.0828 - accuracy: 0.970 - ETA: 10s - loss: 0.0848 - accuracy: 0.970 - ETA: 8s - loss: 0.0831 - accuracy: 0.970 - ETA: 5s - loss: 0.0807 - accuracy: 0.97 - ETA: 3s - loss: 0.0854 - accuracy: 0.97 - ETA: 0s - loss: 0.0834 - accuracy: 0.97 - 75s 83ms/step - loss: 0.0830 - accuracy: 0.9723 - val_loss: 0.7155 - val_accuracy: 0.8274\n",
                        "Epoch 83/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0427 - accuracy: 1.00 - ETA: 1:01 - loss: 0.0359 - accuracy: 1.00 - ETA: 59s - loss: 0.0402 - accuracy: 0.9896 - ETA: 57s - loss: 0.0829 - accuracy: 0.960 - ETA: 54s - loss: 0.0735 - accuracy: 0.968 - ETA: 52s - loss: 0.0843 - accuracy: 0.968 - ETA: 49s - loss: 0.0804 - accuracy: 0.968 - ETA: 47s - loss: 0.0805 - accuracy: 0.968 - ETA: 44s - loss: 0.0823 - accuracy: 0.968 - ETA: 42s - loss: 0.0773 - accuracy: 0.971 - ETA: 39s - loss: 0.0863 - accuracy: 0.971 - ETA: 37s - loss: 0.0816 - accuracy: 0.974 - ETA: 35s - loss: 0.0761 - accuracy: 0.976 - ETA: 32s - loss: 0.0776 - accuracy: 0.973 - ETA: 30s - loss: 0.0906 - accuracy: 0.972 - ETA: 28s - loss: 0.0895 - accuracy: 0.972 - ETA: 25s - loss: 0.0851 - accuracy: 0.974 - ETA: 23s - loss: 0.0837 - accuracy: 0.974 - ETA: 21s - loss: 0.0807 - accuracy: 0.975 - ETA: 18s - loss: 0.0774 - accuracy: 0.976 - ETA: 16s - loss: 0.0753 - accuracy: 0.977 - ETA: 14s - loss: 0.0743 - accuracy: 0.977 - ETA: 12s - loss: 0.0722 - accuracy: 0.978 - ETA: 9s - loss: 0.0713 - accuracy: 0.977 - ETA: 7s - loss: 0.0706 - accuracy: 0.97 - ETA: 5s - loss: 0.0740 - accuracy: 0.97 - ETA: 2s - loss: 0.0745 - accuracy: 0.97 - ETA: 0s - loss: 0.0723 - accuracy: 0.97 - 71s 79ms/step - loss: 0.0720 - accuracy: 0.9767 - val_loss: 0.8478 - val_accuracy: 0.8097\n",
                        "Epoch 84/100\n",
                        "903/903 [==============================] - ETA: 1:10 - loss: 0.0441 - accuracy: 1.00 - ETA: 1:07 - loss: 0.0305 - accuracy: 1.00 - ETA: 1:04 - loss: 0.0228 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0488 - accuracy: 0.99 - ETA: 58s - loss: 0.0629 - accuracy: 0.9875 - ETA: 55s - loss: 0.0840 - accuracy: 0.974 - ETA: 52s - loss: 0.0772 - accuracy: 0.977 - ETA: 49s - loss: 0.0773 - accuracy: 0.976 - ETA: 47s - loss: 0.0933 - accuracy: 0.972 - ETA: 44s - loss: 0.0859 - accuracy: 0.975 - ETA: 41s - loss: 0.0940 - accuracy: 0.971 - ETA: 39s - loss: 0.0918 - accuracy: 0.971 - ETA: 36s - loss: 0.0859 - accuracy: 0.973 - ETA: 34s - loss: 0.0887 - accuracy: 0.971 - ETA: 31s - loss: 0.0892 - accuracy: 0.970 - ETA: 29s - loss: 0.0883 - accuracy: 0.970 - ETA: 27s - loss: 0.0924 - accuracy: 0.970 - ETA: 24s - loss: 0.0878 - accuracy: 0.972 - ETA: 22s - loss: 0.0865 - accuracy: 0.973 - ETA: 19s - loss: 0.0840 - accuracy: 0.975 - ETA: 17s - loss: 0.0822 - accuracy: 0.974 - ETA: 15s - loss: 0.0805 - accuracy: 0.974 - ETA: 12s - loss: 0.0781 - accuracy: 0.975 - ETA: 10s - loss: 0.0792 - accuracy: 0.975 - ETA: 7s - loss: 0.0846 - accuracy: 0.975 - ETA: 5s - loss: 0.0852 - accuracy: 0.97 - ETA: 2s - loss: 0.0828 - accuracy: 0.97 - ETA: 0s - loss: 0.0839 - accuracy: 0.97 - 72s 80ms/step - loss: 0.0837 - accuracy: 0.9745 - val_loss: 0.7962 - val_accuracy: 0.8274\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 85/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.0407 - accuracy: 0.96 - ETA: 1:04 - loss: 0.0404 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0665 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0812 - accuracy: 0.96 - ETA: 57s - loss: 0.0854 - accuracy: 0.9625 - ETA: 55s - loss: 0.0920 - accuracy: 0.963 - ETA: 52s - loss: 0.0837 - accuracy: 0.968 - ETA: 49s - loss: 0.0758 - accuracy: 0.972 - ETA: 47s - loss: 0.0773 - accuracy: 0.972 - ETA: 45s - loss: 0.0715 - accuracy: 0.975 - ETA: 42s - loss: 0.0698 - accuracy: 0.974 - ETA: 40s - loss: 0.0706 - accuracy: 0.974 - ETA: 37s - loss: 0.0701 - accuracy: 0.973 - ETA: 35s - loss: 0.0661 - accuracy: 0.975 - ETA: 32s - loss: 0.0639 - accuracy: 0.977 - ETA: 30s - loss: 0.0656 - accuracy: 0.976 - ETA: 27s - loss: 0.0659 - accuracy: 0.976 - ETA: 25s - loss: 0.0629 - accuracy: 0.977 - ETA: 22s - loss: 0.0602 - accuracy: 0.978 - ETA: 20s - loss: 0.0620 - accuracy: 0.976 - ETA: 17s - loss: 0.0635 - accuracy: 0.976 - ETA: 15s - loss: 0.0619 - accuracy: 0.977 - ETA: 12s - loss: 0.0633 - accuracy: 0.976 - ETA: 10s - loss: 0.0628 - accuracy: 0.976 - ETA: 7s - loss: 0.0608 - accuracy: 0.977 - ETA: 5s - loss: 0.0616 - accuracy: 0.97 - ETA: 2s - loss: 0.0647 - accuracy: 0.97 - ETA: 0s - loss: 0.0642 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0638 - accuracy: 0.9745 - val_loss: 0.7425 - val_accuracy: 0.8363\n",
                        "Epoch 86/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0421 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0436 - accuracy: 0.98 - ETA: 58s - loss: 0.0441 - accuracy: 0.9844 - ETA: 55s - loss: 0.0501 - accuracy: 0.981 - ETA: 53s - loss: 0.0448 - accuracy: 0.984 - ETA: 51s - loss: 0.0448 - accuracy: 0.986 - ETA: 49s - loss: 0.0433 - accuracy: 0.988 - ETA: 47s - loss: 0.0453 - accuracy: 0.986 - ETA: 44s - loss: 0.0415 - accuracy: 0.987 - ETA: 42s - loss: 0.0384 - accuracy: 0.988 - ETA: 40s - loss: 0.0482 - accuracy: 0.987 - ETA: 37s - loss: 0.0618 - accuracy: 0.985 - ETA: 35s - loss: 0.0582 - accuracy: 0.986 - ETA: 32s - loss: 0.0628 - accuracy: 0.983 - ETA: 30s - loss: 0.0632 - accuracy: 0.982 - ETA: 27s - loss: 0.0617 - accuracy: 0.983 - ETA: 25s - loss: 0.0597 - accuracy: 0.984 - ETA: 22s - loss: 0.0594 - accuracy: 0.983 - ETA: 20s - loss: 0.0581 - accuracy: 0.982 - ETA: 17s - loss: 0.0567 - accuracy: 0.983 - ETA: 15s - loss: 0.0572 - accuracy: 0.983 - ETA: 12s - loss: 0.0559 - accuracy: 0.983 - ETA: 10s - loss: 0.0664 - accuracy: 0.980 - ETA: 7s - loss: 0.0649 - accuracy: 0.981 - ETA: 5s - loss: 0.0636 - accuracy: 0.98 - ETA: 2s - loss: 0.0676 - accuracy: 0.97 - ETA: 0s - loss: 0.0654 - accuracy: 0.97 - 72s 80ms/step - loss: 0.0649 - accuracy: 0.9801 - val_loss: 0.8822 - val_accuracy: 0.8186\n",
                        "Epoch 87/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.0545 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0471 - accuracy: 0.96 - ETA: 58s - loss: 0.0351 - accuracy: 0.9792 - ETA: 55s - loss: 0.0423 - accuracy: 0.976 - ETA: 53s - loss: 0.0556 - accuracy: 0.968 - ETA: 50s - loss: 0.0538 - accuracy: 0.968 - ETA: 48s - loss: 0.0599 - accuracy: 0.964 - ETA: 46s - loss: 0.0635 - accuracy: 0.964 - ETA: 43s - loss: 0.0724 - accuracy: 0.965 - ETA: 41s - loss: 0.0662 - accuracy: 0.968 - ETA: 39s - loss: 0.0720 - accuracy: 0.965 - ETA: 36s - loss: 0.0685 - accuracy: 0.968 - ETA: 34s - loss: 0.0698 - accuracy: 0.968 - ETA: 32s - loss: 0.0676 - accuracy: 0.968 - ETA: 30s - loss: 0.0673 - accuracy: 0.968 - ETA: 27s - loss: 0.0724 - accuracy: 0.964 - ETA: 25s - loss: 0.0693 - accuracy: 0.966 - ETA: 23s - loss: 0.0660 - accuracy: 0.968 - ETA: 20s - loss: 0.0662 - accuracy: 0.968 - ETA: 18s - loss: 0.0647 - accuracy: 0.968 - ETA: 16s - loss: 0.0630 - accuracy: 0.970 - ETA: 14s - loss: 0.0655 - accuracy: 0.968 - ETA: 11s - loss: 0.0662 - accuracy: 0.968 - ETA: 9s - loss: 0.0641 - accuracy: 0.970 - ETA: 7s - loss: 0.0625 - accuracy: 0.97 - ETA: 5s - loss: 0.0634 - accuracy: 0.97 - ETA: 2s - loss: 0.0613 - accuracy: 0.97 - ETA: 0s - loss: 0.0601 - accuracy: 0.97 - 68s 75ms/step - loss: 0.0597 - accuracy: 0.9712 - val_loss: 0.8227 - val_accuracy: 0.8230\n",
                        "Epoch 88/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.0088 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0163 - accuracy: 1.00 - ETA: 58s - loss: 0.0398 - accuracy: 0.9792 - ETA: 56s - loss: 0.0471 - accuracy: 0.976 - ETA: 54s - loss: 0.0815 - accuracy: 0.968 - ETA: 51s - loss: 0.0696 - accuracy: 0.974 - ETA: 49s - loss: 0.0703 - accuracy: 0.973 - ETA: 47s - loss: 0.0705 - accuracy: 0.972 - ETA: 44s - loss: 0.0723 - accuracy: 0.968 - ETA: 42s - loss: 0.0742 - accuracy: 0.968 - ETA: 40s - loss: 0.0774 - accuracy: 0.968 - ETA: 37s - loss: 0.0795 - accuracy: 0.966 - ETA: 35s - loss: 0.0740 - accuracy: 0.968 - ETA: 33s - loss: 0.0694 - accuracy: 0.971 - ETA: 31s - loss: 0.0661 - accuracy: 0.972 - ETA: 29s - loss: 0.0769 - accuracy: 0.968 - ETA: 26s - loss: 0.0735 - accuracy: 0.970 - ETA: 24s - loss: 0.0712 - accuracy: 0.972 - ETA: 22s - loss: 0.0727 - accuracy: 0.970 - ETA: 19s - loss: 0.0699 - accuracy: 0.971 - ETA: 17s - loss: 0.0722 - accuracy: 0.971 - ETA: 15s - loss: 0.0707 - accuracy: 0.971 - ETA: 12s - loss: 0.0692 - accuracy: 0.971 - ETA: 10s - loss: 0.0746 - accuracy: 0.970 - ETA: 7s - loss: 0.0763 - accuracy: 0.968 - ETA: 5s - loss: 0.0818 - accuracy: 0.96 - ETA: 2s - loss: 0.0836 - accuracy: 0.96 - ETA: 0s - loss: 0.0820 - accuracy: 0.96 - 72s 80ms/step - loss: 0.0852 - accuracy: 0.9668 - val_loss: 0.9445 - val_accuracy: 0.7965\n",
                        "Epoch 89/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0255 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0176 - accuracy: 1.00 - ETA: 57s - loss: 0.0766 - accuracy: 0.9896 - ETA: 55s - loss: 0.1361 - accuracy: 0.953 - ETA: 53s - loss: 0.2468 - accuracy: 0.925 - ETA: 51s - loss: 0.2448 - accuracy: 0.921 - ETA: 48s - loss: 0.2452 - accuracy: 0.910 - ETA: 46s - loss: 0.2353 - accuracy: 0.918 - ETA: 44s - loss: 0.2308 - accuracy: 0.923 - ETA: 41s - loss: 0.2095 - accuracy: 0.931 - ETA: 39s - loss: 0.2075 - accuracy: 0.934 - ETA: 37s - loss: 0.2073 - accuracy: 0.932 - ETA: 34s - loss: 0.2080 - accuracy: 0.930 - ETA: 32s - loss: 0.2018 - accuracy: 0.928 - ETA: 30s - loss: 0.1976 - accuracy: 0.931 - ETA: 27s - loss: 0.1877 - accuracy: 0.933 - ETA: 25s - loss: 0.1874 - accuracy: 0.933 - ETA: 23s - loss: 0.1799 - accuracy: 0.937 - ETA: 21s - loss: 0.1830 - accuracy: 0.935 - ETA: 18s - loss: 0.1826 - accuracy: 0.935 - ETA: 16s - loss: 0.1780 - accuracy: 0.937 - ETA: 14s - loss: 0.1717 - accuracy: 0.940 - ETA: 12s - loss: 0.1669 - accuracy: 0.941 - ETA: 9s - loss: 0.1674 - accuracy: 0.938 - ETA: 7s - loss: 0.1722 - accuracy: 0.93 - ETA: 5s - loss: 0.1673 - accuracy: 0.93 - ETA: 2s - loss: 0.1627 - accuracy: 0.94 - ETA: 0s - loss: 0.1592 - accuracy: 0.94 - 69s 77ms/step - loss: 0.1581 - accuracy: 0.9435 - val_loss: 0.8804 - val_accuracy: 0.8009\n",
                        "Epoch 90/100\n",
                        "903/903 [==============================] - ETA: 1:02 - loss: 0.1275 - accuracy: 0.93 - ETA: 1:00 - loss: 0.0730 - accuracy: 0.96 - ETA: 58s - loss: 0.0668 - accuracy: 0.9792 - ETA: 56s - loss: 0.0858 - accuracy: 0.968 - ETA: 54s - loss: 0.0887 - accuracy: 0.968 - ETA: 51s - loss: 0.0927 - accuracy: 0.968 - ETA: 49s - loss: 0.0834 - accuracy: 0.973 - ETA: 47s - loss: 0.0763 - accuracy: 0.976 - ETA: 44s - loss: 0.0683 - accuracy: 0.979 - ETA: 42s - loss: 0.0682 - accuracy: 0.978 - ETA: 40s - loss: 0.0734 - accuracy: 0.974 - ETA: 38s - loss: 0.0693 - accuracy: 0.976 - ETA: 35s - loss: 0.0657 - accuracy: 0.978 - ETA: 33s - loss: 0.0629 - accuracy: 0.979 - ETA: 31s - loss: 0.0627 - accuracy: 0.981 - ETA: 29s - loss: 0.0619 - accuracy: 0.980 - ETA: 26s - loss: 0.0606 - accuracy: 0.981 - ETA: 24s - loss: 0.0581 - accuracy: 0.982 - ETA: 22s - loss: 0.0610 - accuracy: 0.981 - ETA: 19s - loss: 0.0594 - accuracy: 0.982 - ETA: 17s - loss: 0.0598 - accuracy: 0.983 - ETA: 14s - loss: 0.0627 - accuracy: 0.981 - ETA: 12s - loss: 0.0649 - accuracy: 0.979 - ETA: 10s - loss: 0.0632 - accuracy: 0.980 - ETA: 7s - loss: 0.0622 - accuracy: 0.981 - ETA: 5s - loss: 0.0681 - accuracy: 0.97 - ETA: 2s - loss: 0.0660 - accuracy: 0.97 - ETA: 0s - loss: 0.0650 - accuracy: 0.97 - 72s 80ms/step - loss: 0.0700 - accuracy: 0.9767 - val_loss: 0.8635 - val_accuracy: 0.8009\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 91/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.0107 - accuracy: 1.00 - ETA: 1:04 - loss: 0.0096 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0737 - accuracy: 0.98 - ETA: 59s - loss: 0.0985 - accuracy: 0.9766 - ETA: 57s - loss: 0.0828 - accuracy: 0.981 - ETA: 54s - loss: 0.0710 - accuracy: 0.984 - ETA: 51s - loss: 0.0793 - accuracy: 0.977 - ETA: 49s - loss: 0.0882 - accuracy: 0.968 - ETA: 46s - loss: 0.0809 - accuracy: 0.972 - ETA: 44s - loss: 0.0761 - accuracy: 0.975 - ETA: 42s - loss: 0.0725 - accuracy: 0.977 - ETA: 39s - loss: 0.0687 - accuracy: 0.979 - ETA: 37s - loss: 0.0762 - accuracy: 0.976 - ETA: 35s - loss: 0.0779 - accuracy: 0.973 - ETA: 32s - loss: 0.0738 - accuracy: 0.975 - ETA: 30s - loss: 0.0698 - accuracy: 0.976 - ETA: 28s - loss: 0.0680 - accuracy: 0.977 - ETA: 25s - loss: 0.0650 - accuracy: 0.979 - ETA: 23s - loss: 0.0625 - accuracy: 0.980 - ETA: 20s - loss: 0.0610 - accuracy: 0.981 - ETA: 18s - loss: 0.0583 - accuracy: 0.982 - ETA: 15s - loss: 0.0565 - accuracy: 0.983 - ETA: 13s - loss: 0.0550 - accuracy: 0.983 - ETA: 10s - loss: 0.0536 - accuracy: 0.984 - ETA: 8s - loss: 0.0613 - accuracy: 0.981 - ETA: 5s - loss: 0.0642 - accuracy: 0.98 - ETA: 3s - loss: 0.0628 - accuracy: 0.98 - ETA: 0s - loss: 0.0610 - accuracy: 0.98 - 76s 84ms/step - loss: 0.0613 - accuracy: 0.9823 - val_loss: 0.7798 - val_accuracy: 0.8274\n",
                        "Epoch 92/100\n",
                        "903/903 [==============================] - ETA: 1:06 - loss: 0.1383 - accuracy: 0.96 - ETA: 1:04 - loss: 0.0966 - accuracy: 0.96 - ETA: 1:01 - loss: 0.0726 - accuracy: 0.97 - ETA: 59s - loss: 0.0774 - accuracy: 0.9688 - ETA: 56s - loss: 0.0706 - accuracy: 0.968 - ETA: 54s - loss: 0.0787 - accuracy: 0.963 - ETA: 51s - loss: 0.0717 - accuracy: 0.968 - ETA: 49s - loss: 0.0809 - accuracy: 0.964 - ETA: 46s - loss: 0.0725 - accuracy: 0.968 - ETA: 44s - loss: 0.0727 - accuracy: 0.968 - ETA: 41s - loss: 0.0716 - accuracy: 0.968 - ETA: 39s - loss: 0.0763 - accuracy: 0.966 - ETA: 37s - loss: 0.0725 - accuracy: 0.968 - ETA: 35s - loss: 0.0721 - accuracy: 0.968 - ETA: 32s - loss: 0.0693 - accuracy: 0.968 - ETA: 30s - loss: 0.0760 - accuracy: 0.966 - ETA: 28s - loss: 0.0721 - accuracy: 0.968 - ETA: 25s - loss: 0.0688 - accuracy: 0.970 - ETA: 22s - loss: 0.0657 - accuracy: 0.972 - ETA: 20s - loss: 0.0649 - accuracy: 0.971 - ETA: 17s - loss: 0.0655 - accuracy: 0.971 - ETA: 15s - loss: 0.0680 - accuracy: 0.971 - ETA: 12s - loss: 0.0660 - accuracy: 0.972 - ETA: 10s - loss: 0.0670 - accuracy: 0.972 - ETA: 7s - loss: 0.0674 - accuracy: 0.972 - ETA: 5s - loss: 0.0674 - accuracy: 0.97 - ETA: 2s - loss: 0.0668 - accuracy: 0.97 - ETA: 0s - loss: 0.0686 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0680 - accuracy: 0.9723 - val_loss: 0.8950 - val_accuracy: 0.8230\n",
                        "Epoch 93/100\n",
                        "903/903 [==============================] - ETA: 1:05 - loss: 0.0097 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0115 - accuracy: 1.00 - ETA: 1:00 - loss: 0.0479 - accuracy: 0.98 - ETA: 57s - loss: 0.0423 - accuracy: 0.9922 - ETA: 55s - loss: 0.0351 - accuracy: 0.993 - ETA: 52s - loss: 0.0307 - accuracy: 0.994 - ETA: 50s - loss: 0.0270 - accuracy: 0.995 - ETA: 48s - loss: 0.0248 - accuracy: 0.996 - ETA: 46s - loss: 0.0284 - accuracy: 0.993 - ETA: 43s - loss: 0.0377 - accuracy: 0.987 - ETA: 41s - loss: 0.0487 - accuracy: 0.983 - ETA: 38s - loss: 0.0534 - accuracy: 0.981 - ETA: 36s - loss: 0.0563 - accuracy: 0.980 - ETA: 33s - loss: 0.0543 - accuracy: 0.982 - ETA: 31s - loss: 0.0695 - accuracy: 0.977 - ETA: 28s - loss: 0.0654 - accuracy: 0.978 - ETA: 26s - loss: 0.0691 - accuracy: 0.976 - ETA: 23s - loss: 0.0779 - accuracy: 0.972 - ETA: 21s - loss: 0.0745 - accuracy: 0.973 - ETA: 19s - loss: 0.0749 - accuracy: 0.973 - ETA: 16s - loss: 0.0734 - accuracy: 0.973 - ETA: 14s - loss: 0.0719 - accuracy: 0.974 - ETA: 12s - loss: 0.0711 - accuracy: 0.974 - ETA: 9s - loss: 0.0720 - accuracy: 0.974 - ETA: 7s - loss: 0.0719 - accuracy: 0.97 - ETA: 5s - loss: 0.0760 - accuracy: 0.97 - ETA: 2s - loss: 0.0743 - accuracy: 0.97 - ETA: 0s - loss: 0.0758 - accuracy: 0.97 - 69s 76ms/step - loss: 0.0754 - accuracy: 0.9723 - val_loss: 0.7964 - val_accuracy: 0.8451\n",
                        "Epoch 94/100\n",
                        "903/903 [==============================] - ETA: 1:00 - loss: 0.1313 - accuracy: 0.96 - ETA: 58s - loss: 0.0780 - accuracy: 0.9844 - ETA: 56s - loss: 0.0804 - accuracy: 0.979 - ETA: 54s - loss: 0.0785 - accuracy: 0.976 - ETA: 51s - loss: 0.0803 - accuracy: 0.968 - ETA: 49s - loss: 0.1407 - accuracy: 0.953 - ETA: 47s - loss: 0.1220 - accuracy: 0.959 - ETA: 45s - loss: 0.1092 - accuracy: 0.964 - ETA: 43s - loss: 0.1105 - accuracy: 0.965 - ETA: 40s - loss: 0.1081 - accuracy: 0.965 - ETA: 38s - loss: 0.1003 - accuracy: 0.968 - ETA: 36s - loss: 0.0967 - accuracy: 0.968 - ETA: 34s - loss: 0.0993 - accuracy: 0.966 - ETA: 32s - loss: 0.0958 - accuracy: 0.966 - ETA: 29s - loss: 0.0910 - accuracy: 0.968 - ETA: 27s - loss: 0.0876 - accuracy: 0.968 - ETA: 25s - loss: 0.0828 - accuracy: 0.970 - ETA: 23s - loss: 0.0803 - accuracy: 0.970 - ETA: 20s - loss: 0.0773 - accuracy: 0.972 - ETA: 18s - loss: 0.0812 - accuracy: 0.970 - ETA: 16s - loss: 0.0823 - accuracy: 0.968 - ETA: 14s - loss: 0.0831 - accuracy: 0.968 - ETA: 11s - loss: 0.0804 - accuracy: 0.970 - ETA: 9s - loss: 0.0835 - accuracy: 0.970 - ETA: 7s - loss: 0.0841 - accuracy: 0.96 - ETA: 5s - loss: 0.0816 - accuracy: 0.97 - ETA: 2s - loss: 0.0806 - accuracy: 0.96 - ETA: 0s - loss: 0.0781 - accuracy: 0.97 - 69s 77ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.7728 - val_accuracy: 0.8230\n",
                        "Epoch 95/100\n",
                        "903/903 [==============================] - ETA: 1:04 - loss: 0.0582 - accuracy: 0.96 - ETA: 1:01 - loss: 0.0353 - accuracy: 0.98 - ETA: 59s - loss: 0.0493 - accuracy: 0.9792 - ETA: 57s - loss: 0.0519 - accuracy: 0.976 - ETA: 55s - loss: 0.0504 - accuracy: 0.975 - ETA: 53s - loss: 0.0591 - accuracy: 0.968 - ETA: 51s - loss: 0.0531 - accuracy: 0.973 - ETA: 49s - loss: 0.0613 - accuracy: 0.968 - ETA: 46s - loss: 0.0571 - accuracy: 0.972 - ETA: 45s - loss: 0.0644 - accuracy: 0.971 - ETA: 42s - loss: 0.0587 - accuracy: 0.974 - ETA: 40s - loss: 0.0546 - accuracy: 0.976 - ETA: 37s - loss: 0.0572 - accuracy: 0.973 - ETA: 35s - loss: 0.0630 - accuracy: 0.973 - ETA: 32s - loss: 0.0609 - accuracy: 0.975 - ETA: 30s - loss: 0.0597 - accuracy: 0.974 - ETA: 27s - loss: 0.0584 - accuracy: 0.976 - ETA: 25s - loss: 0.0660 - accuracy: 0.972 - ETA: 22s - loss: 0.0638 - accuracy: 0.973 - ETA: 20s - loss: 0.0659 - accuracy: 0.973 - ETA: 17s - loss: 0.0639 - accuracy: 0.974 - ETA: 15s - loss: 0.0619 - accuracy: 0.975 - ETA: 12s - loss: 0.0598 - accuracy: 0.976 - ETA: 10s - loss: 0.0657 - accuracy: 0.975 - ETA: 7s - loss: 0.0735 - accuracy: 0.973 - ETA: 5s - loss: 0.0720 - accuracy: 0.97 - ETA: 3s - loss: 0.0712 - accuracy: 0.97 - ETA: 0s - loss: 0.0806 - accuracy: 0.97 - 74s 82ms/step - loss: 0.0801 - accuracy: 0.9712 - val_loss: 0.8788 - val_accuracy: 0.7920\n",
                        "Epoch 96/100\n",
                        "903/903 [==============================] - ETA: 1:09 - loss: 0.0125 - accuracy: 1.00 - ETA: 1:06 - loss: 0.0246 - accuracy: 1.00 - ETA: 1:05 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0581 - accuracy: 0.98 - ETA: 59s - loss: 0.0555 - accuracy: 0.9812 - ETA: 56s - loss: 0.0552 - accuracy: 0.979 - ETA: 53s - loss: 0.0562 - accuracy: 0.977 - ETA: 51s - loss: 0.0513 - accuracy: 0.980 - ETA: 48s - loss: 0.0515 - accuracy: 0.982 - ETA: 45s - loss: 0.0504 - accuracy: 0.984 - ETA: 43s - loss: 0.0638 - accuracy: 0.977 - ETA: 40s - loss: 0.0728 - accuracy: 0.974 - ETA: 38s - loss: 0.0681 - accuracy: 0.976 - ETA: 35s - loss: 0.0670 - accuracy: 0.975 - ETA: 33s - loss: 0.0646 - accuracy: 0.977 - ETA: 30s - loss: 0.0617 - accuracy: 0.978 - ETA: 28s - loss: 0.0614 - accuracy: 0.979 - ETA: 25s - loss: 0.0600 - accuracy: 0.980 - ETA: 23s - loss: 0.0604 - accuracy: 0.980 - ETA: 20s - loss: 0.0670 - accuracy: 0.978 - ETA: 18s - loss: 0.0647 - accuracy: 0.979 - ETA: 15s - loss: 0.0634 - accuracy: 0.980 - ETA: 12s - loss: 0.0632 - accuracy: 0.979 - ETA: 10s - loss: 0.0622 - accuracy: 0.979 - ETA: 7s - loss: 0.0639 - accuracy: 0.977 - ETA: 5s - loss: 0.0632 - accuracy: 0.97 - ETA: 2s - loss: 0.0615 - accuracy: 0.97 - ETA: 0s - loss: 0.0602 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0599 - accuracy: 0.9790 - val_loss: 0.7764 - val_accuracy: 0.8142\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 97/100\n",
                        "903/903 [==============================] - ETA: 1:01 - loss: 0.0936 - accuracy: 0.93 - ETA: 59s - loss: 0.0581 - accuracy: 0.9688 - ETA: 57s - loss: 0.0567 - accuracy: 0.968 - ETA: 55s - loss: 0.0702 - accuracy: 0.968 - ETA: 52s - loss: 0.0651 - accuracy: 0.975 - ETA: 50s - loss: 0.0708 - accuracy: 0.968 - ETA: 48s - loss: 0.0783 - accuracy: 0.968 - ETA: 46s - loss: 0.0722 - accuracy: 0.972 - ETA: 44s - loss: 0.0659 - accuracy: 0.975 - ETA: 42s - loss: 0.0670 - accuracy: 0.971 - ETA: 39s - loss: 0.0642 - accuracy: 0.974 - ETA: 37s - loss: 0.0712 - accuracy: 0.971 - ETA: 35s - loss: 0.0710 - accuracy: 0.971 - ETA: 33s - loss: 0.0799 - accuracy: 0.968 - ETA: 30s - loss: 0.0766 - accuracy: 0.970 - ETA: 28s - loss: 0.0841 - accuracy: 0.966 - ETA: 26s - loss: 0.0834 - accuracy: 0.965 - ETA: 23s - loss: 0.0830 - accuracy: 0.965 - ETA: 21s - loss: 0.0804 - accuracy: 0.965 - ETA: 19s - loss: 0.0820 - accuracy: 0.964 - ETA: 16s - loss: 0.0848 - accuracy: 0.962 - ETA: 14s - loss: 0.0817 - accuracy: 0.964 - ETA: 12s - loss: 0.0786 - accuracy: 0.966 - ETA: 9s - loss: 0.0758 - accuracy: 0.967 - ETA: 7s - loss: 0.0767 - accuracy: 0.96 - ETA: 5s - loss: 0.0768 - accuracy: 0.96 - ETA: 2s - loss: 0.0753 - accuracy: 0.96 - ETA: 0s - loss: 0.0740 - accuracy: 0.96 - 71s 78ms/step - loss: 0.0735 - accuracy: 0.9679 - val_loss: 0.7725 - val_accuracy: 0.8097\n",
                        "Epoch 98/100\n",
                        "903/903 [==============================] - ETA: 1:07 - loss: 0.0216 - accuracy: 1.00 - ETA: 1:04 - loss: 0.0498 - accuracy: 0.96 - ETA: 1:01 - loss: 0.0385 - accuracy: 0.97 - ETA: 58s - loss: 0.0589 - accuracy: 0.9766 - ETA: 55s - loss: 0.0757 - accuracy: 0.975 - ETA: 53s - loss: 0.0660 - accuracy: 0.979 - ETA: 50s - loss: 0.0603 - accuracy: 0.982 - ETA: 48s - loss: 0.0535 - accuracy: 0.984 - ETA: 45s - loss: 0.0525 - accuracy: 0.982 - ETA: 43s - loss: 0.0484 - accuracy: 0.984 - ETA: 40s - loss: 0.0538 - accuracy: 0.980 - ETA: 38s - loss: 0.0656 - accuracy: 0.976 - ETA: 35s - loss: 0.0636 - accuracy: 0.976 - ETA: 33s - loss: 0.0601 - accuracy: 0.977 - ETA: 31s - loss: 0.0605 - accuracy: 0.977 - ETA: 28s - loss: 0.0583 - accuracy: 0.978 - ETA: 26s - loss: 0.0564 - accuracy: 0.979 - ETA: 23s - loss: 0.0545 - accuracy: 0.980 - ETA: 21s - loss: 0.0526 - accuracy: 0.981 - ETA: 19s - loss: 0.0534 - accuracy: 0.981 - ETA: 16s - loss: 0.0511 - accuracy: 0.982 - ETA: 14s - loss: 0.0550 - accuracy: 0.980 - ETA: 12s - loss: 0.0559 - accuracy: 0.979 - ETA: 9s - loss: 0.0542 - accuracy: 0.980 - ETA: 7s - loss: 0.0528 - accuracy: 0.98 - ETA: 5s - loss: 0.0526 - accuracy: 0.98 - ETA: 2s - loss: 0.0557 - accuracy: 0.98 - ETA: 0s - loss: 0.0541 - accuracy: 0.98 - 70s 77ms/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.9019 - val_accuracy: 0.7965\n",
                        "Epoch 99/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0236 - accuracy: 1.00 - ETA: 1:01 - loss: 0.0147 - accuracy: 1.00 - ETA: 59s - loss: 0.0251 - accuracy: 0.9896 - ETA: 57s - loss: 0.0357 - accuracy: 0.984 - ETA: 55s - loss: 0.0304 - accuracy: 0.987 - ETA: 52s - loss: 0.0290 - accuracy: 0.989 - ETA: 50s - loss: 0.0308 - accuracy: 0.986 - ETA: 47s - loss: 0.0289 - accuracy: 0.988 - ETA: 45s - loss: 0.0351 - accuracy: 0.979 - ETA: 42s - loss: 0.0321 - accuracy: 0.981 - ETA: 40s - loss: 0.0295 - accuracy: 0.983 - ETA: 38s - loss: 0.0294 - accuracy: 0.981 - ETA: 35s - loss: 0.0307 - accuracy: 0.980 - ETA: 33s - loss: 0.0294 - accuracy: 0.982 - ETA: 31s - loss: 0.0332 - accuracy: 0.981 - ETA: 28s - loss: 0.0323 - accuracy: 0.982 - ETA: 26s - loss: 0.0307 - accuracy: 0.983 - ETA: 24s - loss: 0.0299 - accuracy: 0.984 - ETA: 21s - loss: 0.0308 - accuracy: 0.985 - ETA: 19s - loss: 0.0325 - accuracy: 0.984 - ETA: 16s - loss: 0.0358 - accuracy: 0.983 - ETA: 14s - loss: 0.0351 - accuracy: 0.984 - ETA: 12s - loss: 0.0365 - accuracy: 0.985 - ETA: 9s - loss: 0.0358 - accuracy: 0.985 - ETA: 7s - loss: 0.0351 - accuracy: 0.98 - ETA: 5s - loss: 0.0348 - accuracy: 0.98 - ETA: 2s - loss: 0.0336 - accuracy: 0.98 - ETA: 0s - loss: 0.0391 - accuracy: 0.98 - 71s 79ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.9467 - val_accuracy: 0.8142\n",
                        "Epoch 100/100\n",
                        "903/903 [==============================] - ETA: 1:03 - loss: 0.0927 - accuracy: 0.93 - ETA: 1:02 - loss: 0.0533 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1170 - accuracy: 0.95 - ETA: 57s - loss: 0.1032 - accuracy: 0.9609 - ETA: 55s - loss: 0.0876 - accuracy: 0.968 - ETA: 52s - loss: 0.0801 - accuracy: 0.968 - ETA: 50s - loss: 0.0725 - accuracy: 0.973 - ETA: 48s - loss: 0.0921 - accuracy: 0.960 - ETA: 45s - loss: 0.0841 - accuracy: 0.965 - ETA: 43s - loss: 0.0915 - accuracy: 0.962 - ETA: 41s - loss: 0.0862 - accuracy: 0.963 - ETA: 38s - loss: 0.0961 - accuracy: 0.960 - ETA: 36s - loss: 0.0952 - accuracy: 0.959 - ETA: 33s - loss: 0.0910 - accuracy: 0.959 - ETA: 31s - loss: 0.0927 - accuracy: 0.960 - ETA: 29s - loss: 0.0957 - accuracy: 0.960 - ETA: 26s - loss: 0.0909 - accuracy: 0.963 - ETA: 24s - loss: 0.0890 - accuracy: 0.963 - ETA: 22s - loss: 0.0852 - accuracy: 0.965 - ETA: 19s - loss: 0.0866 - accuracy: 0.964 - ETA: 17s - loss: 0.0866 - accuracy: 0.964 - ETA: 15s - loss: 0.0841 - accuracy: 0.965 - ETA: 12s - loss: 0.0832 - accuracy: 0.966 - ETA: 10s - loss: 0.0803 - accuracy: 0.967 - ETA: 7s - loss: 0.0781 - accuracy: 0.968 - ETA: 5s - loss: 0.0753 - accuracy: 0.97 - ETA: 2s - loss: 0.0726 - accuracy: 0.97 - ETA: 0s - loss: 0.0723 - accuracy: 0.97 - 73s 81ms/step - loss: 0.0717 - accuracy: 0.9712 - val_loss: 0.7901 - val_accuracy: 0.8274\n"
                    ]
                }
            ],
            "source": [
                "epochs = 100\n",
                "batch_size = 32\n",
                "\n",
                "history = general_model.fit(x=X_train_input,\n",
                "                  y=to_categorical(y_train),batch_size = batch_size,validation_data=(X_test_input,to_categorical(y_test)),\n",
                "                  epochs = epochs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "print(history.history.keys())\n",
                "# summarize history for accuracy\n",
                "plt.plot(history.history['accuracy'])\n",
                "plt.plot(history.history['val_accuracy'])\n",
                "plt.title('model accuracy')\n",
                "plt.ylabel('accuracy')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train', 'test'], loc='upper left')\n",
                "plt.show()\n",
                "# summarize history for loss\n",
                "plt.plot(history.history['loss'])\n",
                "plt.plot(history.history['val_loss'])\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train', 'test'], loc='upper left')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "general_model.save('bert_relation_extraction')\n",
                "#general_model = tf.keras.models.load_model('bert_relation_extraction')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "  NoRelation       0.77      0.84      0.80        58\n",
                        "    MinValue       0.79      0.68      0.73        40\n",
                        "    MaxValue       0.84      0.94      0.89        62\n",
                        "     IsValue       0.90      0.80      0.85        66\n",
                        "\n",
                        "   micro avg       0.83      0.83      0.83       226\n",
                        "   macro avg       0.82      0.81      0.82       226\n",
                        "weighted avg       0.83      0.83      0.83       226\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import classification_report\n",
                "y_pred = general_model.predict(X_test_input, batch_size=32, verbose=10)\n",
                "y_pred_bool = np.argmax(y_pred, axis=1)\n",
                "print(classification_report(y_test,y_pred_bool,target_names=['NoRelation','MinValue','MaxValue','IsValue']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
